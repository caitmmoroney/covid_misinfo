{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Word Context Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.decomposition import FastICA, TruncatedSVD, PCA, NMF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert contractions picked up by word_tokenize() into full words\n",
    "contractions = {\n",
    "    \"n't\": 'not',\n",
    "    \"'ve\": 'have',\n",
    "    \"'s\": 'is', # note that this will include possessive nouns\n",
    "    'gonna': 'going to',\n",
    "    'gotta': 'got to',\n",
    "    \"'d\": 'would',\n",
    "    \"'ll\": 'will',\n",
    "    \"'re\": 'are',\n",
    "    \"'m\": 'am',\n",
    "    'wanna': 'want to'\n",
    "}\n",
    "\n",
    "# to convert nltk_pos tags to wordnet-compatible PoS tags\n",
    "def convert_pos_wordnet(tag):\n",
    "    tag_abbr = tag[0].upper()\n",
    "    tag_dict = {\n",
    "        'J': wordnet.ADJ,\n",
    "        'N': wordnet.NOUN,\n",
    "        'V': wordnet.VERB,\n",
    "        'R': wordnet.ADV\n",
    "    }\n",
    "                \n",
    "    if tag_abbr in tag_dict:\n",
    "        return tag_dict[tag_abbr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextMatrix(TransformerMixin):\n",
    "    \n",
    "    # initialize class & private variables\n",
    "    def __init__(self,\n",
    "                 window_size = 4,\n",
    "                 remove_stopwords = True,\n",
    "                 add_start_end_tokens = True,\n",
    "                 lowercase = False,\n",
    "                 lemmatize = False,\n",
    "                 pmi = False,\n",
    "                 spmi_k = 1,\n",
    "                 laplace_smoothing = 0,\n",
    "                 pmi_positive = False,\n",
    "                 sppmi_k = 1):\n",
    "        \n",
    "        \"\"\" Params:\n",
    "                window_size: size of +/- context window (default = 4)\n",
    "                remove_stopwords: boolean, whether or not to remove NLTK English stopwords\n",
    "                add_start_end_tokens: boolean, whether or not to append <START> and <END> to the\n",
    "                beginning/end of each document in the corpus (default = True)\n",
    "                lowercase: boolean, whether or not to convert words to all lowercase\n",
    "                lemmatize: boolean, whether or not to lemmatize input text\n",
    "                pmi: boolean, whether or not to compute pointwise mutual information\n",
    "                pmi_positive: boolean, whether or not to compute positive PMI\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.add_start_end_tokens = add_start_end_tokens\n",
    "        self.lowercase = lowercase\n",
    "        self.lemmatize = lemmatize\n",
    "        self.pmi = pmi\n",
    "        self.spmi_k = spmi_k\n",
    "        self.laplace_smoothing = laplace_smoothing\n",
    "        self.pmi_positive = pmi_positive\n",
    "        self.sppmi_k = sppmi_k\n",
    "        self.corpus = None\n",
    "        self.clean_corpus = None\n",
    "        self.vocabulary = None\n",
    "        self.X = None\n",
    "        self.doc_terms_lists = None\n",
    "    \n",
    "    def fit(self, corpus, y = None):\n",
    "        \n",
    "        \"\"\" Learn the dictionary of all unique tokens for given corpus.\n",
    "        \n",
    "            Params:\n",
    "                corpus: list of strings\n",
    "            \n",
    "            Returns: self\n",
    "        \"\"\"\n",
    "        self.corpus = corpus\n",
    "        \n",
    "        term_dict = dict()\n",
    "        k = 0\n",
    "        corpus_words = []\n",
    "        clean_corpus = []\n",
    "        doc_terms_lists = []\n",
    "        detokenizer = TreebankWordDetokenizer()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        for text in corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*([)\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "            \n",
    "            # detokenize trick taken from this StackOverflow post:\n",
    "            # https://stackoverflow.com/questions/21948019/python-untokenize-a-sentence\n",
    "            # and NLTK treebank documentation:\n",
    "            # https://www.nltk.org/_modules/nltk/tokenize/treebank.html\n",
    "            text = detokenizer.detokenize(words)\n",
    "            clean_corpus.append(text)\n",
    "            \n",
    "            [corpus_words.append(word) for word in words]\n",
    "            \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            doc_terms_lists.append(words)\n",
    "            \n",
    "        self.clean_corpus = clean_corpus\n",
    "        \n",
    "        self.doc_terms_lists = doc_terms_lists\n",
    "        \n",
    "        corpus_words = list(set(corpus_words))\n",
    "        \n",
    "        if self.add_start_end_tokens:\n",
    "            corpus_words = ['<START>'] + corpus_words + ['<END>']\n",
    "        \n",
    "        corpus_words = sorted(corpus_words)\n",
    "        \n",
    "        for el in corpus_words:\n",
    "            term_dict[el] = k\n",
    "            k += 1\n",
    "            \n",
    "        self.vocabulary = term_dict\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def transform(self, y = None):\n",
    "        \n",
    "        \"\"\" Compute the co-occurrence matrix for given corpus and window_size, using term dictionary\n",
    "            obtained with fit method.\n",
    "        \n",
    "            Returns: term-context co-occurrence matrix (shape: target terms by context terms) with\n",
    "            raw counts\n",
    "        \"\"\"\n",
    "        num_terms = len(self.vocabulary)\n",
    "        window = self.window_size\n",
    "        X = np.full((num_terms, num_terms), self.laplace_smoothing)\n",
    "        \n",
    "        # iterate over each text in the clean corpus (if stopwords were not removed, this is identical\n",
    "        # to the original corpus)\n",
    "        for i in range(len(self.doc_terms_lists)):\n",
    "            \n",
    "            # (ordered) list of words in text\n",
    "            words = self.doc_terms_lists[i]\n",
    "            \n",
    "            for i in range(len(words)):\n",
    "                target = words[i]\n",
    "                \n",
    "                # check to see if target word is in the dictionary; if not, skip\n",
    "                if target in self.vocabulary:\n",
    "                    \n",
    "                    # grab index from dictionary\n",
    "                    target_dict_index = self.vocabulary[target]\n",
    "                    \n",
    "                    # find left-most and right-most window indices for each target word\n",
    "                    left_end_index = max(i - window, 0)\n",
    "                    right_end_index = min(i + window, len(words) - 1)\n",
    "                    \n",
    "                    # loop over all words within window\n",
    "                    # NOTE: this will include the target word; make sure to skip over it\n",
    "                    for j in range(left_end_index, right_end_index + 1):\n",
    "                        \n",
    "                        # skip \"context word\" where the \"context word\" index is equal to the\n",
    "                        # target word index\n",
    "                        if j != i:\n",
    "                            context_word = words[j]\n",
    "                            \n",
    "                            # check to see if context word is in the fitted dictionary; if\n",
    "                            # not, skip\n",
    "                            if context_word in self.vocabulary:\n",
    "                                X[target_dict_index, self.vocabulary[context_word]] += 1\n",
    "        \n",
    "        # if pmi = True, compute pmi matrix from word-context raw frequencies\n",
    "        # more concise code taken from this StackOverflow post:\n",
    "        # https://stackoverflow.com/questions/58701337/how-to-construct-ppmi-matrix-from-a-text-corpus\n",
    "        if self.pmi:\n",
    "            denom = X.sum()\n",
    "            col_sums = X.sum(axis = 0)\n",
    "            row_sums = X.sum(axis = 1)\n",
    "            \n",
    "            expected = np.outer(row_sums, col_sums)/denom\n",
    "            \n",
    "            X = X/expected\n",
    "            \n",
    "            #X[np.any([(X < 0), (X > 0)])] = max(np.log2(X), 0)\n",
    "            \n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(X.shape[1]):\n",
    "                \n",
    "                    if X[i,j] > 0:\n",
    "                        X[i,j] = np.log(X[i,j]) - np.log(self.spmi_k)\n",
    "                        \n",
    "                        if self.pmi_positive:\n",
    "                            X[i,j] = max(X[i,j] - np.log(self.sppmi_k), 0)\n",
    "        \n",
    "        # note that X is a dense matrix\n",
    "        self.X = X\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(lowercase = True, lemmatize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [\n",
    "    \"Coronavirus is a fake liberal hoax.\",\n",
    "    \"Trump won't do anything about coronavirus.\",\n",
    "    \"The liberal fake news media always blame Pres Trump.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ContextMatrix at 0x1a17621410>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.fit(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <th>always</th>\n",
       "      <th>anything</th>\n",
       "      <th>blame</th>\n",
       "      <th>coronavirus</th>\n",
       "      <th>fake</th>\n",
       "      <th>hoax</th>\n",
       "      <th>liberal</th>\n",
       "      <th>medium</th>\n",
       "      <th>news</th>\n",
       "      <th>pres</th>\n",
       "      <th>trump</th>\n",
       "      <th>wont</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>always</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anything</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blame</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronavirus</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fake</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoax</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pres</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wont</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             .  <END>  <START>  always  anything  blame  coronavirus  fake  \\\n",
       ".            0      3        0       1         1      1            2     1   \n",
       "<END>        3      0        0       0         1      1            1     1   \n",
       "<START>      0      0        0       0         1      0            2     2   \n",
       "always       1      0        0       0         0      1            0     1   \n",
       "anything     1      1        1       0         0      0            1     0   \n",
       "blame        1      1        0       1         0      0            0     1   \n",
       "coronavirus  2      1        2       0         1      0            0     1   \n",
       "fake         1      1        2       1         0      1            1     0   \n",
       "hoax         1      1        1       0         0      0            1     1   \n",
       "liberal      1      1        2       1         0      0            1     2   \n",
       "medium       0      0        1       1         0      1            0     1   \n",
       "news         0      0        1       1         0      1            0     1   \n",
       "pres         1      1        0       1         0      1            0     0   \n",
       "trump        2      1        1       1         1      1            1     0   \n",
       "wont         1      1        1       0         1      0            1     0   \n",
       "\n",
       "             hoax  liberal  medium  news  pres  trump  wont  \n",
       ".               1        1       0     0     1      2     1  \n",
       "<END>           1        1       0     0     1      1     1  \n",
       "<START>         1        2       1     1     0      1     1  \n",
       "always          0        1       1     1     1      1     0  \n",
       "anything        0        0       0     0     0      1     1  \n",
       "blame           0        0       1     1     1      1     0  \n",
       "coronavirus     1        1       0     0     0      1     1  \n",
       "fake            1        2       1     1     0      0     0  \n",
       "hoax            0        1       0     0     0      0     0  \n",
       "liberal         1        0       1     1     0      0     0  \n",
       "medium          0        1       0     1     1      1     0  \n",
       "news            0        1       1     0     1      0     0  \n",
       "pres            0        0       1     1     0      1     0  \n",
       "trump           0        0       1     0     1      0     1  \n",
       "wont            0        0       0     0     0      1     0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cm.transform(tweets), index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <th>always</th>\n",
       "      <th>anything</th>\n",
       "      <th>blame</th>\n",
       "      <th>coronavirus</th>\n",
       "      <th>fake</th>\n",
       "      <th>hoax</th>\n",
       "      <th>liberal</th>\n",
       "      <th>medium</th>\n",
       "      <th>news</th>\n",
       "      <th>pres</th>\n",
       "      <th>trump</th>\n",
       "      <th>wont</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>always</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anything</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blame</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronavirus</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fake</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoax</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pres</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wont</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             .  <END>  <START>  always  anything  blame  coronavirus  fake  \\\n",
       ".            0      3        0       1         1      1            2     1   \n",
       "<END>        3      0        0       0         1      1            1     1   \n",
       "<START>      0      0        0       0         1      0            2     2   \n",
       "always       1      0        0       0         0      1            0     1   \n",
       "anything     1      1        1       0         0      0            1     0   \n",
       "blame        1      1        0       1         0      0            0     1   \n",
       "coronavirus  2      1        2       0         1      0            0     1   \n",
       "fake         1      1        2       1         0      1            1     0   \n",
       "hoax         1      1        1       0         0      0            1     1   \n",
       "liberal      1      1        2       1         0      0            1     2   \n",
       "medium       0      0        1       1         0      1            0     1   \n",
       "news         0      0        1       1         0      1            0     1   \n",
       "pres         1      1        0       1         0      1            0     0   \n",
       "trump        2      1        1       1         1      1            1     0   \n",
       "wont         1      1        1       0         1      0            1     0   \n",
       "\n",
       "             hoax  liberal  medium  news  pres  trump  wont  \n",
       ".               1        1       0     0     1      2     1  \n",
       "<END>           1        1       0     0     1      1     1  \n",
       "<START>         1        2       1     1     0      1     1  \n",
       "always          0        1       1     1     1      1     0  \n",
       "anything        0        0       0     0     0      1     1  \n",
       "blame           0        0       1     1     1      1     0  \n",
       "coronavirus     1        1       0     0     0      1     1  \n",
       "fake            1        2       1     1     0      0     0  \n",
       "hoax            0        1       0     0     0      0     0  \n",
       "liberal         1        0       1     1     0      0     0  \n",
       "medium          0        1       0     1     1      1     0  \n",
       "news            0        1       1     0     1      0     0  \n",
       "pres            0        0       1     1     0      1     0  \n",
       "trump           0        0       1     0     1      0     1  \n",
       "wont            0        0       0     0     0      1     0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cm.transform(tweets), index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coronavirus fake liberal hoax.',\n",
       " 'trump wont anything coronavirus.',\n",
       " 'liberal fake news medium always blame pres trump.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.clean_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coronavirus is a fake liberal hoax.',\n",
       " \"Trump won't do anything about coronavirus.\",\n",
       " 'The liberal fake news media always blame Pres Trump.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train embeddings using tweets as corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('COVID19_Dataset-text_labels_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Unreliable</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 3, 6, 9</td>\n",
       "      <td>We are living in scary times in Canada. Gov’t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 6, 8, 9</td>\n",
       "      <td>Just as bad in Canada. In fact, our government...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 4, 9</td>\n",
       "      <td>It was only a matter of time before the mainst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8</td>\n",
       "      <td>Russia's taking no chances: Foreigners infecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8, 9</td>\n",
       "      <td>Although there is now a presumptive confirmed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BREAKING: Harvard classes will move online sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singularity University is hosting a FREE Virtu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus: how does it spread and what are t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stanford just cancelled classes for the rest o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tech conferences were cancelled in #Waterloo R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Is_Unreliable    Category  \\\n",
       "0                1  1, 3, 6, 9   \n",
       "1                1  1, 6, 8, 9   \n",
       "2                1     1, 4, 9   \n",
       "3                1        6, 8   \n",
       "4                1     6, 8, 9   \n",
       "..             ...         ...   \n",
       "555              0         NaN   \n",
       "556              0         NaN   \n",
       "557              0         NaN   \n",
       "558              0         NaN   \n",
       "559              0         NaN   \n",
       "\n",
       "                                                 Tweet  \n",
       "0    We are living in scary times in Canada. Gov’t ...  \n",
       "1    Just as bad in Canada. In fact, our government...  \n",
       "2    It was only a matter of time before the mainst...  \n",
       "3    Russia's taking no chances: Foreigners infecte...  \n",
       "4    Although there is now a presumptive confirmed ...  \n",
       "..                                                 ...  \n",
       "555  BREAKING: Harvard classes will move online sta...  \n",
       "556  Singularity University is hosting a FREE Virtu...  \n",
       "557  Coronavirus: how does it spread and what are t...  \n",
       "558  Stanford just cancelled classes for the rest o...  \n",
       "559  Tech conferences were cancelled in #Waterloo R...  \n",
       "\n",
       "[560 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(window_size = 15, lowercase = True, lemmatize = True, pmi = True, laplace_smoothing = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ContextMatrix at 0x1a1f199910>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.fit(tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_context_matrix = cm.transform(tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>#</th>\n",
       "      <th>,</th>\n",
       "      <th>-</th>\n",
       "      <th>--</th>\n",
       "      <th>.</th>\n",
       "      <th>...</th>\n",
       "      <th>1</th>\n",
       "      <th>1,600</th>\n",
       "      <th>1,975</th>\n",
       "      <th>...</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoomer</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>—</th>\n",
       "      <th>‘</th>\n",
       "      <th>’</th>\n",
       "      <th>“</th>\n",
       "      <th>”</th>\n",
       "      <th>❝real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>4.032835</td>\n",
       "      <td>1.783085</td>\n",
       "      <td>1.078992</td>\n",
       "      <td>0.781164</td>\n",
       "      <td>-0.421772</td>\n",
       "      <td>1.988385</td>\n",
       "      <td>1.648172</td>\n",
       "      <td>0.959143</td>\n",
       "      <td>-0.391441</td>\n",
       "      <td>-0.391013</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.392723</td>\n",
       "      <td>-0.402923</td>\n",
       "      <td>-0.393150</td>\n",
       "      <td>-0.389300</td>\n",
       "      <td>0.269717</td>\n",
       "      <td>-0.436599</td>\n",
       "      <td>2.408141</td>\n",
       "      <td>1.634069</td>\n",
       "      <td>0.579646</td>\n",
       "      <td>0.299143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>1.783085</td>\n",
       "      <td>3.972184</td>\n",
       "      <td>2.474860</td>\n",
       "      <td>1.535179</td>\n",
       "      <td>0.109099</td>\n",
       "      <td>2.870653</td>\n",
       "      <td>-0.593546</td>\n",
       "      <td>-0.589428</td>\n",
       "      <td>-1.246864</td>\n",
       "      <td>-1.246436</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.248146</td>\n",
       "      <td>-0.565199</td>\n",
       "      <td>-0.555426</td>\n",
       "      <td>-1.244723</td>\n",
       "      <td>-0.180241</td>\n",
       "      <td>0.317416</td>\n",
       "      <td>2.310404</td>\n",
       "      <td>0.373180</td>\n",
       "      <td>0.235048</td>\n",
       "      <td>-1.249427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>1.078992</td>\n",
       "      <td>2.474860</td>\n",
       "      <td>2.918123</td>\n",
       "      <td>1.349384</td>\n",
       "      <td>0.577230</td>\n",
       "      <td>2.802958</td>\n",
       "      <td>0.344589</td>\n",
       "      <td>0.571851</td>\n",
       "      <td>-1.001877</td>\n",
       "      <td>-1.001449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383135</td>\n",
       "      <td>-0.320212</td>\n",
       "      <td>-1.003586</td>\n",
       "      <td>-0.999736</td>\n",
       "      <td>0.064746</td>\n",
       "      <td>0.339260</td>\n",
       "      <td>2.225150</td>\n",
       "      <td>1.598997</td>\n",
       "      <td>1.067823</td>\n",
       "      <td>-1.004440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>0.781164</td>\n",
       "      <td>1.535179</td>\n",
       "      <td>1.349384</td>\n",
       "      <td>2.529658</td>\n",
       "      <td>-0.231423</td>\n",
       "      <td>1.536880</td>\n",
       "      <td>0.452226</td>\n",
       "      <td>-0.236802</td>\n",
       "      <td>-0.201092</td>\n",
       "      <td>-0.200664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.202374</td>\n",
       "      <td>-0.212574</td>\n",
       "      <td>0.490346</td>\n",
       "      <td>-0.198951</td>\n",
       "      <td>-0.233081</td>\n",
       "      <td>-0.246250</td>\n",
       "      <td>1.143203</td>\n",
       "      <td>1.013488</td>\n",
       "      <td>0.769995</td>\n",
       "      <td>-0.203655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--</th>\n",
       "      <td>-0.421772</td>\n",
       "      <td>0.109099</td>\n",
       "      <td>0.577230</td>\n",
       "      <td>-0.231423</td>\n",
       "      <td>-0.048064</td>\n",
       "      <td>0.110800</td>\n",
       "      <td>-0.057563</td>\n",
       "      <td>-0.053444</td>\n",
       "      <td>-0.017733</td>\n",
       "      <td>-0.017306</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019016</td>\n",
       "      <td>-0.029215</td>\n",
       "      <td>-0.019443</td>\n",
       "      <td>-0.015592</td>\n",
       "      <td>-0.049723</td>\n",
       "      <td>-0.062891</td>\n",
       "      <td>-0.619348</td>\n",
       "      <td>0.503699</td>\n",
       "      <td>0.547889</td>\n",
       "      <td>-0.020296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>-0.436599</td>\n",
       "      <td>0.317416</td>\n",
       "      <td>0.339260</td>\n",
       "      <td>-0.246250</td>\n",
       "      <td>-0.062891</td>\n",
       "      <td>0.319116</td>\n",
       "      <td>-0.072390</td>\n",
       "      <td>-0.068271</td>\n",
       "      <td>-0.032561</td>\n",
       "      <td>-0.032133</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033843</td>\n",
       "      <td>-0.044043</td>\n",
       "      <td>-0.034270</td>\n",
       "      <td>-0.030420</td>\n",
       "      <td>-0.064550</td>\n",
       "      <td>-0.077719</td>\n",
       "      <td>1.668409</td>\n",
       "      <td>-0.204276</td>\n",
       "      <td>-0.160086</td>\n",
       "      <td>-0.035124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>2.408141</td>\n",
       "      <td>2.310404</td>\n",
       "      <td>2.225150</td>\n",
       "      <td>1.143203</td>\n",
       "      <td>-0.619348</td>\n",
       "      <td>2.619130</td>\n",
       "      <td>1.162913</td>\n",
       "      <td>-0.624728</td>\n",
       "      <td>-0.589018</td>\n",
       "      <td>-0.588590</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.590300</td>\n",
       "      <td>-0.600500</td>\n",
       "      <td>-0.590727</td>\n",
       "      <td>-0.586877</td>\n",
       "      <td>-0.621007</td>\n",
       "      <td>1.668409</td>\n",
       "      <td>2.920241</td>\n",
       "      <td>1.878325</td>\n",
       "      <td>1.848406</td>\n",
       "      <td>0.101567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“</th>\n",
       "      <td>1.634069</td>\n",
       "      <td>0.373180</td>\n",
       "      <td>1.598997</td>\n",
       "      <td>1.013488</td>\n",
       "      <td>0.503699</td>\n",
       "      <td>1.473493</td>\n",
       "      <td>0.494200</td>\n",
       "      <td>0.498319</td>\n",
       "      <td>-0.159118</td>\n",
       "      <td>-0.158690</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.160400</td>\n",
       "      <td>-0.170600</td>\n",
       "      <td>-0.160827</td>\n",
       "      <td>-0.156977</td>\n",
       "      <td>0.502040</td>\n",
       "      <td>-0.204276</td>\n",
       "      <td>1.878325</td>\n",
       "      <td>1.278605</td>\n",
       "      <td>2.757879</td>\n",
       "      <td>-0.161681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>”</th>\n",
       "      <td>0.579646</td>\n",
       "      <td>0.235048</td>\n",
       "      <td>1.067823</td>\n",
       "      <td>0.769995</td>\n",
       "      <td>0.547889</td>\n",
       "      <td>1.266369</td>\n",
       "      <td>0.538390</td>\n",
       "      <td>-0.150638</td>\n",
       "      <td>-0.114928</td>\n",
       "      <td>-0.114500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.116210</td>\n",
       "      <td>-0.126410</td>\n",
       "      <td>-0.116637</td>\n",
       "      <td>-0.112787</td>\n",
       "      <td>0.546230</td>\n",
       "      <td>-0.160086</td>\n",
       "      <td>1.848406</td>\n",
       "      <td>2.757879</td>\n",
       "      <td>1.954771</td>\n",
       "      <td>-0.117491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>❝real</th>\n",
       "      <td>0.299143</td>\n",
       "      <td>-1.249427</td>\n",
       "      <td>-1.004440</td>\n",
       "      <td>-0.203655</td>\n",
       "      <td>-0.020296</td>\n",
       "      <td>-1.247726</td>\n",
       "      <td>-0.029795</td>\n",
       "      <td>-0.025676</td>\n",
       "      <td>0.010035</td>\n",
       "      <td>0.010462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008752</td>\n",
       "      <td>-0.001448</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>0.012175</td>\n",
       "      <td>-0.021955</td>\n",
       "      <td>-0.035124</td>\n",
       "      <td>0.101567</td>\n",
       "      <td>-0.161681</td>\n",
       "      <td>-0.117491</td>\n",
       "      <td>0.007472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2323 rows × 2323 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              !         #         ,         -        --         .       ...  \\\n",
       "!      4.032835  1.783085  1.078992  0.781164 -0.421772  1.988385  1.648172   \n",
       "#      1.783085  3.972184  2.474860  1.535179  0.109099  2.870653 -0.593546   \n",
       ",      1.078992  2.474860  2.918123  1.349384  0.577230  2.802958  0.344589   \n",
       "-      0.781164  1.535179  1.349384  2.529658 -0.231423  1.536880  0.452226   \n",
       "--    -0.421772  0.109099  0.577230 -0.231423 -0.048064  0.110800 -0.057563   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "‘     -0.436599  0.317416  0.339260 -0.246250 -0.062891  0.319116 -0.072390   \n",
       "’      2.408141  2.310404  2.225150  1.143203 -0.619348  2.619130  1.162913   \n",
       "“      1.634069  0.373180  1.598997  1.013488  0.503699  1.473493  0.494200   \n",
       "”      0.579646  0.235048  1.067823  0.769995  0.547889  1.266369  0.538390   \n",
       "❝real  0.299143 -1.249427 -1.004440 -0.203655 -0.020296 -1.247726 -0.029795   \n",
       "\n",
       "              1     1,600     1,975  ...    zombie      zone    zoomer  \\\n",
       "!      0.959143 -0.391441 -0.391013  ... -0.392723 -0.402923 -0.393150   \n",
       "#     -0.589428 -1.246864 -1.246436  ... -1.248146 -0.565199 -0.555426   \n",
       ",      0.571851 -1.001877 -1.001449  ...  0.383135 -0.320212 -1.003586   \n",
       "-     -0.236802 -0.201092 -0.200664  ... -0.202374 -0.212574  0.490346   \n",
       "--    -0.053444 -0.017733 -0.017306  ... -0.019016 -0.029215 -0.019443   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "‘     -0.068271 -0.032561 -0.032133  ... -0.033843 -0.044043 -0.034270   \n",
       "’     -0.624728 -0.589018 -0.588590  ... -0.590300 -0.600500 -0.590727   \n",
       "“      0.498319 -0.159118 -0.158690  ... -0.160400 -0.170600 -0.160827   \n",
       "”     -0.150638 -0.114928 -0.114500  ... -0.116210 -0.126410 -0.116637   \n",
       "❝real -0.025676  0.010035  0.010462  ...  0.008752 -0.001448  0.008325   \n",
       "\n",
       "       zuckerberg         —         ‘         ’         “         ”     ❝real  \n",
       "!       -0.389300  0.269717 -0.436599  2.408141  1.634069  0.579646  0.299143  \n",
       "#       -1.244723 -0.180241  0.317416  2.310404  0.373180  0.235048 -1.249427  \n",
       ",       -0.999736  0.064746  0.339260  2.225150  1.598997  1.067823 -1.004440  \n",
       "-       -0.198951 -0.233081 -0.246250  1.143203  1.013488  0.769995 -0.203655  \n",
       "--      -0.015592 -0.049723 -0.062891 -0.619348  0.503699  0.547889 -0.020296  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "‘       -0.030420 -0.064550 -0.077719  1.668409 -0.204276 -0.160086 -0.035124  \n",
       "’       -0.586877 -0.621007  1.668409  2.920241  1.878325  1.848406  0.101567  \n",
       "“       -0.156977  0.502040 -0.204276  1.878325  1.278605  2.757879 -0.161681  \n",
       "”       -0.112787  0.546230 -0.160086  1.848406  2.757879  1.954771 -0.117491  \n",
       "❝real    0.012175 -0.021955 -0.035124  0.101567 -0.161681 -0.117491  0.007472  \n",
       "\n",
       "[2323 rows x 2323 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(word_context_matrix, index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2323, 2323)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_context_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = FastICA(n_components = 2)\n",
    "std_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.11757778, -0.06243962],\n",
       "       [-0.66041863,  0.64883245],\n",
       "       [-0.17797362, -0.3456496 ],\n",
       "       ...,\n",
       "       [-0.03053962, -0.067334  ],\n",
       "       [-0.02231178, -0.04882103],\n",
       "       [ 0.00308632,  0.00284792]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std = std_scaler.fit_transform(word_context_matrix)\n",
    "\n",
    "matrix = ica.fit_transform(X_std)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comp 1</th>\n",
       "      <th>Comp 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>-0.117578</td>\n",
       "      <td>-0.062440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>-0.660419</td>\n",
       "      <td>0.648832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>-0.177974</td>\n",
       "      <td>-0.345650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>-0.054613</td>\n",
       "      <td>-0.051800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--</th>\n",
       "      <td>-0.001185</td>\n",
       "      <td>-0.011083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>-0.007010</td>\n",
       "      <td>-0.011921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>-0.145875</td>\n",
       "      <td>-0.132536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“</th>\n",
       "      <td>-0.030540</td>\n",
       "      <td>-0.067334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>”</th>\n",
       "      <td>-0.022312</td>\n",
       "      <td>-0.048821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>❝real</th>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.002848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2323 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Comp 1    Comp 2\n",
       "!     -0.117578 -0.062440\n",
       "#     -0.660419  0.648832\n",
       ",     -0.177974 -0.345650\n",
       "-     -0.054613 -0.051800\n",
       "--    -0.001185 -0.011083\n",
       "...         ...       ...\n",
       "‘     -0.007010 -0.011921\n",
       "’     -0.145875 -0.132536\n",
       "“     -0.030540 -0.067334\n",
       "”     -0.022312 -0.048821\n",
       "❝real  0.003086  0.002848\n",
       "\n",
       "[2323 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(matrix,\n",
    "                  index = cm.vocabulary,\n",
    "                  columns = ['Comp {}'.format(i+1) for i in range(2)])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 62222 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 62222 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = [key for key in cm.vocabulary.keys()]\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    \n",
    "    #if re.match('^co[rv]', word):\n",
    "    \n",
    "        x = df['Comp 1'][i]\n",
    "        y = df['Comp 2'][i]\n",
    "\n",
    "        plt.scatter(x, y)\n",
    "        plt.text(x, y, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set word embeddings for text classification\n",
    "ica = FastICA(n_components = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00779803, -0.00726506,  0.00225473, ...,  0.00558108,\n",
       "         0.0172869 , -0.00522129],\n",
       "       [ 0.00145591,  0.00045756, -0.00854115, ..., -0.00037973,\n",
       "        -0.003826  , -0.00555393],\n",
       "       [ 0.0088351 , -0.00099645, -0.0036743 , ...,  0.00197031,\n",
       "         0.00044117,  0.00778231],\n",
       "       ...,\n",
       "       [ 0.01514471, -0.01748738, -0.00585052, ...,  0.02471021,\n",
       "         0.00997192,  0.00222164],\n",
       "       [-0.01831722,  0.0010355 ,  0.00055172, ..., -0.01765762,\n",
       "         0.00017632, -0.01079781],\n",
       "       [ 0.01008351, -0.02014355, -0.00181666, ...,  0.00212127,\n",
       "        -0.00573326, -0.00753083]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = ica.fit_transform(X_std)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean text - all lowercase & remove stopwords\n",
    "def clean_text(str_list):\n",
    "    \n",
    "    clean_list = []\n",
    "    \n",
    "    for text in str_list:\n",
    "            \n",
    "        words = word_tokenize(text)\n",
    "\n",
    "        clean_words = []\n",
    "        for word in words:\n",
    "            if word.lower() not in set(stopwords.words('english')):\n",
    "                clean_words.append(word.lower())\n",
    "        words = clean_words\n",
    "\n",
    "        clean_text = ' '.join(clean_words)\n",
    "        clean_list.append(clean_text)\n",
    "        \n",
    "    return clean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run on all tweets\n",
    "tweets['clean_tweet'] = clean_text(tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out target\n",
    "y = tweets['Is_Unreliable']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derive text vectors from word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_vectors(word_embeddings, word_index_dict, text_list):\n",
    "    for k in range(len(text_list)):\n",
    "        text = text_list[k]\n",
    "        text_vec = np.zeros(word_embeddings.shape[1])\n",
    "        words = word_tokenize(text)\n",
    "        \n",
    "        for i in range(len(words)):\n",
    "            word = words[i]\n",
    "            if word in word_index_dict:\n",
    "                word_embed_vec = word_embeddings[word_index_dict[word],:]\n",
    "                if i == 0:\n",
    "                    text_matrix = word_embed_vec\n",
    "                else:\n",
    "                    text_matrix = np.vstack((text_matrix, word_embed_vec))\n",
    "                    \n",
    "        for j in range(len(text_vec)):\n",
    "            text_vec[j] = text_matrix[:,j].mean()\n",
    "            \n",
    "        if k == 0:\n",
    "            full_matrix = text_vec\n",
    "        else:\n",
    "            full_matrix = np.vstack((full_matrix, text_vec))\n",
    "            \n",
    "    return full_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_text_vectors(embeddings, cm.vocabulary, tweets['clean_tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 150)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00703499,  0.0700423 , -0.00430676, ...,  0.00754241,\n",
       "        -0.00205674, -0.01024147],\n",
       "       [-0.0020079 ,  0.06051914,  0.00756464, ...,  0.00181369,\n",
       "         0.01414261, -0.00571375],\n",
       "       [ 0.01447704, -0.02756221, -0.00627871, ...,  0.01188008,\n",
       "         0.02050197,  0.00611035],\n",
       "       ...,\n",
       "       [ 0.00780898, -0.00986981, -0.00220895, ...,  0.0033921 ,\n",
       "        -0.01210752, -0.00706796],\n",
       "       [-0.00040272, -0.00586639, -0.00057376, ..., -0.00359435,\n",
       "         0.00111324, -0.00026235],\n",
       "       [-0.02061265,  0.02171845,  0.00321622, ..., -0.00687031,\n",
       "        -0.0027044 , -0.00053498]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, KFold, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipe = Pipeline([\n",
    "    ('classify', SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC hyperparams to optimize\n",
    "kernel = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "C = [0.001, 0.01, 0.1, 1, 10]\n",
    "# set up parameter grid\n",
    "params = {\n",
    "    'classify__kernel': kernel,\n",
    "    'classify__C': C\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CV scheme for inner and outer loops\n",
    "inner_cv = KFold(n_splits = 3, shuffle = True, random_state = 1)\n",
    "outer_cv = KFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "\n",
    "# Set up GridSearch for inner loop\n",
    "grid_SVC = GridSearchCV(pipe, params, cv = inner_cv)\n",
    "#grid_SVC.fit(X, y)\n",
    "\n",
    "# Nested CV scores\n",
    "scores = cross_validate(grid_SVC,\n",
    "                        X = X,\n",
    "                        y = y,\n",
    "                        cv = outer_cv,\n",
    "                        scoring = ['roc_auc', 'accuracy', 'f1', 'precision', 'recall'],\n",
    "                        return_estimator = True)\n",
    "auc = scores['test_roc_auc']\n",
    "accuracy = scores['test_accuracy']\n",
    "f1 = scores['test_f1']\n",
    "precision = scores['test_precision']\n",
    "recall = scores['test_recall']\n",
    "estimators = scores['estimator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9279804849100504"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8535714285714284"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8582388270237693"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.835295960991178"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.883683254747037"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classify__C': 10, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 10, 'classify__kernel': 'linear'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 10, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in estimators:\n",
    "    print(i.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
