{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Word Context Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.decomposition import FastICA, TruncatedSVD, PCA, NMF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert contractions picked up by word_tokenize() into full words\n",
    "contractions = {\n",
    "    \"n't\": 'not',\n",
    "    \"'ve\": 'have',\n",
    "    \"'s\": 'is', # note that this will include possessive nouns\n",
    "    'gonna': 'going to',\n",
    "    'gotta': 'got to',\n",
    "    \"'d\": 'would',\n",
    "    \"'ll\": 'will',\n",
    "    \"'re\": 'are',\n",
    "    \"'m\": 'am',\n",
    "    'wanna': 'want to'\n",
    "}\n",
    "\n",
    "# to convert nltk_pos tags to wordnet-compatible PoS tags\n",
    "def convert_pos_wordnet(tag):\n",
    "    tag_abbr = tag[0].upper()\n",
    "    tag_dict = {\n",
    "        'J': wordnet.ADJ,\n",
    "        'N': wordnet.NOUN,\n",
    "        'V': wordnet.VERB,\n",
    "        'R': wordnet.ADV\n",
    "    }\n",
    "                \n",
    "    if tag_abbr in tag_dict:\n",
    "        return tag_dict[tag_abbr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextMatrix(TransformerMixin):\n",
    "    \n",
    "    # initialize class & private variables\n",
    "    def __init__(self,\n",
    "                 window_size = 4,\n",
    "                 remove_stopwords = True,\n",
    "                 add_start_end_tokens = True,\n",
    "                 lowercase = False,\n",
    "                 lemmatize = False,\n",
    "                 pmi = False,\n",
    "                 spmi_k = 1,\n",
    "                 laplace_smoothing = 0,\n",
    "                 pmi_positive = False,\n",
    "                 sppmi_k = 1):\n",
    "        \n",
    "        \"\"\" Params:\n",
    "                window_size: size of +/- context window (default = 4)\n",
    "                remove_stopwords: boolean, whether or not to remove NLTK English stopwords\n",
    "                add_start_end_tokens: boolean, whether or not to append <START> and <END> to the\n",
    "                beginning/end of each document in the corpus (default = True)\n",
    "                lowercase: boolean, whether or not to convert words to all lowercase\n",
    "                lemmatize: boolean, whether or not to lemmatize input text\n",
    "                pmi: boolean, whether or not to compute pointwise mutual information\n",
    "                pmi_positive: boolean, whether or not to compute positive PMI\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.add_start_end_tokens = add_start_end_tokens\n",
    "        self.lowercase = lowercase\n",
    "        self.lemmatize = lemmatize\n",
    "        self.pmi = pmi\n",
    "        self.spmi_k = spmi_k\n",
    "        self.laplace_smoothing = laplace_smoothing\n",
    "        self.pmi_positive = pmi_positive\n",
    "        self.sppmi_k = sppmi_k\n",
    "        self.corpus = None\n",
    "        self.clean_corpus = None\n",
    "        self.vocabulary = None\n",
    "        self.X = None\n",
    "        self.doc_terms_lists = None\n",
    "    \n",
    "    def fit(self, corpus, y = None):\n",
    "        \n",
    "        \"\"\" Learn the dictionary of all unique tokens for given corpus.\n",
    "        \n",
    "            Params:\n",
    "                corpus: list of strings\n",
    "            \n",
    "            Returns: self\n",
    "        \"\"\"\n",
    "        self.corpus = corpus\n",
    "        \n",
    "        term_dict = dict()\n",
    "        k = 0\n",
    "        corpus_words = []\n",
    "        clean_corpus = []\n",
    "        doc_terms_lists = []\n",
    "        detokenizer = TreebankWordDetokenizer()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        for text in corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "            \n",
    "            # detokenize trick taken from this StackOverflow post:\n",
    "            # https://stackoverflow.com/questions/21948019/python-untokenize-a-sentence\n",
    "            # and NLTK treebank documentation:\n",
    "            # https://www.nltk.org/_modules/nltk/tokenize/treebank.html\n",
    "            text = detokenizer.detokenize(words)\n",
    "            clean_corpus.append(text)\n",
    "            \n",
    "            [corpus_words.append(word) for word in words]\n",
    "            \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            doc_terms_lists.append(words)\n",
    "            \n",
    "        self.clean_corpus = clean_corpus\n",
    "        \n",
    "        self.doc_terms_lists = doc_terms_lists\n",
    "        \n",
    "        corpus_words = list(set(corpus_words))\n",
    "        \n",
    "        if self.add_start_end_tokens:\n",
    "            corpus_words = ['<START>'] + corpus_words + ['<END>']\n",
    "        \n",
    "        corpus_words = sorted(corpus_words)\n",
    "        \n",
    "        for el in corpus_words:\n",
    "            term_dict[el] = k\n",
    "            k += 1\n",
    "            \n",
    "        self.vocabulary = term_dict\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def transform(self, new_corpus = None, y = None):\n",
    "        \n",
    "        \"\"\" Compute the co-occurrence matrix for given corpus and window_size, using term dictionary\n",
    "            obtained with fit method.\n",
    "        \n",
    "            Returns: term-context co-occurrence matrix (shape: target terms by context terms) with\n",
    "            raw counts\n",
    "        \"\"\"\n",
    "        num_terms = len(self.vocabulary)\n",
    "        window = self.window_size\n",
    "        X = np.full((num_terms, num_terms), self.laplace_smoothing)\n",
    "        \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        if type(new_corpus) != list:\n",
    "            new_corpus = self.corpus\n",
    "        \n",
    "        for text in new_corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            for i in range(len(words)):\n",
    "                target = words[i]\n",
    "                \n",
    "                # check to see if target word is in the dictionary; if not, skip\n",
    "                if target in self.vocabulary:\n",
    "                    \n",
    "                    # grab index from dictionary\n",
    "                    target_dict_index = self.vocabulary[target]\n",
    "                    \n",
    "                    # find left-most and right-most window indices for each target word\n",
    "                    left_end_index = max(i - window, 0)\n",
    "                    right_end_index = min(i + window, len(words) - 1)\n",
    "                    \n",
    "                    # loop over all words within window\n",
    "                    # NOTE: this will include the target word; make sure to skip over it\n",
    "                    for j in range(left_end_index, right_end_index + 1):\n",
    "                        \n",
    "                        # skip \"context word\" where the \"context word\" index is equal to the\n",
    "                        # target word index\n",
    "                        if j != i:\n",
    "                            context_word = words[j]\n",
    "                            \n",
    "                            # check to see if context word is in the fitted dictionary; if\n",
    "                            # not, skip\n",
    "                            if context_word in self.vocabulary:\n",
    "                                X[target_dict_index, self.vocabulary[context_word]] += 1\n",
    "        \n",
    "        # if pmi = True, compute pmi matrix from word-context raw frequencies\n",
    "        # more concise code taken from this StackOverflow post:\n",
    "        # https://stackoverflow.com/questions/58701337/how-to-construct-ppmi-matrix-from-a-text-corpus\n",
    "        if self.pmi:\n",
    "            denom = X.sum()\n",
    "            col_sums = X.sum(axis = 0)\n",
    "            row_sums = X.sum(axis = 1)\n",
    "            \n",
    "            expected = np.outer(row_sums, col_sums)/denom\n",
    "            \n",
    "            X = X/expected\n",
    "            \n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(X.shape[1]):\n",
    "                \n",
    "                    if X[i,j] > 0:\n",
    "                        X[i,j] = np.log(X[i,j]) - np.log(self.spmi_k)\n",
    "                        \n",
    "                        if self.pmi_positive:\n",
    "                            X[i,j] = max(X[i,j] - np.log(self.sppmi_k), 0)\n",
    "        \n",
    "        # note that X is a dense matrix\n",
    "        self.X = X\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(lowercase = True, lemmatize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [\n",
    "    \"Coronavirus is a fake liberal hoax.\",\n",
    "    \"Trump won't do anything about coronavirus.\",\n",
    "    \"The liberal fake news media always blame Pres Trump.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ContextMatrix at 0x1a18dac250>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.fit(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <th>always</th>\n",
       "      <th>anything</th>\n",
       "      <th>blame</th>\n",
       "      <th>coronavirus</th>\n",
       "      <th>fake</th>\n",
       "      <th>hoax</th>\n",
       "      <th>liberal</th>\n",
       "      <th>medium</th>\n",
       "      <th>news</th>\n",
       "      <th>pres</th>\n",
       "      <th>trump</th>\n",
       "      <th>wont</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>always</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anything</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blame</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronavirus</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fake</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoax</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pres</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wont</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             .  <END>  <START>  always  anything  blame  coronavirus  fake  \\\n",
       ".            0      3        0       1         1      1            2     1   \n",
       "<END>        3      0        0       0         1      1            1     1   \n",
       "<START>      0      0        0       0         1      0            2     2   \n",
       "always       1      0        0       0         0      1            0     1   \n",
       "anything     1      1        1       0         0      0            1     0   \n",
       "blame        1      1        0       1         0      0            0     1   \n",
       "coronavirus  2      1        2       0         1      0            0     1   \n",
       "fake         1      1        2       1         0      1            1     0   \n",
       "hoax         1      1        1       0         0      0            1     1   \n",
       "liberal      1      1        2       1         0      0            1     2   \n",
       "medium       0      0        1       1         0      1            0     1   \n",
       "news         0      0        1       1         0      1            0     1   \n",
       "pres         1      1        0       1         0      1            0     0   \n",
       "trump        2      1        1       1         1      1            1     0   \n",
       "wont         1      1        1       0         1      0            1     0   \n",
       "\n",
       "             hoax  liberal  medium  news  pres  trump  wont  \n",
       ".               1        1       0     0     1      2     1  \n",
       "<END>           1        1       0     0     1      1     1  \n",
       "<START>         1        2       1     1     0      1     1  \n",
       "always          0        1       1     1     1      1     0  \n",
       "anything        0        0       0     0     0      1     1  \n",
       "blame           0        0       1     1     1      1     0  \n",
       "coronavirus     1        1       0     0     0      1     1  \n",
       "fake            1        2       1     1     0      0     0  \n",
       "hoax            0        1       0     0     0      0     0  \n",
       "liberal         1        0       1     1     0      0     0  \n",
       "medium          0        1       0     1     1      1     0  \n",
       "news            0        1       1     0     1      0     0  \n",
       "pres            0        0       1     1     0      1     0  \n",
       "trump           0        0       1     0     1      0     1  \n",
       "wont            0        0       0     0     0      1     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cm.transform(tweets), index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coronavirus fake liberal hoax.',\n",
       " 'trump wont anything coronavirus.',\n",
       " 'liberal fake news medium always blame pres trump.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.clean_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coronavirus is a fake liberal hoax.',\n",
       " \"Trump won't do anything about coronavirus.\",\n",
       " 'The liberal fake news media always blame Pres Trump.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train embeddings using tweets as corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('COVID19_Dataset-text_labels_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Unreliable</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 3, 6, 9</td>\n",
       "      <td>We are living in scary times in Canada. Gov’t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 6, 8, 9</td>\n",
       "      <td>Just as bad in Canada. In fact, our government...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 4, 9</td>\n",
       "      <td>It was only a matter of time before the mainst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8</td>\n",
       "      <td>Russia's taking no chances: Foreigners infecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8, 9</td>\n",
       "      <td>Although there is now a presumptive confirmed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BREAKING: Harvard classes will move online sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singularity University is hosting a FREE Virtu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus: how does it spread and what are t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stanford just cancelled classes for the rest o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tech conferences were cancelled in #Waterloo R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Is_Unreliable    Category  \\\n",
       "0                1  1, 3, 6, 9   \n",
       "1                1  1, 6, 8, 9   \n",
       "2                1     1, 4, 9   \n",
       "3                1        6, 8   \n",
       "4                1     6, 8, 9   \n",
       "..             ...         ...   \n",
       "555              0         NaN   \n",
       "556              0         NaN   \n",
       "557              0         NaN   \n",
       "558              0         NaN   \n",
       "559              0         NaN   \n",
       "\n",
       "                                                 Tweet  \n",
       "0    We are living in scary times in Canada. Gov’t ...  \n",
       "1    Just as bad in Canada. In fact, our government...  \n",
       "2    It was only a matter of time before the mainst...  \n",
       "3    Russia's taking no chances: Foreigners infecte...  \n",
       "4    Although there is now a presumptive confirmed ...  \n",
       "..                                                 ...  \n",
       "555  BREAKING: Harvard classes will move online sta...  \n",
       "556  Singularity University is hosting a FREE Virtu...  \n",
       "557  Coronavirus: how does it spread and what are t...  \n",
       "558  Stanford just cancelled classes for the rest o...  \n",
       "559  Tech conferences were cancelled in #Waterloo R...  \n",
       "\n",
       "[560 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(window_size = 15, lowercase = True, lemmatize = True, pmi = True, spmi_k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ContextMatrix at 0x1a208e9ad0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.fit(tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_context_matrix = cm.transform(tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>#</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>,</th>\n",
       "      <th>-</th>\n",
       "      <th>--</th>\n",
       "      <th>.</th>\n",
       "      <th>...</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoomer</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>—</th>\n",
       "      <th>‘</th>\n",
       "      <th>’</th>\n",
       "      <th>“</th>\n",
       "      <th>”</th>\n",
       "      <th>❝real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>0.921891</td>\n",
       "      <td>-2.112382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.093170</td>\n",
       "      <td>-2.851110</td>\n",
       "      <td>-2.079986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.901818</td>\n",
       "      <td>0.401442</td>\n",
       "      <td>-0.332527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.336828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.033232</td>\n",
       "      <td>-0.862420</td>\n",
       "      <td>-1.940964</td>\n",
       "      <td>0.129509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>-2.112382</td>\n",
       "      <td>-0.651796</td>\n",
       "      <td>-2.478344</td>\n",
       "      <td>-2.511134</td>\n",
       "      <td>-2.041496</td>\n",
       "      <td>-1.849348</td>\n",
       "      <td>-1.808454</td>\n",
       "      <td>-1.757287</td>\n",
       "      <td>-3.159657</td>\n",
       "      <td>-3.046328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.178828</td>\n",
       "      <td>-1.385597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.258870</td>\n",
       "      <td>-1.867048</td>\n",
       "      <td>-1.872582</td>\n",
       "      <td>-2.947612</td>\n",
       "      <td>-2.863006</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.478344</td>\n",
       "      <td>-1.529221</td>\n",
       "      <td>1.210578</td>\n",
       "      <td>-1.750735</td>\n",
       "      <td>-2.340587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.841512</td>\n",
       "      <td>-0.706457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.176222</td>\n",
       "      <td>-2.103850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>-3.093170</td>\n",
       "      <td>-2.511134</td>\n",
       "      <td>1.210578</td>\n",
       "      <td>-1.594801</td>\n",
       "      <td>-1.783524</td>\n",
       "      <td>-2.373377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.711783</td>\n",
       "      <td>-0.739246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.209012</td>\n",
       "      <td>-2.136640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>-2.851110</td>\n",
       "      <td>-2.041496</td>\n",
       "      <td>-1.750735</td>\n",
       "      <td>-1.783524</td>\n",
       "      <td>-1.481746</td>\n",
       "      <td>-1.948996</td>\n",
       "      <td>-1.160887</td>\n",
       "      <td>-1.711795</td>\n",
       "      <td>-1.701160</td>\n",
       "      <td>-1.300149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126967</td>\n",
       "      <td>-1.818943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.898986</td>\n",
       "      <td>-1.794845</td>\n",
       "      <td>-1.849169</td>\n",
       "      <td>-1.489115</td>\n",
       "      <td>-1.809974</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.867048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.794845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.866204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>-1.033232</td>\n",
       "      <td>-1.872582</td>\n",
       "      <td>-2.176222</td>\n",
       "      <td>-2.209012</td>\n",
       "      <td>-1.849169</td>\n",
       "      <td>-1.888975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.560525</td>\n",
       "      <td>-0.437166</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056935</td>\n",
       "      <td>-0.808319</td>\n",
       "      <td>-0.879048</td>\n",
       "      <td>-0.651341</td>\n",
       "      <td>-0.372628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“</th>\n",
       "      <td>-0.862420</td>\n",
       "      <td>-2.947612</td>\n",
       "      <td>-2.103850</td>\n",
       "      <td>-2.136640</td>\n",
       "      <td>-1.489115</td>\n",
       "      <td>-1.123456</td>\n",
       "      <td>-0.335347</td>\n",
       "      <td>-1.722993</td>\n",
       "      <td>-0.587938</td>\n",
       "      <td>-0.474609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.380299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.879048</td>\n",
       "      <td>-0.599037</td>\n",
       "      <td>1.318151</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>”</th>\n",
       "      <td>-1.940964</td>\n",
       "      <td>-2.863006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.809974</td>\n",
       "      <td>-1.221172</td>\n",
       "      <td>-0.027598</td>\n",
       "      <td>-1.683507</td>\n",
       "      <td>-0.280188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.072549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.651341</td>\n",
       "      <td>1.318151</td>\n",
       "      <td>0.709610</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>❝real</th>\n",
       "      <td>0.129509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.372628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2325 rows × 2325 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              !         #         (         )         ,         -        --  \\\n",
       "!      0.921891 -2.112382  0.000000 -3.093170 -2.851110 -2.079986  0.000000   \n",
       "#     -2.112382 -0.651796 -2.478344 -2.511134 -2.041496 -1.849348 -1.808454   \n",
       "(      0.000000 -2.478344 -1.529221  1.210578 -1.750735 -2.340587  0.000000   \n",
       ")     -3.093170 -2.511134  1.210578 -1.594801 -1.783524 -2.373377  0.000000   \n",
       ",     -2.851110 -2.041496 -1.750735 -1.783524 -1.481746 -1.948996 -1.160887   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "‘      0.000000 -1.867048  0.000000  0.000000 -1.794845  0.000000  0.000000   \n",
       "’     -1.033232 -1.872582 -2.176222 -2.209012 -1.849169 -1.888975  0.000000   \n",
       "“     -0.862420 -2.947612 -2.103850 -2.136640 -1.489115 -1.123456 -0.335347   \n",
       "”     -1.940964 -2.863006  0.000000  0.000000 -1.809974 -1.221172 -0.027598   \n",
       "❝real  0.129509  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "              .       ...         1  ...    zombie      zone    zoomer  \\\n",
       "!     -1.901818  0.401442 -0.332527  ...  0.000000  0.000000  0.000000   \n",
       "#     -1.757287 -3.159657 -3.046328  ...  0.000000 -2.178828 -1.385597   \n",
       "(     -1.841512 -0.706457  0.000000  ...  0.000000  0.000000  0.000000   \n",
       ")     -1.711783 -0.739246  0.000000  ...  0.000000  0.000000  0.000000   \n",
       ",     -1.711795 -1.701160 -1.300149  ...  0.126967 -1.818943  0.000000   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "‘     -1.866204  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "’     -1.560525 -0.437166  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "“     -1.722993 -0.587938 -0.474609  ...  0.000000  0.000000  0.000000   \n",
       "”     -1.683507 -0.280188  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "❝real  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "\n",
       "       zuckerberg         —         ‘         ’         “         ”     ❝real  \n",
       "!             0.0 -1.336828  0.000000 -1.033232 -0.862420 -1.940964  0.129509  \n",
       "#             0.0 -2.258870 -1.867048 -1.872582 -2.947612 -2.863006  0.000000  \n",
       "(             0.0  0.000000  0.000000 -2.176222 -2.103850  0.000000  0.000000  \n",
       ")             0.0  0.000000  0.000000 -2.209012 -2.136640  0.000000  0.000000  \n",
       ",             0.0 -1.898986 -1.794845 -1.849169 -1.489115 -1.809974  0.000000  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "‘             0.0  0.000000  0.000000  0.056935  0.000000  0.000000  0.000000  \n",
       "’             0.0  0.000000  0.056935 -0.808319 -0.879048 -0.651341 -0.372628  \n",
       "“             0.0 -0.380299  0.000000 -0.879048 -0.599037  1.318151  0.000000  \n",
       "”             0.0 -0.072549  0.000000 -0.651341  1.318151  0.709610  0.000000  \n",
       "❝real         0.0  0.000000  0.000000 -0.372628  0.000000  0.000000  0.000000  \n",
       "\n",
       "[2325 rows x 2325 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(word_context_matrix, index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2325, 2325)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_context_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = FastICA(n_components = 2)\n",
    "std_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.05300921e-02,  1.55449173e-01],\n",
       "       [ 2.23908142e-01,  2.92544409e-01],\n",
       "       [-6.63369882e-03,  1.05606954e-01],\n",
       "       ...,\n",
       "       [-1.09980468e-02,  9.13207995e-02],\n",
       "       [-1.35111394e-02,  5.43294435e-02],\n",
       "       [-1.98375039e-04, -6.27308874e-03]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std = std_scaler.fit_transform(word_context_matrix)\n",
    "\n",
    "matrix = ica.fit_transform(X_std)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comp 1</th>\n",
       "      <th>Comp 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>0.010530</td>\n",
       "      <td>0.155449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>0.223908</td>\n",
       "      <td>0.292544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>-0.006634</td>\n",
       "      <td>0.105607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>-0.005775</td>\n",
       "      <td>0.110960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.214099</td>\n",
       "      <td>0.246103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>-0.009867</td>\n",
       "      <td>0.012800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>0.067720</td>\n",
       "      <td>0.226921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“</th>\n",
       "      <td>-0.010998</td>\n",
       "      <td>0.091321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>”</th>\n",
       "      <td>-0.013511</td>\n",
       "      <td>0.054329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>❝real</th>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.006273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2325 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Comp 1    Comp 2\n",
       "!      0.010530  0.155449\n",
       "#      0.223908  0.292544\n",
       "(     -0.006634  0.105607\n",
       ")     -0.005775  0.110960\n",
       ",      0.214099  0.246103\n",
       "...         ...       ...\n",
       "‘     -0.009867  0.012800\n",
       "’      0.067720  0.226921\n",
       "“     -0.010998  0.091321\n",
       "”     -0.013511  0.054329\n",
       "❝real -0.000198 -0.006273\n",
       "\n",
       "[2325 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(matrix,\n",
    "                  index = cm.vocabulary,\n",
    "                  columns = ['Comp {}'.format(i+1) for i in range(2)])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 62222 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 62222 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = [key for key in cm.vocabulary.keys()]\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    \n",
    "    #if re.match('^co[rv]', word):\n",
    "    \n",
    "        x = df['Comp 1'][i]\n",
    "        y = df['Comp 2'][i]\n",
    "\n",
    "        plt.scatter(x, y)\n",
    "        plt.text(x, y, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set word embeddings for text classification\n",
    "ica = FastICA(n_components = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.08520250e-03, -2.31716774e-03,  5.97006599e-03, ...,\n",
       "         1.10894993e-01,  4.25077962e-02,  2.35812747e-03],\n",
       "       [-2.32131452e-02,  2.15315362e-02, -4.75143783e-03, ...,\n",
       "        -1.42173059e-01, -4.43382638e-02,  4.81964743e-02],\n",
       "       [ 1.27703721e-02, -3.58929556e-03, -2.05635024e-03, ...,\n",
       "        -2.37731982e-02,  1.54577291e-03,  1.44067862e-02],\n",
       "       ...,\n",
       "       [-2.76345626e-03,  6.67005750e-03, -1.25474287e-04, ...,\n",
       "         2.18487102e-03,  3.18182134e-02,  7.54751368e-03],\n",
       "       [-1.86365823e-03,  5.15569876e-03, -5.72010861e-04, ...,\n",
       "         5.39334755e-03,  5.72755173e-02,  4.32565817e-03],\n",
       "       [-3.84557118e-03,  1.63422568e-03, -6.63159781e-04, ...,\n",
       "        -3.69800597e-03, -1.11219671e-03,  2.74469791e-03]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = ica.fit_transform(X_std)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out target\n",
    "y = tweets['Is_Unreliable']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derive text vectors from word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_vectors(word_embeddings,\n",
    "                     word_index_dict,\n",
    "                     text_list,\n",
    "                     remove_stopwords = True,\n",
    "                     lowercase = True,\n",
    "                     lemmatize = True,\n",
    "                     add_start_end_tokens = True):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    for k in range(len(text_list)):\n",
    "        text = text_list[k]\n",
    "        text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "        text_vec = np.zeros(word_embeddings.shape[1])\n",
    "        words = word_tokenize(text)\n",
    "        tracker = 0 # to track whether we've encountered a word for which we have an embedding (in each tweet)\n",
    "        \n",
    "        if remove_stopwords:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                if word.lower() not in set(stopwords.words('english')):\n",
    "                    clean_words.append(word)\n",
    "            words = clean_words\n",
    "\n",
    "        if lowercase:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                clean_words.append(word.lower())\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if lemmatize:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                PoS_tag = pos_tag([word])[0][1]\n",
    "\n",
    "                # to change contractions to full word form\n",
    "                if word in contractions:\n",
    "                    word = contractions[word]\n",
    "\n",
    "                if PoS_tag[0].upper() in 'JNVR':\n",
    "                    word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                else:\n",
    "                    word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                clean_words.append(word)\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if add_start_end_tokens:\n",
    "            words = ['<START>'] + words + ['<END>']\n",
    "        \n",
    "        for i in range(len(words)):\n",
    "            word = words[i]\n",
    "            if word in word_index_dict:\n",
    "                word_embed_vec = word_embeddings[word_index_dict[word],:]\n",
    "                if tracker == 0:\n",
    "                    text_matrix = word_embed_vec\n",
    "                else:\n",
    "                    text_matrix = np.vstack((text_matrix, word_embed_vec))\n",
    "                    \n",
    "                # only increment if we have come across a word in the embeddings dictionary\n",
    "                tracker += 1\n",
    "                    \n",
    "        for j in range(len(text_vec)):\n",
    "            text_vec[j] = text_matrix[:,j].mean()\n",
    "            \n",
    "        if k == 0:\n",
    "            full_matrix = text_vec\n",
    "        else:\n",
    "            full_matrix = np.vstack((full_matrix, text_vec))\n",
    "            \n",
    "    return full_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_text_vectors(embeddings, cm.vocabulary, tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 150)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00015618, -0.0062352 ,  0.00246065, ...,  0.00067946,\n",
       "        -0.00217895,  0.0014629 ],\n",
       "       [-0.00439442, -0.00584523, -0.00627114, ...,  0.00193995,\n",
       "        -0.00527585,  0.00215334],\n",
       "       [-0.00521266, -0.00382433, -0.00746015, ..., -0.00018286,\n",
       "        -0.00455574,  0.00378513],\n",
       "       ...,\n",
       "       [ 0.00252653, -0.00102036,  0.00273674, ...,  0.00097709,\n",
       "        -0.000908  , -0.00242381],\n",
       "       [ 0.00925108, -0.00168812, -0.0030709 , ..., -0.01031774,\n",
       "        -0.00234417,  0.00705791],\n",
       "       [ 0.00059404, -0.00066515, -0.00405028, ..., -0.00423033,\n",
       "        -0.00411887,  0.00350019]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, KFold, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipe = Pipeline([\n",
    "    ('classify', SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC hyperparams to optimize\n",
    "kernel = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "C = [0.001, 0.01, 0.1, 1, 10]\n",
    "# set up parameter grid\n",
    "params = {\n",
    "    'classify__kernel': kernel,\n",
    "    'classify__C': C\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CV scheme for inner and outer loops\n",
    "inner_cv = KFold(n_splits = 3, shuffle = True, random_state = 1)\n",
    "outer_cv = KFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "\n",
    "# Set up GridSearch for inner loop\n",
    "grid_SVC = GridSearchCV(pipe, params, cv = inner_cv)\n",
    "#grid_SVC.fit(X, y)\n",
    "\n",
    "# Nested CV scores\n",
    "scores = cross_validate(grid_SVC,\n",
    "                        X = X,\n",
    "                        y = y,\n",
    "                        cv = outer_cv,\n",
    "                        scoring = ['roc_auc', 'accuracy', 'f1', 'precision', 'recall'],\n",
    "                        return_estimator = True)\n",
    "auc = scores['test_roc_auc']\n",
    "accuracy = scores['test_accuracy']\n",
    "f1 = scores['test_f1']\n",
    "precision = scores['test_precision']\n",
    "recall = scores['test_recall']\n",
    "estimators = scores['estimator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9042229802826242"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8232142857142858"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8296985511506753"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7992553170339917"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8667096767342084"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in estimators:\n",
    "    print(i.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
