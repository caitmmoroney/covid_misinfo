{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Word Context Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.decomposition import FastICA, TruncatedSVD, PCA, NMF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert contractions picked up by word_tokenize() into full words\n",
    "contractions = {\n",
    "    \"n't\": 'not',\n",
    "    \"'ve\": 'have',\n",
    "    \"'s\": 'is', # note that this will include possessive nouns\n",
    "    'gonna': 'going to',\n",
    "    'gotta': 'got to',\n",
    "    \"'d\": 'would',\n",
    "    \"'ll\": 'will',\n",
    "    \"'re\": 'are',\n",
    "    \"'m\": 'am',\n",
    "    'wanna': 'want to'\n",
    "}\n",
    "\n",
    "# to convert nltk_pos tags to wordnet-compatible PoS tags\n",
    "def convert_pos_wordnet(tag):\n",
    "    tag_abbr = tag[0].upper()\n",
    "    tag_dict = {\n",
    "        'J': wordnet.ADJ,\n",
    "        'N': wordnet.NOUN,\n",
    "        'V': wordnet.VERB,\n",
    "        'R': wordnet.ADV\n",
    "    }\n",
    "                \n",
    "    if tag_abbr in tag_dict:\n",
    "        return tag_dict[tag_abbr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextMatrix(TransformerMixin):\n",
    "    \n",
    "    # initialize class & private variables\n",
    "    def __init__(self,\n",
    "                 window_size = 4,\n",
    "                 remove_stopwords = True,\n",
    "                 add_start_end_tokens = True,\n",
    "                 lowercase = False,\n",
    "                 lemmatize = False,\n",
    "                 pmi = False,\n",
    "                 spmi_k = 1,\n",
    "                 laplace_smoothing = 0,\n",
    "                 pmi_positive = False,\n",
    "                 sppmi_k = 1):\n",
    "        \n",
    "        \"\"\" Params:\n",
    "                window_size: size of +/- context window (default = 4)\n",
    "                remove_stopwords: boolean, whether or not to remove NLTK English stopwords\n",
    "                add_start_end_tokens: boolean, whether or not to append <START> and <END> to the\n",
    "                beginning/end of each document in the corpus (default = True)\n",
    "                lowercase: boolean, whether or not to convert words to all lowercase\n",
    "                lemmatize: boolean, whether or not to lemmatize input text\n",
    "                pmi: boolean, whether or not to compute pointwise mutual information\n",
    "                pmi_positive: boolean, whether or not to compute positive PMI\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.add_start_end_tokens = add_start_end_tokens\n",
    "        self.lowercase = lowercase\n",
    "        self.lemmatize = lemmatize\n",
    "        self.pmi = pmi\n",
    "        self.spmi_k = spmi_k\n",
    "        self.laplace_smoothing = laplace_smoothing\n",
    "        self.pmi_positive = pmi_positive\n",
    "        self.sppmi_k = sppmi_k\n",
    "        self.corpus = None\n",
    "        self.clean_corpus = None\n",
    "        self.vocabulary = None\n",
    "        self.X = None\n",
    "        self.doc_terms_lists = None\n",
    "    \n",
    "    def fit(self, corpus, y = None):\n",
    "        \n",
    "        \"\"\" Learn the dictionary of all unique tokens for given corpus.\n",
    "        \n",
    "            Params:\n",
    "                corpus: list of strings\n",
    "            \n",
    "            Returns: self\n",
    "        \"\"\"\n",
    "        self.corpus = corpus\n",
    "        \n",
    "        term_dict = dict()\n",
    "        k = 0\n",
    "        corpus_words = []\n",
    "        clean_corpus = []\n",
    "        doc_terms_lists = []\n",
    "        detokenizer = TreebankWordDetokenizer()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        for text in corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "            \n",
    "            # detokenize trick taken from this StackOverflow post:\n",
    "            # https://stackoverflow.com/questions/21948019/python-untokenize-a-sentence\n",
    "            # and NLTK treebank documentation:\n",
    "            # https://www.nltk.org/_modules/nltk/tokenize/treebank.html\n",
    "            text = detokenizer.detokenize(words)\n",
    "            clean_corpus.append(text)\n",
    "            \n",
    "            [corpus_words.append(word) for word in words]\n",
    "            \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            doc_terms_lists.append(words)\n",
    "            \n",
    "        self.clean_corpus = clean_corpus\n",
    "        \n",
    "        self.doc_terms_lists = doc_terms_lists\n",
    "        \n",
    "        corpus_words = list(set(corpus_words))\n",
    "        \n",
    "        if self.add_start_end_tokens:\n",
    "            corpus_words = ['<START>'] + corpus_words + ['<END>']\n",
    "        \n",
    "        corpus_words = sorted(corpus_words)\n",
    "        \n",
    "        for el in corpus_words:\n",
    "            term_dict[el] = k\n",
    "            k += 1\n",
    "            \n",
    "        self.vocabulary = term_dict\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def transform(self, new_corpus = None, y = None):\n",
    "        \n",
    "        \"\"\" Compute the co-occurrence matrix for given corpus and window_size, using term dictionary\n",
    "            obtained with fit method.\n",
    "        \n",
    "            Returns: term-context co-occurrence matrix (shape: target terms by context terms) with\n",
    "            raw counts\n",
    "        \"\"\"\n",
    "        num_terms = len(self.vocabulary)\n",
    "        window = self.window_size\n",
    "        X = np.full((num_terms, num_terms), self.laplace_smoothing)\n",
    "        \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        if type(new_corpus) != list:\n",
    "            new_corpus = self.corpus\n",
    "        \n",
    "        for text in new_corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            for i in range(len(words)):\n",
    "                target = words[i]\n",
    "                \n",
    "                # check to see if target word is in the dictionary; if not, skip\n",
    "                if target in self.vocabulary:\n",
    "                    \n",
    "                    # grab index from dictionary\n",
    "                    target_dict_index = self.vocabulary[target]\n",
    "                    \n",
    "                    # find left-most and right-most window indices for each target word\n",
    "                    left_end_index = max(i - window, 0)\n",
    "                    right_end_index = min(i + window, len(words) - 1)\n",
    "                    \n",
    "                    # loop over all words within window\n",
    "                    # NOTE: this will include the target word; make sure to skip over it\n",
    "                    for j in range(left_end_index, right_end_index + 1):\n",
    "                        \n",
    "                        # skip \"context word\" where the \"context word\" index is equal to the\n",
    "                        # target word index\n",
    "                        if j != i:\n",
    "                            context_word = words[j]\n",
    "                            \n",
    "                            # check to see if context word is in the fitted dictionary; if\n",
    "                            # not, skip\n",
    "                            if context_word in self.vocabulary:\n",
    "                                X[target_dict_index, self.vocabulary[context_word]] += 1\n",
    "        \n",
    "        # if pmi = True, compute pmi matrix from word-context raw frequencies\n",
    "        # more concise code taken from this StackOverflow post:\n",
    "        # https://stackoverflow.com/questions/58701337/how-to-construct-ppmi-matrix-from-a-text-corpus\n",
    "        if self.pmi:\n",
    "            denom = X.sum()\n",
    "            col_sums = X.sum(axis = 0)\n",
    "            row_sums = X.sum(axis = 1)\n",
    "            \n",
    "            expected = np.outer(row_sums, col_sums)/denom\n",
    "            \n",
    "            X = X/expected\n",
    "            \n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(X.shape[1]):\n",
    "                \n",
    "                    if X[i,j] > 0:\n",
    "                        X[i,j] = np.log(X[i,j]) - np.log(self.spmi_k)\n",
    "                        \n",
    "                        if self.pmi_positive:\n",
    "                            X[i,j] = max(X[i,j] - np.log(self.sppmi_k), 0)\n",
    "        \n",
    "        # note that X is a dense matrix\n",
    "        self.X = X\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(lowercase = True, lemmatize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [\n",
    "    \"Coronavirus is a fake liberal hoax.\",\n",
    "    \"Trump won't do anything about coronavirus.\",\n",
    "    \"The liberal fake news media always blame Pres Trump.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ContextMatrix at 0x1a1f9acf90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.fit(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <th>always</th>\n",
       "      <th>anything</th>\n",
       "      <th>blame</th>\n",
       "      <th>coronavirus</th>\n",
       "      <th>fake</th>\n",
       "      <th>hoax</th>\n",
       "      <th>liberal</th>\n",
       "      <th>medium</th>\n",
       "      <th>news</th>\n",
       "      <th>pres</th>\n",
       "      <th>trump</th>\n",
       "      <th>wont</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>always</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anything</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blame</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronavirus</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fake</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoax</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pres</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wont</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             .  <END>  <START>  always  anything  blame  coronavirus  fake  \\\n",
       ".            0      3        0       1         1      1            2     1   \n",
       "<END>        3      0        0       0         1      1            1     1   \n",
       "<START>      0      0        0       0         1      0            2     2   \n",
       "always       1      0        0       0         0      1            0     1   \n",
       "anything     1      1        1       0         0      0            1     0   \n",
       "blame        1      1        0       1         0      0            0     1   \n",
       "coronavirus  2      1        2       0         1      0            0     1   \n",
       "fake         1      1        2       1         0      1            1     0   \n",
       "hoax         1      1        1       0         0      0            1     1   \n",
       "liberal      1      1        2       1         0      0            1     2   \n",
       "medium       0      0        1       1         0      1            0     1   \n",
       "news         0      0        1       1         0      1            0     1   \n",
       "pres         1      1        0       1         0      1            0     0   \n",
       "trump        2      1        1       1         1      1            1     0   \n",
       "wont         1      1        1       0         1      0            1     0   \n",
       "\n",
       "             hoax  liberal  medium  news  pres  trump  wont  \n",
       ".               1        1       0     0     1      2     1  \n",
       "<END>           1        1       0     0     1      1     1  \n",
       "<START>         1        2       1     1     0      1     1  \n",
       "always          0        1       1     1     1      1     0  \n",
       "anything        0        0       0     0     0      1     1  \n",
       "blame           0        0       1     1     1      1     0  \n",
       "coronavirus     1        1       0     0     0      1     1  \n",
       "fake            1        2       1     1     0      0     0  \n",
       "hoax            0        1       0     0     0      0     0  \n",
       "liberal         1        0       1     1     0      0     0  \n",
       "medium          0        1       0     1     1      1     0  \n",
       "news            0        1       1     0     1      0     0  \n",
       "pres            0        0       1     1     0      1     0  \n",
       "trump           0        0       1     0     1      0     1  \n",
       "wont            0        0       0     0     0      1     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cm.transform(tweets), index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coronavirus fake liberal hoax.',\n",
       " 'trump wont anything coronavirus.',\n",
       " 'liberal fake news medium always blame pres trump.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.clean_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coronavirus is a fake liberal hoax.',\n",
       " \"Trump won't do anything about coronavirus.\",\n",
       " 'The liberal fake news media always blame Pres Trump.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train embeddings using tweets as corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('COVID19_Dataset-text_labels_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Unreliable</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 3, 6, 9</td>\n",
       "      <td>We are living in scary times in Canada. Gov’t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 6, 8, 9</td>\n",
       "      <td>Just as bad in Canada. In fact, our government...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 4, 9</td>\n",
       "      <td>It was only a matter of time before the mainst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8</td>\n",
       "      <td>Russia's taking no chances: Foreigners infecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8, 9</td>\n",
       "      <td>Although there is now a presumptive confirmed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BREAKING: Harvard classes will move online sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singularity University is hosting a FREE Virtu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus: how does it spread and what are t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stanford just cancelled classes for the rest o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tech conferences were cancelled in #Waterloo R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Is_Unreliable    Category  \\\n",
       "0                1  1, 3, 6, 9   \n",
       "1                1  1, 6, 8, 9   \n",
       "2                1     1, 4, 9   \n",
       "3                1        6, 8   \n",
       "4                1     6, 8, 9   \n",
       "..             ...         ...   \n",
       "555              0         NaN   \n",
       "556              0         NaN   \n",
       "557              0         NaN   \n",
       "558              0         NaN   \n",
       "559              0         NaN   \n",
       "\n",
       "                                                 Tweet  \n",
       "0    We are living in scary times in Canada. Gov’t ...  \n",
       "1    Just as bad in Canada. In fact, our government...  \n",
       "2    It was only a matter of time before the mainst...  \n",
       "3    Russia's taking no chances: Foreigners infecte...  \n",
       "4    Although there is now a presumptive confirmed ...  \n",
       "..                                                 ...  \n",
       "555  BREAKING: Harvard classes will move online sta...  \n",
       "556  Singularity University is hosting a FREE Virtu...  \n",
       "557  Coronavirus: how does it spread and what are t...  \n",
       "558  Stanford just cancelled classes for the rest o...  \n",
       "559  Tech conferences were cancelled in #Waterloo R...  \n",
       "\n",
       "[560 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(window_size = 15,\n",
    "                   lowercase = True,\n",
    "                   lemmatize = True,\n",
    "                   pmi = True,\n",
    "                   spmi_k = 5,\n",
    "                   laplace_smoothing = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_context_matrix = cm.fit_transform(tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>#</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>,</th>\n",
       "      <th>-</th>\n",
       "      <th>--</th>\n",
       "      <th>.</th>\n",
       "      <th>...</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoomer</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>—</th>\n",
       "      <th>‘</th>\n",
       "      <th>’</th>\n",
       "      <th>“</th>\n",
       "      <th>”</th>\n",
       "      <th>❝real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>2.094690</td>\n",
       "      <td>0.128119</td>\n",
       "      <td>-1.926536</td>\n",
       "      <td>-1.524360</td>\n",
       "      <td>-0.667113</td>\n",
       "      <td>-1.022572</td>\n",
       "      <td>-1.841003</td>\n",
       "      <td>0.326417</td>\n",
       "      <td>-0.342190</td>\n",
       "      <td>-0.927453</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.826330</td>\n",
       "      <td>-1.831458</td>\n",
       "      <td>-1.826544</td>\n",
       "      <td>-1.824615</td>\n",
       "      <td>-1.436382</td>\n",
       "      <td>-1.848574</td>\n",
       "      <td>0.568474</td>\n",
       "      <td>-0.305990</td>\n",
       "      <td>-1.198484</td>\n",
       "      <td>-1.421507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>0.128119</td>\n",
       "      <td>2.546402</td>\n",
       "      <td>-0.817813</td>\n",
       "      <td>-0.821102</td>\n",
       "      <td>0.996887</td>\n",
       "      <td>-0.183513</td>\n",
       "      <td>-1.520738</td>\n",
       "      <td>1.446727</td>\n",
       "      <td>-2.036827</td>\n",
       "      <td>-2.034304</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.422355</td>\n",
       "      <td>-2.022019</td>\n",
       "      <td>-2.017105</td>\n",
       "      <td>-2.420640</td>\n",
       "      <td>-1.744726</td>\n",
       "      <td>-1.345988</td>\n",
       "      <td>0.712849</td>\n",
       "      <td>-1.258690</td>\n",
       "      <td>-1.389045</td>\n",
       "      <td>-2.422998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>-1.926536</td>\n",
       "      <td>-0.817813</td>\n",
       "      <td>-1.111480</td>\n",
       "      <td>1.025297</td>\n",
       "      <td>-0.322061</td>\n",
       "      <td>-1.411489</td>\n",
       "      <td>-1.719094</td>\n",
       "      <td>-0.270797</td>\n",
       "      <td>-1.318893</td>\n",
       "      <td>-1.721835</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.704421</td>\n",
       "      <td>-1.709549</td>\n",
       "      <td>-1.704635</td>\n",
       "      <td>-1.702706</td>\n",
       "      <td>-1.719939</td>\n",
       "      <td>-1.726665</td>\n",
       "      <td>-0.951845</td>\n",
       "      <td>-1.388054</td>\n",
       "      <td>-1.769723</td>\n",
       "      <td>-1.705064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>-1.524360</td>\n",
       "      <td>-0.821102</td>\n",
       "      <td>1.025297</td>\n",
       "      <td>-1.118058</td>\n",
       "      <td>-0.325350</td>\n",
       "      <td>-1.414778</td>\n",
       "      <td>-1.722384</td>\n",
       "      <td>-0.127482</td>\n",
       "      <td>-1.322182</td>\n",
       "      <td>-1.725124</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.707710</td>\n",
       "      <td>-1.712839</td>\n",
       "      <td>-1.707925</td>\n",
       "      <td>-1.705995</td>\n",
       "      <td>-1.723228</td>\n",
       "      <td>-1.729955</td>\n",
       "      <td>-0.955134</td>\n",
       "      <td>-1.391343</td>\n",
       "      <td>-1.773012</td>\n",
       "      <td>-1.708353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>-0.667113</td>\n",
       "      <td>0.996887</td>\n",
       "      <td>-0.322061</td>\n",
       "      <td>-0.325350</td>\n",
       "      <td>1.379195</td>\n",
       "      <td>-0.403380</td>\n",
       "      <td>-1.152819</td>\n",
       "      <td>1.321332</td>\n",
       "      <td>-1.340404</td>\n",
       "      <td>-1.155560</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.320467</td>\n",
       "      <td>-1.836421</td>\n",
       "      <td>-2.236972</td>\n",
       "      <td>-2.235043</td>\n",
       "      <td>-1.559128</td>\n",
       "      <td>-1.342712</td>\n",
       "      <td>0.574207</td>\n",
       "      <td>-0.185790</td>\n",
       "      <td>-0.692621</td>\n",
       "      <td>-2.237400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>-1.848574</td>\n",
       "      <td>-1.345988</td>\n",
       "      <td>-1.726665</td>\n",
       "      <td>-1.729955</td>\n",
       "      <td>-1.342712</td>\n",
       "      <td>-1.738992</td>\n",
       "      <td>-1.641133</td>\n",
       "      <td>-1.345515</td>\n",
       "      <td>-1.646397</td>\n",
       "      <td>-1.643874</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.626460</td>\n",
       "      <td>-1.631588</td>\n",
       "      <td>-1.626674</td>\n",
       "      <td>-1.624744</td>\n",
       "      <td>-1.641977</td>\n",
       "      <td>-1.648704</td>\n",
       "      <td>-0.267747</td>\n",
       "      <td>-1.715557</td>\n",
       "      <td>-1.691761</td>\n",
       "      <td>-1.627102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>0.568474</td>\n",
       "      <td>0.712849</td>\n",
       "      <td>-0.951845</td>\n",
       "      <td>-0.955134</td>\n",
       "      <td>0.574207</td>\n",
       "      <td>-0.676489</td>\n",
       "      <td>-1.964924</td>\n",
       "      <td>1.016271</td>\n",
       "      <td>-0.717425</td>\n",
       "      <td>-1.967665</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.950251</td>\n",
       "      <td>-1.955379</td>\n",
       "      <td>-1.950465</td>\n",
       "      <td>-1.948536</td>\n",
       "      <td>-1.965769</td>\n",
       "      <td>-0.267747</td>\n",
       "      <td>1.137700</td>\n",
       "      <td>-0.024446</td>\n",
       "      <td>-0.069642</td>\n",
       "      <td>-1.545428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“</th>\n",
       "      <td>-0.305990</td>\n",
       "      <td>-1.258690</td>\n",
       "      <td>-1.388054</td>\n",
       "      <td>-1.391343</td>\n",
       "      <td>-0.185790</td>\n",
       "      <td>-0.889555</td>\n",
       "      <td>-1.302521</td>\n",
       "      <td>-0.259689</td>\n",
       "      <td>-1.307785</td>\n",
       "      <td>-1.305262</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.693313</td>\n",
       "      <td>-1.698441</td>\n",
       "      <td>-1.693527</td>\n",
       "      <td>-1.691598</td>\n",
       "      <td>-1.303365</td>\n",
       "      <td>-1.715557</td>\n",
       "      <td>-0.024446</td>\n",
       "      <td>-0.683799</td>\n",
       "      <td>0.639281</td>\n",
       "      <td>-1.693956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>”</th>\n",
       "      <td>-1.198484</td>\n",
       "      <td>-1.389045</td>\n",
       "      <td>-1.769723</td>\n",
       "      <td>-1.773012</td>\n",
       "      <td>-0.692621</td>\n",
       "      <td>-1.088902</td>\n",
       "      <td>-1.278725</td>\n",
       "      <td>-0.472281</td>\n",
       "      <td>-1.283989</td>\n",
       "      <td>-1.686931</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.669517</td>\n",
       "      <td>-1.674645</td>\n",
       "      <td>-1.669731</td>\n",
       "      <td>-1.667801</td>\n",
       "      <td>-1.279569</td>\n",
       "      <td>-1.691761</td>\n",
       "      <td>-0.069642</td>\n",
       "      <td>0.639281</td>\n",
       "      <td>-0.125380</td>\n",
       "      <td>-1.670159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>❝real</th>\n",
       "      <td>-1.421507</td>\n",
       "      <td>-2.422998</td>\n",
       "      <td>-1.705064</td>\n",
       "      <td>-1.708353</td>\n",
       "      <td>-2.237400</td>\n",
       "      <td>-1.717390</td>\n",
       "      <td>-1.619531</td>\n",
       "      <td>-2.422525</td>\n",
       "      <td>-1.624795</td>\n",
       "      <td>-1.622272</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.604858</td>\n",
       "      <td>-1.609986</td>\n",
       "      <td>-1.605072</td>\n",
       "      <td>-1.603142</td>\n",
       "      <td>-1.620375</td>\n",
       "      <td>-1.627102</td>\n",
       "      <td>-1.545428</td>\n",
       "      <td>-1.693956</td>\n",
       "      <td>-1.670159</td>\n",
       "      <td>-1.605500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2325 rows × 2325 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              !         #         (         )         ,         -        --  \\\n",
       "!      2.094690  0.128119 -1.926536 -1.524360 -0.667113 -1.022572 -1.841003   \n",
       "#      0.128119  2.546402 -0.817813 -0.821102  0.996887 -0.183513 -1.520738   \n",
       "(     -1.926536 -0.817813 -1.111480  1.025297 -0.322061 -1.411489 -1.719094   \n",
       ")     -1.524360 -0.821102  1.025297 -1.118058 -0.325350 -1.414778 -1.722384   \n",
       ",     -0.667113  0.996887 -0.322061 -0.325350  1.379195 -0.403380 -1.152819   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "‘     -1.848574 -1.345988 -1.726665 -1.729955 -1.342712 -1.738992 -1.641133   \n",
       "’      0.568474  0.712849 -0.951845 -0.955134  0.574207 -0.676489 -1.964924   \n",
       "“     -0.305990 -1.258690 -1.388054 -1.391343 -0.185790 -0.889555 -1.302521   \n",
       "”     -1.198484 -1.389045 -1.769723 -1.773012 -0.692621 -1.088902 -1.278725   \n",
       "❝real -1.421507 -2.422998 -1.705064 -1.708353 -2.237400 -1.717390 -1.619531   \n",
       "\n",
       "              .       ...         1  ...    zombie      zone    zoomer  \\\n",
       "!      0.326417 -0.342190 -0.927453  ... -1.826330 -1.831458 -1.826544   \n",
       "#      1.446727 -2.036827 -2.034304  ... -2.422355 -2.022019 -2.017105   \n",
       "(     -0.270797 -1.318893 -1.721835  ... -1.704421 -1.709549 -1.704635   \n",
       ")     -0.127482 -1.322182 -1.725124  ... -1.707710 -1.712839 -1.707925   \n",
       ",      1.321332 -1.340404 -1.155560  ... -1.320467 -1.836421 -2.236972   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "‘     -1.345515 -1.646397 -1.643874  ... -1.626460 -1.631588 -1.626674   \n",
       "’      1.016271 -0.717425 -1.967665  ... -1.950251 -1.955379 -1.950465   \n",
       "“     -0.259689 -1.307785 -1.305262  ... -1.693313 -1.698441 -1.693527   \n",
       "”     -0.472281 -1.283989 -1.686931  ... -1.669517 -1.674645 -1.669731   \n",
       "❝real -2.422525 -1.624795 -1.622272  ... -1.604858 -1.609986 -1.605072   \n",
       "\n",
       "       zuckerberg         —         ‘         ’         “         ”     ❝real  \n",
       "!       -1.824615 -1.436382 -1.848574  0.568474 -0.305990 -1.198484 -1.421507  \n",
       "#       -2.420640 -1.744726 -1.345988  0.712849 -1.258690 -1.389045 -2.422998  \n",
       "(       -1.702706 -1.719939 -1.726665 -0.951845 -1.388054 -1.769723 -1.705064  \n",
       ")       -1.705995 -1.723228 -1.729955 -0.955134 -1.391343 -1.773012 -1.708353  \n",
       ",       -2.235043 -1.559128 -1.342712  0.574207 -0.185790 -0.692621 -2.237400  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "‘       -1.624744 -1.641977 -1.648704 -0.267747 -1.715557 -1.691761 -1.627102  \n",
       "’       -1.948536 -1.965769 -0.267747  1.137700 -0.024446 -0.069642 -1.545428  \n",
       "“       -1.691598 -1.303365 -1.715557 -0.024446 -0.683799  0.639281 -1.693956  \n",
       "”       -1.667801 -1.279569 -1.691761 -0.069642  0.639281 -0.125380 -1.670159  \n",
       "❝real   -1.603142 -1.620375 -1.627102 -1.545428 -1.693956 -1.670159 -1.605500  \n",
       "\n",
       "[2325 rows x 2325 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(word_context_matrix, index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2325, 2325)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_context_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = FastICA(n_components = 2)\n",
    "std_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09131057, -0.06381238],\n",
       "       [-0.70462045,  0.62590622],\n",
       "       [-0.03141412, -0.04714335],\n",
       "       ...,\n",
       "       [-0.01973723, -0.05700864],\n",
       "       [-0.0139762 , -0.04096542],\n",
       "       [ 0.00258252,  0.00268278]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std = std_scaler.fit_transform(word_context_matrix)\n",
    "\n",
    "matrix = ica.fit_transform(X_std)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comp 1</th>\n",
       "      <th>Comp 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>-0.091311</td>\n",
       "      <td>-0.063812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>-0.704620</td>\n",
       "      <td>0.625906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>-0.031414</td>\n",
       "      <td>-0.047143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>-0.032061</td>\n",
       "      <td>-0.049630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>-0.166859</td>\n",
       "      <td>-0.329936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>-0.004369</td>\n",
       "      <td>-0.009360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>-0.123662</td>\n",
       "      <td>-0.122548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“</th>\n",
       "      <td>-0.019737</td>\n",
       "      <td>-0.057009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>”</th>\n",
       "      <td>-0.013976</td>\n",
       "      <td>-0.040965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>❝real</th>\n",
       "      <td>0.002583</td>\n",
       "      <td>0.002683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2325 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Comp 1    Comp 2\n",
       "!     -0.091311 -0.063812\n",
       "#     -0.704620  0.625906\n",
       "(     -0.031414 -0.047143\n",
       ")     -0.032061 -0.049630\n",
       ",     -0.166859 -0.329936\n",
       "...         ...       ...\n",
       "‘     -0.004369 -0.009360\n",
       "’     -0.123662 -0.122548\n",
       "“     -0.019737 -0.057009\n",
       "”     -0.013976 -0.040965\n",
       "❝real  0.002583  0.002683\n",
       "\n",
       "[2325 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(matrix,\n",
    "                  index = cm.vocabulary,\n",
    "                  columns = ['Comp {}'.format(i+1) for i in range(2)])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 62222 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 62222 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = [key for key in cm.vocabulary.keys()]\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    \n",
    "    #if re.match('^co[rv]', word):\n",
    "    \n",
    "        x = df['Comp 1'][i]\n",
    "        y = df['Comp 2'][i]\n",
    "\n",
    "        plt.scatter(x, y)\n",
    "        plt.text(x, y, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set word embeddings for text classification\n",
    "ica = FastICA(n_components = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.30654326e-03, -9.45830661e-03,  1.10801750e-03, ...,\n",
       "        -2.96802033e-03,  1.73821918e-03, -7.24576721e-03],\n",
       "       [ 8.44313310e-04, -1.72447822e-03,  7.98324317e-04, ...,\n",
       "        -4.43656036e-04,  5.81317521e-04,  8.51477875e-04],\n",
       "       [-6.19755242e-03, -1.22127217e-03,  1.70243664e-03, ...,\n",
       "        -1.98296062e-03, -1.11635012e-03, -9.91098035e-04],\n",
       "       ...,\n",
       "       [ 2.52828859e-02,  3.87277278e-03,  1.70200418e-02, ...,\n",
       "         9.50105488e-03, -8.26356582e-05,  1.22221376e-02],\n",
       "       [-9.04794236e-03, -1.26920608e-02,  1.79001105e-02, ...,\n",
       "        -1.35272098e-03, -7.61613372e-03, -1.67739082e-02],\n",
       "       [ 3.32838098e-03,  1.26559587e-04, -6.79966489e-03, ...,\n",
       "         3.47995168e-03,  2.04181149e-03,  4.37437901e-03]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = ica.fit_transform(X_std)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out target\n",
    "y = tweets['Is_Unreliable']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derive text vectors from word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_vectors(word_embeddings,\n",
    "                     word_index_dict,\n",
    "                     text_list,\n",
    "                     remove_stopwords = True,\n",
    "                     lowercase = True,\n",
    "                     lemmatize = True,\n",
    "                     add_start_end_tokens = True):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    for k in range(len(text_list)):\n",
    "        text = text_list[k]\n",
    "        text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "        text_vec = np.zeros(word_embeddings.shape[1])\n",
    "        words = word_tokenize(text)\n",
    "        tracker = 0 # to track whether we've encountered a word for which we have an embedding (in each tweet)\n",
    "        \n",
    "        if remove_stopwords:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                if word.lower() not in set(stopwords.words('english')):\n",
    "                    clean_words.append(word)\n",
    "            words = clean_words\n",
    "\n",
    "        if lowercase:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                clean_words.append(word.lower())\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if lemmatize:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                PoS_tag = pos_tag([word])[0][1]\n",
    "\n",
    "                # to change contractions to full word form\n",
    "                if word in contractions:\n",
    "                    word = contractions[word]\n",
    "\n",
    "                if PoS_tag[0].upper() in 'JNVR':\n",
    "                    word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                else:\n",
    "                    word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                clean_words.append(word)\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if add_start_end_tokens:\n",
    "            words = ['<START>'] + words + ['<END>']\n",
    "        \n",
    "        for i in range(len(words)):\n",
    "            word = words[i]\n",
    "            if word in word_index_dict:\n",
    "                word_embed_vec = word_embeddings[word_index_dict[word],:]\n",
    "                if tracker == 0:\n",
    "                    text_matrix = word_embed_vec\n",
    "                else:\n",
    "                    text_matrix = np.vstack((text_matrix, word_embed_vec))\n",
    "                    \n",
    "                # only increment if we have come across a word in the embeddings dictionary\n",
    "                tracker += 1\n",
    "                    \n",
    "        for j in range(len(text_vec)):\n",
    "            text_vec[j] = text_matrix[:,j].mean()\n",
    "            \n",
    "        if k == 0:\n",
    "            full_matrix = text_vec\n",
    "        else:\n",
    "            full_matrix = np.vstack((full_matrix, text_vec))\n",
    "            \n",
    "    return full_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_text_vectors(embeddings, cm.vocabulary, tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 150)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00733606,  0.00013973,  0.00157793, ...,  0.00046618,\n",
       "         0.00411328, -0.00604159],\n",
       "       [-0.00698682,  0.00324474, -0.01008144, ..., -0.00600844,\n",
       "         0.07146351,  0.04660539],\n",
       "       [ 0.00515755,  0.00316823,  0.00474775, ..., -0.00326874,\n",
       "        -0.00254577,  0.00127707],\n",
       "       ...,\n",
       "       [ 0.00333092,  0.00291835,  0.00102546, ...,  0.00025792,\n",
       "        -0.00409203, -0.00177115],\n",
       "       [-0.00183895,  0.01060158,  0.00779227, ...,  0.00088582,\n",
       "         0.00216808, -0.00124595],\n",
       "       [-0.00026339,  0.00020911, -0.00206963, ...,  0.00167407,\n",
       "        -0.00244815, -0.00253324]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, KFold, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipe = Pipeline([\n",
    "    ('classify', SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC hyperparams to optimize\n",
    "kernel = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "C = [0.001, 0.01, 0.1, 1, 10]\n",
    "# set up parameter grid\n",
    "params = {\n",
    "    'classify__kernel': kernel,\n",
    "    'classify__C': C\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CV scheme for inner and outer loops\n",
    "inner_cv = KFold(n_splits = 3, shuffle = True, random_state = 1)\n",
    "outer_cv = KFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "\n",
    "# Set up GridSearch for inner loop\n",
    "grid_SVC = GridSearchCV(pipe, params, cv = inner_cv)\n",
    "#grid_SVC.fit(X, y)\n",
    "\n",
    "# Nested CV scores\n",
    "scores = cross_validate(grid_SVC,\n",
    "                        X = X,\n",
    "                        y = y,\n",
    "                        cv = outer_cv,\n",
    "                        scoring = ['roc_auc', 'accuracy', 'f1', 'precision', 'recall'],\n",
    "                        return_estimator = True)\n",
    "auc = scores['test_roc_auc']\n",
    "accuracy = scores['test_accuracy']\n",
    "f1 = scores['test_f1']\n",
    "precision = scores['test_precision']\n",
    "recall = scores['test_recall']\n",
    "estimators = scores['estimator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9199740570180126"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8464285714285713"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8520920955610564"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8220030756699916"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8883764495985729"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 10, 'classify__kernel': 'linear'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in estimators:\n",
    "    print(i.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
