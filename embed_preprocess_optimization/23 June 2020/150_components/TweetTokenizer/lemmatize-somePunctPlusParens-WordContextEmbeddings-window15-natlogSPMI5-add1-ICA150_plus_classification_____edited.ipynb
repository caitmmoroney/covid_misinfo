{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Word Context Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.decomposition import FastICA, TruncatedSVD, PCA, NMF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert contractions picked up by word_tokenize() into full words\n",
    "contractions = {\n",
    "    \"n't\": 'not',\n",
    "    \"'ve\": 'have',\n",
    "    \"'s\": 'is', # note that this will include possessive nouns\n",
    "    'gonna': 'going to',\n",
    "    'gotta': 'got to',\n",
    "    \"'d\": 'would',\n",
    "    \"'ll\": 'will',\n",
    "    \"'re\": 'are',\n",
    "    \"'m\": 'am',\n",
    "    'wanna': 'want to'\n",
    "}\n",
    "\n",
    "# to convert nltk_pos tags to wordnet-compatible PoS tags\n",
    "def convert_pos_wordnet(tag):\n",
    "    tag_abbr = tag[0].upper()\n",
    "    tag_dict = {\n",
    "        'J': wordnet.ADJ,\n",
    "        'N': wordnet.NOUN,\n",
    "        'V': wordnet.VERB,\n",
    "        'R': wordnet.ADV\n",
    "    }\n",
    "                \n",
    "    if tag_abbr in tag_dict:\n",
    "        return tag_dict[tag_abbr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextMatrix(TransformerMixin):\n",
    "    \n",
    "    # initialize class & private variables\n",
    "    def __init__(self,\n",
    "                 window_size = 4,\n",
    "                 remove_stopwords = True,\n",
    "                 add_start_end_tokens = True,\n",
    "                 lowercase = False,\n",
    "                 lemmatize = False,\n",
    "                 pmi = False,\n",
    "                 spmi_k = 1,\n",
    "                 laplace_smoothing = 0,\n",
    "                 pmi_positive = False,\n",
    "                 sppmi_k = 1):\n",
    "        \n",
    "        \"\"\" Params:\n",
    "                window_size: size of +/- context window (default = 4)\n",
    "                remove_stopwords: boolean, whether or not to remove NLTK English stopwords\n",
    "                add_start_end_tokens: boolean, whether or not to append <START> and <END> to the\n",
    "                beginning/end of each document in the corpus (default = True)\n",
    "                lowercase: boolean, whether or not to convert words to all lowercase\n",
    "                lemmatize: boolean, whether or not to lemmatize input text\n",
    "                pmi: boolean, whether or not to compute pointwise mutual information\n",
    "                pmi_positive: boolean, whether or not to compute positive PMI\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.add_start_end_tokens = add_start_end_tokens\n",
    "        self.lowercase = lowercase\n",
    "        self.lemmatize = lemmatize\n",
    "        self.pmi = pmi\n",
    "        self.spmi_k = spmi_k\n",
    "        self.laplace_smoothing = laplace_smoothing\n",
    "        self.pmi_positive = pmi_positive\n",
    "        self.sppmi_k = sppmi_k\n",
    "        self.corpus = None\n",
    "        self.clean_corpus = None\n",
    "        self.vocabulary = None\n",
    "        self.X = None\n",
    "        self.doc_terms_lists = None\n",
    "    \n",
    "    def fit(self, corpus, y = None):\n",
    "        \n",
    "        \"\"\" Learn the dictionary of all unique tokens for given corpus.\n",
    "        \n",
    "            Params:\n",
    "                corpus: list of strings\n",
    "            \n",
    "            Returns: self\n",
    "        \"\"\"\n",
    "        self.corpus = corpus\n",
    "        \n",
    "        term_dict = dict()\n",
    "        k = 0\n",
    "        corpus_words = []\n",
    "        clean_corpus = []\n",
    "        doc_terms_lists = []\n",
    "        detokenizer = TreebankWordDetokenizer()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        for text in corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "            \n",
    "            # detokenize trick taken from this StackOverflow post:\n",
    "            # https://stackoverflow.com/questions/21948019/python-untokenize-a-sentence\n",
    "            # and NLTK treebank documentation:\n",
    "            # https://www.nltk.org/_modules/nltk/tokenize/treebank.html\n",
    "            text = detokenizer.detokenize(words)\n",
    "            clean_corpus.append(text)\n",
    "            \n",
    "            [corpus_words.append(word) for word in words]\n",
    "            \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            doc_terms_lists.append(words)\n",
    "            \n",
    "        self.clean_corpus = clean_corpus\n",
    "        \n",
    "        self.doc_terms_lists = doc_terms_lists\n",
    "        \n",
    "        corpus_words = list(set(corpus_words))\n",
    "        \n",
    "        if self.add_start_end_tokens:\n",
    "            corpus_words = ['<START>'] + corpus_words + ['<END>']\n",
    "        \n",
    "        corpus_words = sorted(corpus_words)\n",
    "        \n",
    "        for el in corpus_words:\n",
    "            term_dict[el] = k\n",
    "            k += 1\n",
    "            \n",
    "        self.vocabulary = term_dict\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def transform(self, new_corpus = None, y = None):\n",
    "        \n",
    "        \"\"\" Compute the co-occurrence matrix for given corpus and window_size, using term dictionary\n",
    "            obtained with fit method.\n",
    "        \n",
    "            Returns: term-context co-occurrence matrix (shape: target terms by context terms) with\n",
    "            raw counts\n",
    "        \"\"\"\n",
    "        num_terms = len(self.vocabulary)\n",
    "        window = self.window_size\n",
    "        X = np.full((num_terms, num_terms), self.laplace_smoothing)\n",
    "        \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        if type(new_corpus) != list:\n",
    "            new_corpus = self.corpus\n",
    "        \n",
    "        for text in new_corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            for i in range(len(words)):\n",
    "                target = words[i]\n",
    "                \n",
    "                # check to see if target word is in the dictionary; if not, skip\n",
    "                if target in self.vocabulary:\n",
    "                    \n",
    "                    # grab index from dictionary\n",
    "                    target_dict_index = self.vocabulary[target]\n",
    "                    \n",
    "                    # find left-most and right-most window indices for each target word\n",
    "                    left_end_index = max(i - window, 0)\n",
    "                    right_end_index = min(i + window, len(words) - 1)\n",
    "                    \n",
    "                    # loop over all words within window\n",
    "                    # NOTE: this will include the target word; make sure to skip over it\n",
    "                    for j in range(left_end_index, right_end_index + 1):\n",
    "                        \n",
    "                        # skip \"context word\" where the \"context word\" index is equal to the\n",
    "                        # target word index\n",
    "                        if j != i:\n",
    "                            context_word = words[j]\n",
    "                            \n",
    "                            # check to see if context word is in the fitted dictionary; if\n",
    "                            # not, skip\n",
    "                            if context_word in self.vocabulary:\n",
    "                                X[target_dict_index, self.vocabulary[context_word]] += 1\n",
    "        \n",
    "        # if pmi = True, compute pmi matrix from word-context raw frequencies\n",
    "        # more concise code taken from this StackOverflow post:\n",
    "        # https://stackoverflow.com/questions/58701337/how-to-construct-ppmi-matrix-from-a-text-corpus\n",
    "        if self.pmi:\n",
    "            denom = X.sum()\n",
    "            col_sums = X.sum(axis = 0)\n",
    "            row_sums = X.sum(axis = 1)\n",
    "            \n",
    "            expected = np.outer(row_sums, col_sums)/denom\n",
    "            \n",
    "            X = X/expected\n",
    "            \n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(X.shape[1]):\n",
    "                \n",
    "                    if X[i,j] > 0:\n",
    "                        X[i,j] = np.log(X[i,j]) - np.log(self.spmi_k)\n",
    "                        \n",
    "                        if self.pmi_positive:\n",
    "                            X[i,j] = max(X[i,j] - np.log(self.sppmi_k), 0)\n",
    "        \n",
    "        # note that X is a dense matrix\n",
    "        self.X = X\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(lowercase = True, lemmatize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [\n",
    "    \"Coronavirus is a fake liberal hoax.\",\n",
    "    \"Trump won't do anything about coronavirus.\",\n",
    "    \"The liberal fake news media always blame Pres Trump.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ContextMatrix at 0x103646c50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.fit(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <th>always</th>\n",
       "      <th>anything</th>\n",
       "      <th>blame</th>\n",
       "      <th>coronavirus</th>\n",
       "      <th>fake</th>\n",
       "      <th>hoax</th>\n",
       "      <th>liberal</th>\n",
       "      <th>medium</th>\n",
       "      <th>news</th>\n",
       "      <th>pres</th>\n",
       "      <th>trump</th>\n",
       "      <th>wont</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>always</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anything</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blame</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronavirus</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fake</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoax</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pres</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wont</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             .  <END>  <START>  always  anything  blame  coronavirus  fake  \\\n",
       ".            0      3        0       1         1      1            2     1   \n",
       "<END>        3      0        0       0         1      1            1     1   \n",
       "<START>      0      0        0       0         1      0            2     2   \n",
       "always       1      0        0       0         0      1            0     1   \n",
       "anything     1      1        1       0         0      0            1     0   \n",
       "blame        1      1        0       1         0      0            0     1   \n",
       "coronavirus  2      1        2       0         1      0            0     1   \n",
       "fake         1      1        2       1         0      1            1     0   \n",
       "hoax         1      1        1       0         0      0            1     1   \n",
       "liberal      1      1        2       1         0      0            1     2   \n",
       "medium       0      0        1       1         0      1            0     1   \n",
       "news         0      0        1       1         0      1            0     1   \n",
       "pres         1      1        0       1         0      1            0     0   \n",
       "trump        2      1        1       1         1      1            1     0   \n",
       "wont         1      1        1       0         1      0            1     0   \n",
       "\n",
       "             hoax  liberal  medium  news  pres  trump  wont  \n",
       ".               1        1       0     0     1      2     1  \n",
       "<END>           1        1       0     0     1      1     1  \n",
       "<START>         1        2       1     1     0      1     1  \n",
       "always          0        1       1     1     1      1     0  \n",
       "anything        0        0       0     0     0      1     1  \n",
       "blame           0        0       1     1     1      1     0  \n",
       "coronavirus     1        1       0     0     0      1     1  \n",
       "fake            1        2       1     1     0      0     0  \n",
       "hoax            0        1       0     0     0      0     0  \n",
       "liberal         1        0       1     1     0      0     0  \n",
       "medium          0        1       0     1     1      1     0  \n",
       "news            0        1       1     0     1      0     0  \n",
       "pres            0        0       1     1     0      1     0  \n",
       "trump           0        0       1     0     1      0     1  \n",
       "wont            0        0       0     0     0      1     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cm.transform(tweets), index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coronavirus fake liberal hoax.',\n",
       " 'trump wont anything coronavirus.',\n",
       " 'liberal fake news medium always blame pres trump.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.clean_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coronavirus is a fake liberal hoax.',\n",
       " \"Trump won't do anything about coronavirus.\",\n",
       " 'The liberal fake news media always blame Pres Trump.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train embeddings using tweets as corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('COVID19_Dataset-text_labels_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Unreliable</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 3, 6, 9</td>\n",
       "      <td>We are living in scary times in Canada. Gov’t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 6, 8, 9</td>\n",
       "      <td>Just as bad in Canada. In fact, our government...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 4, 9</td>\n",
       "      <td>It was only a matter of time before the mainst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8</td>\n",
       "      <td>Russia's taking no chances: Foreigners infecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8, 9</td>\n",
       "      <td>Although there is now a presumptive confirmed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BREAKING: Harvard classes will move online sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singularity University is hosting a FREE Virtu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus: how does it spread and what are t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stanford just cancelled classes for the rest o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tech conferences were cancelled in #Waterloo R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Is_Unreliable    Category  \\\n",
       "0                1  1, 3, 6, 9   \n",
       "1                1  1, 6, 8, 9   \n",
       "2                1     1, 4, 9   \n",
       "3                1        6, 8   \n",
       "4                1     6, 8, 9   \n",
       "..             ...         ...   \n",
       "555              0         NaN   \n",
       "556              0         NaN   \n",
       "557              0         NaN   \n",
       "558              0         NaN   \n",
       "559              0         NaN   \n",
       "\n",
       "                                                 Tweet  \n",
       "0    We are living in scary times in Canada. Gov’t ...  \n",
       "1    Just as bad in Canada. In fact, our government...  \n",
       "2    It was only a matter of time before the mainst...  \n",
       "3    Russia's taking no chances: Foreigners infecte...  \n",
       "4    Although there is now a presumptive confirmed ...  \n",
       "..                                                 ...  \n",
       "555  BREAKING: Harvard classes will move online sta...  \n",
       "556  Singularity University is hosting a FREE Virtu...  \n",
       "557  Coronavirus: how does it spread and what are t...  \n",
       "558  Stanford just cancelled classes for the rest o...  \n",
       "559  Tech conferences were cancelled in #Waterloo R...  \n",
       "\n",
       "[560 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(window_size = 15,\n",
    "                   lowercase = True,\n",
    "                   lemmatize = True,\n",
    "                   pmi = True,\n",
    "                   spmi_k = 5,\n",
    "                   laplace_smoothing = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_context_matrix = cm.fit_transform(tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>#</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>,</th>\n",
       "      <th>-</th>\n",
       "      <th>--</th>\n",
       "      <th>.</th>\n",
       "      <th>...</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoomer</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>—</th>\n",
       "      <th>‘</th>\n",
       "      <th>’</th>\n",
       "      <th>“</th>\n",
       "      <th>”</th>\n",
       "      <th>❝real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>2.424239</td>\n",
       "      <td>0.173120</td>\n",
       "      <td>-2.192211</td>\n",
       "      <td>-1.505043</td>\n",
       "      <td>-0.618213</td>\n",
       "      <td>-0.828241</td>\n",
       "      <td>-2.030626</td>\n",
       "      <td>0.377325</td>\n",
       "      <td>0.038504</td>\n",
       "      <td>-0.649706</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.001601</td>\n",
       "      <td>-2.011793</td>\n",
       "      <td>-2.002028</td>\n",
       "      <td>-1.998181</td>\n",
       "      <td>-1.339135</td>\n",
       "      <td>-2.045441</td>\n",
       "      <td>0.798712</td>\n",
       "      <td>0.025324</td>\n",
       "      <td>-1.029131</td>\n",
       "      <td>-1.309734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>0.173120</td>\n",
       "      <td>2.360850</td>\n",
       "      <td>-0.746419</td>\n",
       "      <td>-0.752397</td>\n",
       "      <td>0.863298</td>\n",
       "      <td>-0.075596</td>\n",
       "      <td>-1.501124</td>\n",
       "      <td>1.258224</td>\n",
       "      <td>-2.204583</td>\n",
       "      <td>-2.199646</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.858394</td>\n",
       "      <td>-2.175438</td>\n",
       "      <td>-2.165674</td>\n",
       "      <td>-2.854974</td>\n",
       "      <td>-1.790463</td>\n",
       "      <td>-1.292796</td>\n",
       "      <td>0.699605</td>\n",
       "      <td>-1.236934</td>\n",
       "      <td>-1.375098</td>\n",
       "      <td>-2.859674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>-2.192211</td>\n",
       "      <td>-0.746419</td>\n",
       "      <td>-0.881736</td>\n",
       "      <td>1.510181</td>\n",
       "      <td>-0.165188</td>\n",
       "      <td>-1.309525</td>\n",
       "      <td>-1.818762</td>\n",
       "      <td>-0.158026</td>\n",
       "      <td>-1.135927</td>\n",
       "      <td>-1.824138</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.789738</td>\n",
       "      <td>-1.799929</td>\n",
       "      <td>-1.790165</td>\n",
       "      <td>-1.786318</td>\n",
       "      <td>-1.820419</td>\n",
       "      <td>-1.833577</td>\n",
       "      <td>-0.781184</td>\n",
       "      <td>-1.266890</td>\n",
       "      <td>-1.915880</td>\n",
       "      <td>-1.791018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>-1.505043</td>\n",
       "      <td>-0.752397</td>\n",
       "      <td>1.510181</td>\n",
       "      <td>-0.893693</td>\n",
       "      <td>-0.171166</td>\n",
       "      <td>-1.315503</td>\n",
       "      <td>-1.824741</td>\n",
       "      <td>-0.009854</td>\n",
       "      <td>-1.141905</td>\n",
       "      <td>-1.830116</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.795717</td>\n",
       "      <td>-1.805908</td>\n",
       "      <td>-1.796144</td>\n",
       "      <td>-1.792297</td>\n",
       "      <td>-1.826398</td>\n",
       "      <td>-1.839556</td>\n",
       "      <td>-0.787163</td>\n",
       "      <td>-1.272869</td>\n",
       "      <td>-1.921859</td>\n",
       "      <td>-1.796996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>-0.618213</td>\n",
       "      <td>0.863298</td>\n",
       "      <td>-0.165188</td>\n",
       "      <td>-0.171166</td>\n",
       "      <td>1.306332</td>\n",
       "      <td>-0.261620</td>\n",
       "      <td>-1.033221</td>\n",
       "      <td>1.190300</td>\n",
       "      <td>-1.266676</td>\n",
       "      <td>-1.038597</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.227341</td>\n",
       "      <td>-1.930679</td>\n",
       "      <td>-2.614062</td>\n",
       "      <td>-2.610215</td>\n",
       "      <td>-1.545704</td>\n",
       "      <td>-1.271180</td>\n",
       "      <td>0.614122</td>\n",
       "      <td>-0.011346</td>\n",
       "      <td>-0.542552</td>\n",
       "      <td>-2.614915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>-2.045441</td>\n",
       "      <td>-1.292796</td>\n",
       "      <td>-1.833577</td>\n",
       "      <td>-1.839556</td>\n",
       "      <td>-1.271180</td>\n",
       "      <td>-1.855901</td>\n",
       "      <td>-1.671992</td>\n",
       "      <td>-1.292190</td>\n",
       "      <td>-1.682303</td>\n",
       "      <td>-1.677367</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.642968</td>\n",
       "      <td>-1.653159</td>\n",
       "      <td>-1.643394</td>\n",
       "      <td>-1.639547</td>\n",
       "      <td>-1.673649</td>\n",
       "      <td>-1.686807</td>\n",
       "      <td>0.058733</td>\n",
       "      <td>-1.813267</td>\n",
       "      <td>-1.769109</td>\n",
       "      <td>-1.644247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>0.798712</td>\n",
       "      <td>0.699605</td>\n",
       "      <td>-0.781184</td>\n",
       "      <td>-0.787163</td>\n",
       "      <td>0.614122</td>\n",
       "      <td>-0.467036</td>\n",
       "      <td>-2.229037</td>\n",
       "      <td>1.007236</td>\n",
       "      <td>-0.447589</td>\n",
       "      <td>-2.234412</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.200012</td>\n",
       "      <td>-2.210204</td>\n",
       "      <td>-2.200439</td>\n",
       "      <td>-2.196592</td>\n",
       "      <td>-2.230694</td>\n",
       "      <td>0.058733</td>\n",
       "      <td>1.309977</td>\n",
       "      <td>0.268746</td>\n",
       "      <td>0.238795</td>\n",
       "      <td>-1.508145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“</th>\n",
       "      <td>0.025324</td>\n",
       "      <td>-1.236934</td>\n",
       "      <td>-1.266890</td>\n",
       "      <td>-1.272869</td>\n",
       "      <td>-0.011346</td>\n",
       "      <td>-0.596067</td>\n",
       "      <td>-1.105304</td>\n",
       "      <td>-0.137716</td>\n",
       "      <td>-1.115616</td>\n",
       "      <td>-1.110680</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.769428</td>\n",
       "      <td>-1.779619</td>\n",
       "      <td>-1.769854</td>\n",
       "      <td>-1.766007</td>\n",
       "      <td>-1.106961</td>\n",
       "      <td>-1.813267</td>\n",
       "      <td>0.268746</td>\n",
       "      <td>-0.330289</td>\n",
       "      <td>1.148953</td>\n",
       "      <td>-1.770707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>”</th>\n",
       "      <td>-1.029131</td>\n",
       "      <td>-1.375098</td>\n",
       "      <td>-1.915880</td>\n",
       "      <td>-1.921859</td>\n",
       "      <td>-0.542552</td>\n",
       "      <td>-0.839592</td>\n",
       "      <td>-1.061147</td>\n",
       "      <td>-0.344873</td>\n",
       "      <td>-1.071459</td>\n",
       "      <td>-1.759670</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.725270</td>\n",
       "      <td>-1.735461</td>\n",
       "      <td>-1.725697</td>\n",
       "      <td>-1.721850</td>\n",
       "      <td>-1.062804</td>\n",
       "      <td>-1.769109</td>\n",
       "      <td>0.238795</td>\n",
       "      <td>1.148953</td>\n",
       "      <td>0.345813</td>\n",
       "      <td>-1.726550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>❝real</th>\n",
       "      <td>-1.309734</td>\n",
       "      <td>-2.859674</td>\n",
       "      <td>-1.791018</td>\n",
       "      <td>-1.796996</td>\n",
       "      <td>-2.614915</td>\n",
       "      <td>-1.813342</td>\n",
       "      <td>-1.629432</td>\n",
       "      <td>-2.859068</td>\n",
       "      <td>-1.639744</td>\n",
       "      <td>-1.634807</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.600408</td>\n",
       "      <td>-1.610599</td>\n",
       "      <td>-1.600835</td>\n",
       "      <td>-1.596988</td>\n",
       "      <td>-1.631089</td>\n",
       "      <td>-1.644247</td>\n",
       "      <td>-1.508145</td>\n",
       "      <td>-1.770707</td>\n",
       "      <td>-1.726550</td>\n",
       "      <td>-1.601688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2325 rows × 2325 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              !         #         (         )         ,         -        --  \\\n",
       "!      2.424239  0.173120 -2.192211 -1.505043 -0.618213 -0.828241 -2.030626   \n",
       "#      0.173120  2.360850 -0.746419 -0.752397  0.863298 -0.075596 -1.501124   \n",
       "(     -2.192211 -0.746419 -0.881736  1.510181 -0.165188 -1.309525 -1.818762   \n",
       ")     -1.505043 -0.752397  1.510181 -0.893693 -0.171166 -1.315503 -1.824741   \n",
       ",     -0.618213  0.863298 -0.165188 -0.171166  1.306332 -0.261620 -1.033221   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "‘     -2.045441 -1.292796 -1.833577 -1.839556 -1.271180 -1.855901 -1.671992   \n",
       "’      0.798712  0.699605 -0.781184 -0.787163  0.614122 -0.467036 -2.229037   \n",
       "“      0.025324 -1.236934 -1.266890 -1.272869 -0.011346 -0.596067 -1.105304   \n",
       "”     -1.029131 -1.375098 -1.915880 -1.921859 -0.542552 -0.839592 -1.061147   \n",
       "❝real -1.309734 -2.859674 -1.791018 -1.796996 -2.614915 -1.813342 -1.629432   \n",
       "\n",
       "              .       ...         1  ...    zombie      zone    zoomer  \\\n",
       "!      0.377325  0.038504 -0.649706  ... -2.001601 -2.011793 -2.002028   \n",
       "#      1.258224 -2.204583 -2.199646  ... -2.858394 -2.175438 -2.165674   \n",
       "(     -0.158026 -1.135927 -1.824138  ... -1.789738 -1.799929 -1.790165   \n",
       ")     -0.009854 -1.141905 -1.830116  ... -1.795717 -1.805908 -1.796144   \n",
       ",      1.190300 -1.266676 -1.038597  ... -1.227341 -1.930679 -2.614062   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "‘     -1.292190 -1.682303 -1.677367  ... -1.642968 -1.653159 -1.643394   \n",
       "’      1.007236 -0.447589 -2.234412  ... -2.200012 -2.210204 -2.200439   \n",
       "“     -0.137716 -1.115616 -1.110680  ... -1.769428 -1.779619 -1.769854   \n",
       "”     -0.344873 -1.071459 -1.759670  ... -1.725270 -1.735461 -1.725697   \n",
       "❝real -2.859068 -1.639744 -1.634807  ... -1.600408 -1.610599 -1.600835   \n",
       "\n",
       "       zuckerberg         —         ‘         ’         “         ”     ❝real  \n",
       "!       -1.998181 -1.339135 -2.045441  0.798712  0.025324 -1.029131 -1.309734  \n",
       "#       -2.854974 -1.790463 -1.292796  0.699605 -1.236934 -1.375098 -2.859674  \n",
       "(       -1.786318 -1.820419 -1.833577 -0.781184 -1.266890 -1.915880 -1.791018  \n",
       ")       -1.792297 -1.826398 -1.839556 -0.787163 -1.272869 -1.921859 -1.796996  \n",
       ",       -2.610215 -1.545704 -1.271180  0.614122 -0.011346 -0.542552 -2.614915  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "‘       -1.639547 -1.673649 -1.686807  0.058733 -1.813267 -1.769109 -1.644247  \n",
       "’       -2.196592 -2.230694  0.058733  1.309977  0.268746  0.238795 -1.508145  \n",
       "“       -1.766007 -1.106961 -1.813267  0.268746 -0.330289  1.148953 -1.770707  \n",
       "”       -1.721850 -1.062804 -1.769109  0.238795  1.148953  0.345813 -1.726550  \n",
       "❝real   -1.596988 -1.631089 -1.644247 -1.508145 -1.770707 -1.726550 -1.601688  \n",
       "\n",
       "[2325 rows x 2325 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(word_context_matrix, index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2325, 2325)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_context_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = FastICA(n_components = 2)\n",
    "std_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.72606037e-02, -1.28890174e-01],\n",
       "       [-9.22792176e-01, -8.64836729e-02],\n",
       "       [ 1.60673890e-02, -6.87884856e-02],\n",
       "       ...,\n",
       "       [ 3.11473373e-02, -6.58501433e-02],\n",
       "       [ 2.24253035e-02, -4.76632582e-02],\n",
       "       [-2.36311477e-04,  4.27958249e-03]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std = std_scaler.fit_transform(word_context_matrix)\n",
    "\n",
    "matrix = ica.fit_transform(X_std)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comp 1</th>\n",
       "      <th>Comp 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>-0.027261</td>\n",
       "      <td>-0.128890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>-0.922792</td>\n",
       "      <td>-0.086484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>0.016067</td>\n",
       "      <td>-0.068788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>0.017622</td>\n",
       "      <td>-0.071343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.148803</td>\n",
       "      <td>-0.355462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>0.004360</td>\n",
       "      <td>-0.012692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>0.005944</td>\n",
       "      <td>-0.195189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“</th>\n",
       "      <td>0.031147</td>\n",
       "      <td>-0.065850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>”</th>\n",
       "      <td>0.022425</td>\n",
       "      <td>-0.047663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>❝real</th>\n",
       "      <td>-0.000236</td>\n",
       "      <td>0.004280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2325 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Comp 1    Comp 2\n",
       "!     -0.027261 -0.128890\n",
       "#     -0.922792 -0.086484\n",
       "(      0.016067 -0.068788\n",
       ")      0.017622 -0.071343\n",
       ",      0.148803 -0.355462\n",
       "...         ...       ...\n",
       "‘      0.004360 -0.012692\n",
       "’      0.005944 -0.195189\n",
       "“      0.031147 -0.065850\n",
       "”      0.022425 -0.047663\n",
       "❝real -0.000236  0.004280\n",
       "\n",
       "[2325 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(matrix,\n",
    "                  index = cm.vocabulary,\n",
    "                  columns = ['Comp {}'.format(i+1) for i in range(2)])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 62222 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 62222 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = [key for key in cm.vocabulary.keys()]\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    \n",
    "    #if re.match('^co[rv]', word):\n",
    "    \n",
    "        x = df['Comp 1'][i]\n",
    "        y = df['Comp 2'][i]\n",
    "\n",
    "        plt.scatter(x, y)\n",
    "        plt.text(x, y, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set word embeddings for text classification\n",
    "ica = FastICA(n_components = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.34158215e-03,  3.57856276e-03, -9.95275688e-04, ...,\n",
       "        -8.86358763e-05, -2.30983630e-03, -1.16138534e-03],\n",
       "       [ 4.45891107e-03, -6.12854880e-03,  1.78346264e-03, ...,\n",
       "        -4.39696577e-03, -5.38257526e-03, -3.51365764e-03],\n",
       "       [ 1.25200364e-03, -6.05810463e-03, -8.18295636e-04, ...,\n",
       "        -2.54338323e-03, -7.45690911e-03,  6.49285201e-01],\n",
       "       ...,\n",
       "       [-1.23866855e-02, -9.73248393e-03, -2.96796565e-03, ...,\n",
       "         1.51404296e-03, -9.08825371e-03,  1.99195322e-02],\n",
       "       [ 3.62757812e-03,  1.39583917e-02,  1.17058118e-02, ...,\n",
       "        -3.34047557e-03,  8.55857482e-03, -1.35366102e-02],\n",
       "       [-4.61293730e-03, -8.13190832e-05,  7.93513917e-03, ...,\n",
       "         4.46269977e-03,  6.34963699e-03, -2.89800178e-03]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = ica.fit_transform(X_std)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out target\n",
    "y = tweets['Is_Unreliable']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derive text vectors from word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_vectors(word_embeddings,\n",
    "                     word_index_dict,\n",
    "                     text_list,\n",
    "                     remove_stopwords = True,\n",
    "                     lowercase = True,\n",
    "                     lemmatize = True,\n",
    "                     add_start_end_tokens = True):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    for k in range(len(text_list)):\n",
    "        text = text_list[k]\n",
    "        text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "        text_vec = np.zeros(word_embeddings.shape[1])\n",
    "        words = word_tokenize(text)\n",
    "        tracker = 0 # to track whether we've encountered a word for which we have an embedding (in each tweet)\n",
    "        \n",
    "        if remove_stopwords:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                if word.lower() not in set(stopwords.words('english')):\n",
    "                    clean_words.append(word)\n",
    "            words = clean_words\n",
    "\n",
    "        if lowercase:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                clean_words.append(word.lower())\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if lemmatize:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                PoS_tag = pos_tag([word])[0][1]\n",
    "\n",
    "                # to change contractions to full word form\n",
    "                if word in contractions:\n",
    "                    word = contractions[word]\n",
    "\n",
    "                if PoS_tag[0].upper() in 'JNVR':\n",
    "                    word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                else:\n",
    "                    word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                clean_words.append(word)\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if add_start_end_tokens:\n",
    "            words = ['<START>'] + words + ['<END>']\n",
    "        \n",
    "        for i in range(len(words)):\n",
    "            word = words[i]\n",
    "            if word in word_index_dict:\n",
    "                word_embed_vec = word_embeddings[word_index_dict[word],:]\n",
    "                if tracker == 0:\n",
    "                    text_matrix = word_embed_vec\n",
    "                else:\n",
    "                    text_matrix = np.vstack((text_matrix, word_embed_vec))\n",
    "                    \n",
    "                # only increment if we have come across a word in the embeddings dictionary\n",
    "                tracker += 1\n",
    "                    \n",
    "        for j in range(len(text_vec)):\n",
    "            text_vec[j] = text_matrix[:,j].mean()\n",
    "            \n",
    "        if k == 0:\n",
    "            full_matrix = text_vec\n",
    "        else:\n",
    "            full_matrix = np.vstack((full_matrix, text_vec))\n",
    "            \n",
    "    return full_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_text_vectors(embeddings, cm.vocabulary, tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 150)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.66264769e-02, -6.92473630e-02, -1.76017929e-03, ...,\n",
       "        -6.82868963e-03,  2.90461038e-04,  2.80204796e-03],\n",
       "       [ 6.34153597e-04, -6.41016138e-02, -3.84890944e-04, ...,\n",
       "        -2.24701707e-03,  1.68361311e-03,  9.88500000e-05],\n",
       "       [-4.84114149e-04, -6.92015874e-02,  5.12435041e-03, ...,\n",
       "        -7.19753378e-04, -1.66008129e-03, -5.48878882e-04],\n",
       "       ...,\n",
       "       [-1.42614411e-04, -8.15176794e-02,  5.76277505e-04, ...,\n",
       "         5.00763655e-04,  1.65600634e-02,  3.08852844e-03],\n",
       "       [-5.66219134e-02, -2.20454945e-03,  7.43682705e-04, ...,\n",
       "        -2.83596397e-03,  1.91329120e-03, -8.40559577e-03],\n",
       "       [ 5.58619007e-03,  1.84108697e-03,  1.00708546e-04, ...,\n",
       "        -3.06694378e-03, -2.80870901e-04, -2.51563997e-03]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, KFold, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipe = Pipeline([\n",
    "    ('classify', SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC hyperparams to optimize\n",
    "kernel = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "C = [0.001, 0.01, 0.1, 1, 10]\n",
    "# set up parameter grid\n",
    "params = {\n",
    "    'classify__kernel': kernel,\n",
    "    'classify__C': C\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CV scheme for inner and outer loops\n",
    "inner_cv = KFold(n_splits = 3, shuffle = True, random_state = 1)\n",
    "outer_cv = KFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "\n",
    "# Set up GridSearch for inner loop\n",
    "grid_SVC = GridSearchCV(pipe, params, cv = inner_cv)\n",
    "#grid_SVC.fit(X, y)\n",
    "\n",
    "# Nested CV scores\n",
    "scores = cross_validate(grid_SVC,\n",
    "                        X = X,\n",
    "                        y = y,\n",
    "                        cv = outer_cv,\n",
    "                        scoring = ['roc_auc', 'accuracy', 'f1', 'precision', 'recall'],\n",
    "                        return_estimator = True)\n",
    "auc = scores['test_roc_auc']\n",
    "accuracy = scores['test_accuracy']\n",
    "f1 = scores['test_f1']\n",
    "precision = scores['test_precision']\n",
    "recall = scores['test_recall']\n",
    "estimators = scores['estimator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9130682981458449"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8321428571428571"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8392856506690499"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8067342584656905"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8782069580731491"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 10, 'classify__kernel': 'linear'}\n",
      "\n",
      "\n",
      "{'classify__C': 10, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in estimators:\n",
    "    print(i.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
