{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Word Context Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.decomposition import FastICA, TruncatedSVD, PCA, NMF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert contractions picked up by word_tokenize() into full words\n",
    "contractions = {\n",
    "    \"n't\": 'not',\n",
    "    \"'ve\": 'have',\n",
    "    \"'s\": 'is', # note that this will include possessive nouns\n",
    "    'gonna': 'going to',\n",
    "    'gotta': 'got to',\n",
    "    \"'d\": 'would',\n",
    "    \"'ll\": 'will',\n",
    "    \"'re\": 'are',\n",
    "    \"'m\": 'am',\n",
    "    'wanna': 'want to'\n",
    "}\n",
    "\n",
    "# to convert nltk_pos tags to wordnet-compatible PoS tags\n",
    "def convert_pos_wordnet(tag):\n",
    "    tag_abbr = tag[0].upper()\n",
    "    tag_dict = {\n",
    "        'J': wordnet.ADJ,\n",
    "        'N': wordnet.NOUN,\n",
    "        'V': wordnet.VERB,\n",
    "        'R': wordnet.ADV\n",
    "    }\n",
    "                \n",
    "    if tag_abbr in tag_dict:\n",
    "        return tag_dict[tag_abbr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextMatrix(TransformerMixin):\n",
    "    \n",
    "    # initialize class & private variables\n",
    "    def __init__(self,\n",
    "                 window_size = 4,\n",
    "                 remove_stopwords = True,\n",
    "                 add_start_end_tokens = True,\n",
    "                 lowercase = False,\n",
    "                 lemmatize = False,\n",
    "                 pmi = False,\n",
    "                 spmi_k = 1,\n",
    "                 laplace_smoothing = 0,\n",
    "                 pmi_positive = False,\n",
    "                 sppmi_k = 1):\n",
    "        \n",
    "        \"\"\" Params:\n",
    "                window_size: size of +/- context window (default = 4)\n",
    "                remove_stopwords: boolean, whether or not to remove NLTK English stopwords\n",
    "                add_start_end_tokens: boolean, whether or not to append <START> and <END> to the\n",
    "                beginning/end of each document in the corpus (default = True)\n",
    "                lowercase: boolean, whether or not to convert words to all lowercase\n",
    "                lemmatize: boolean, whether or not to lemmatize input text\n",
    "                pmi: boolean, whether or not to compute pointwise mutual information\n",
    "                pmi_positive: boolean, whether or not to compute positive PMI\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.add_start_end_tokens = add_start_end_tokens\n",
    "        self.lowercase = lowercase\n",
    "        self.lemmatize = lemmatize\n",
    "        self.pmi = pmi\n",
    "        self.spmi_k = spmi_k\n",
    "        self.laplace_smoothing = laplace_smoothing\n",
    "        self.pmi_positive = pmi_positive\n",
    "        self.sppmi_k = sppmi_k\n",
    "        self.corpus = None\n",
    "        self.clean_corpus = None\n",
    "        self.vocabulary = None\n",
    "        self.X = None\n",
    "        self.doc_terms_lists = None\n",
    "    \n",
    "    def fit(self, corpus, y = None):\n",
    "        \n",
    "        \"\"\" Learn the dictionary of all unique tokens for given corpus.\n",
    "        \n",
    "            Params:\n",
    "                corpus: list of strings\n",
    "            \n",
    "            Returns: self\n",
    "        \"\"\"\n",
    "        self.corpus = corpus\n",
    "        \n",
    "        term_dict = dict()\n",
    "        k = 0\n",
    "        corpus_words = []\n",
    "        clean_corpus = []\n",
    "        doc_terms_lists = []\n",
    "        detokenizer = TreebankWordDetokenizer()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        for text in corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "            \n",
    "            # detokenize trick taken from this StackOverflow post:\n",
    "            # https://stackoverflow.com/questions/21948019/python-untokenize-a-sentence\n",
    "            # and NLTK treebank documentation:\n",
    "            # https://www.nltk.org/_modules/nltk/tokenize/treebank.html\n",
    "            text = detokenizer.detokenize(words)\n",
    "            clean_corpus.append(text)\n",
    "            \n",
    "            [corpus_words.append(word) for word in words]\n",
    "            \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            doc_terms_lists.append(words)\n",
    "            \n",
    "        self.clean_corpus = clean_corpus\n",
    "        \n",
    "        self.doc_terms_lists = doc_terms_lists\n",
    "        \n",
    "        corpus_words = list(set(corpus_words))\n",
    "        \n",
    "        if self.add_start_end_tokens:\n",
    "            corpus_words = ['<START>'] + corpus_words + ['<END>']\n",
    "        \n",
    "        corpus_words = sorted(corpus_words)\n",
    "        \n",
    "        for el in corpus_words:\n",
    "            term_dict[el] = k\n",
    "            k += 1\n",
    "            \n",
    "        self.vocabulary = term_dict\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def transform(self, new_corpus = None, y = None):\n",
    "        \n",
    "        \"\"\" Compute the co-occurrence matrix for given corpus and window_size, using term dictionary\n",
    "            obtained with fit method.\n",
    "        \n",
    "            Returns: term-context co-occurrence matrix (shape: target terms by context terms) with\n",
    "            raw counts\n",
    "        \"\"\"\n",
    "        num_terms = len(self.vocabulary)\n",
    "        window = self.window_size\n",
    "        X = np.full((num_terms, num_terms), self.laplace_smoothing)\n",
    "        \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        if type(new_corpus) != list:\n",
    "            new_corpus = self.corpus\n",
    "        \n",
    "        for text in new_corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            for i in range(len(words)):\n",
    "                target = words[i]\n",
    "                \n",
    "                # check to see if target word is in the dictionary; if not, skip\n",
    "                if target in self.vocabulary:\n",
    "                    \n",
    "                    # grab index from dictionary\n",
    "                    target_dict_index = self.vocabulary[target]\n",
    "                    \n",
    "                    # find left-most and right-most window indices for each target word\n",
    "                    left_end_index = max(i - window, 0)\n",
    "                    right_end_index = min(i + window, len(words) - 1)\n",
    "                    \n",
    "                    # loop over all words within window\n",
    "                    # NOTE: this will include the target word; make sure to skip over it\n",
    "                    for j in range(left_end_index, right_end_index + 1):\n",
    "                        \n",
    "                        # skip \"context word\" where the \"context word\" index is equal to the\n",
    "                        # target word index\n",
    "                        if j != i:\n",
    "                            context_word = words[j]\n",
    "                            \n",
    "                            # check to see if context word is in the fitted dictionary; if\n",
    "                            # not, skip\n",
    "                            if context_word in self.vocabulary:\n",
    "                                X[target_dict_index, self.vocabulary[context_word]] += 1\n",
    "        \n",
    "        # if pmi = True, compute pmi matrix from word-context raw frequencies\n",
    "        # more concise code taken from this StackOverflow post:\n",
    "        # https://stackoverflow.com/questions/58701337/how-to-construct-ppmi-matrix-from-a-text-corpus\n",
    "        if self.pmi:\n",
    "            denom = X.sum()\n",
    "            col_sums = X.sum(axis = 0)\n",
    "            row_sums = X.sum(axis = 1)\n",
    "            \n",
    "            expected = np.outer(row_sums, col_sums)/denom\n",
    "            \n",
    "            X = X/expected\n",
    "            \n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(X.shape[1]):\n",
    "                \n",
    "                    if X[i,j] > 0:\n",
    "                        X[i,j] = np.log(X[i,j]) - np.log(self.spmi_k)\n",
    "                        \n",
    "                        if self.pmi_positive:\n",
    "                            X[i,j] = max(X[i,j] - np.log(self.sppmi_k), 0)\n",
    "        \n",
    "        # note that X is a dense matrix\n",
    "        self.X = X\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(lowercase = True, lemmatize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [\n",
    "    \"Coronavirus is a fake liberal hoax.\",\n",
    "    \"Trump won't do anything about coronavirus.\",\n",
    "    \"The liberal fake news media always blame Pres Trump.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ContextMatrix at 0x1a1ee26210>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.fit(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <th>always</th>\n",
       "      <th>anything</th>\n",
       "      <th>blame</th>\n",
       "      <th>coronavirus</th>\n",
       "      <th>fake</th>\n",
       "      <th>hoax</th>\n",
       "      <th>liberal</th>\n",
       "      <th>medium</th>\n",
       "      <th>news</th>\n",
       "      <th>pres</th>\n",
       "      <th>trump</th>\n",
       "      <th>wont</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>always</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anything</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blame</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronavirus</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fake</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoax</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pres</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wont</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             .  <END>  <START>  always  anything  blame  coronavirus  fake  \\\n",
       ".            0      3        0       1         1      1            2     1   \n",
       "<END>        3      0        0       0         1      1            1     1   \n",
       "<START>      0      0        0       0         1      0            2     2   \n",
       "always       1      0        0       0         0      1            0     1   \n",
       "anything     1      1        1       0         0      0            1     0   \n",
       "blame        1      1        0       1         0      0            0     1   \n",
       "coronavirus  2      1        2       0         1      0            0     1   \n",
       "fake         1      1        2       1         0      1            1     0   \n",
       "hoax         1      1        1       0         0      0            1     1   \n",
       "liberal      1      1        2       1         0      0            1     2   \n",
       "medium       0      0        1       1         0      1            0     1   \n",
       "news         0      0        1       1         0      1            0     1   \n",
       "pres         1      1        0       1         0      1            0     0   \n",
       "trump        2      1        1       1         1      1            1     0   \n",
       "wont         1      1        1       0         1      0            1     0   \n",
       "\n",
       "             hoax  liberal  medium  news  pres  trump  wont  \n",
       ".               1        1       0     0     1      2     1  \n",
       "<END>           1        1       0     0     1      1     1  \n",
       "<START>         1        2       1     1     0      1     1  \n",
       "always          0        1       1     1     1      1     0  \n",
       "anything        0        0       0     0     0      1     1  \n",
       "blame           0        0       1     1     1      1     0  \n",
       "coronavirus     1        1       0     0     0      1     1  \n",
       "fake            1        2       1     1     0      0     0  \n",
       "hoax            0        1       0     0     0      0     0  \n",
       "liberal         1        0       1     1     0      0     0  \n",
       "medium          0        1       0     1     1      1     0  \n",
       "news            0        1       1     0     1      0     0  \n",
       "pres            0        0       1     1     0      1     0  \n",
       "trump           0        0       1     0     1      0     1  \n",
       "wont            0        0       0     0     0      1     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cm.transform(tweets), index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coronavirus fake liberal hoax.',\n",
       " 'trump wont anything coronavirus.',\n",
       " 'liberal fake news medium always blame pres trump.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.clean_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coronavirus is a fake liberal hoax.',\n",
       " \"Trump won't do anything about coronavirus.\",\n",
       " 'The liberal fake news media always blame Pres Trump.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train embeddings using tweets as corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('COVID19_Dataset-text_labels_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Unreliable</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 3, 6, 9</td>\n",
       "      <td>We are living in scary times in Canada. Gov’t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 6, 8, 9</td>\n",
       "      <td>Just as bad in Canada. In fact, our government...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 4, 9</td>\n",
       "      <td>It was only a matter of time before the mainst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8</td>\n",
       "      <td>Russia's taking no chances: Foreigners infecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8, 9</td>\n",
       "      <td>Although there is now a presumptive confirmed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BREAKING: Harvard classes will move online sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singularity University is hosting a FREE Virtu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus: how does it spread and what are t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stanford just cancelled classes for the rest o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tech conferences were cancelled in #Waterloo R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Is_Unreliable    Category  \\\n",
       "0                1  1, 3, 6, 9   \n",
       "1                1  1, 6, 8, 9   \n",
       "2                1     1, 4, 9   \n",
       "3                1        6, 8   \n",
       "4                1     6, 8, 9   \n",
       "..             ...         ...   \n",
       "555              0         NaN   \n",
       "556              0         NaN   \n",
       "557              0         NaN   \n",
       "558              0         NaN   \n",
       "559              0         NaN   \n",
       "\n",
       "                                                 Tweet  \n",
       "0    We are living in scary times in Canada. Gov’t ...  \n",
       "1    Just as bad in Canada. In fact, our government...  \n",
       "2    It was only a matter of time before the mainst...  \n",
       "3    Russia's taking no chances: Foreigners infecte...  \n",
       "4    Although there is now a presumptive confirmed ...  \n",
       "..                                                 ...  \n",
       "555  BREAKING: Harvard classes will move online sta...  \n",
       "556  Singularity University is hosting a FREE Virtu...  \n",
       "557  Coronavirus: how does it spread and what are t...  \n",
       "558  Stanford just cancelled classes for the rest o...  \n",
       "559  Tech conferences were cancelled in #Waterloo R...  \n",
       "\n",
       "[560 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(window_size = 15, lowercase = True, lemmatize = True, pmi = True, laplace_smoothing = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_context_matrix = cm.fit_transform(tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>#</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>,</th>\n",
       "      <th>-</th>\n",
       "      <th>--</th>\n",
       "      <th>.</th>\n",
       "      <th>...</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoomer</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>—</th>\n",
       "      <th>‘</th>\n",
       "      <th>’</th>\n",
       "      <th>“</th>\n",
       "      <th>”</th>\n",
       "      <th>❝real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>4.033677</td>\n",
       "      <td>1.782558</td>\n",
       "      <td>-0.582773</td>\n",
       "      <td>0.104395</td>\n",
       "      <td>0.991225</td>\n",
       "      <td>0.781197</td>\n",
       "      <td>-0.421188</td>\n",
       "      <td>1.986763</td>\n",
       "      <td>1.647942</td>\n",
       "      <td>0.959731</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.392164</td>\n",
       "      <td>-0.402355</td>\n",
       "      <td>-0.392590</td>\n",
       "      <td>-0.388743</td>\n",
       "      <td>0.270302</td>\n",
       "      <td>-0.436003</td>\n",
       "      <td>2.408150</td>\n",
       "      <td>1.634762</td>\n",
       "      <td>0.580307</td>\n",
       "      <td>0.299704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>1.782558</td>\n",
       "      <td>3.970288</td>\n",
       "      <td>0.863019</td>\n",
       "      <td>0.857040</td>\n",
       "      <td>2.472735</td>\n",
       "      <td>1.533842</td>\n",
       "      <td>0.108314</td>\n",
       "      <td>2.867662</td>\n",
       "      <td>-0.595145</td>\n",
       "      <td>-0.590209</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.248956</td>\n",
       "      <td>-0.566000</td>\n",
       "      <td>-0.556236</td>\n",
       "      <td>-1.245536</td>\n",
       "      <td>-0.181025</td>\n",
       "      <td>0.316642</td>\n",
       "      <td>2.309043</td>\n",
       "      <td>0.372504</td>\n",
       "      <td>0.234340</td>\n",
       "      <td>-1.250236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>-0.582773</td>\n",
       "      <td>0.863019</td>\n",
       "      <td>0.727702</td>\n",
       "      <td>3.119619</td>\n",
       "      <td>1.444250</td>\n",
       "      <td>0.299913</td>\n",
       "      <td>-0.209324</td>\n",
       "      <td>1.451412</td>\n",
       "      <td>0.473511</td>\n",
       "      <td>-0.214700</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.180300</td>\n",
       "      <td>-0.190491</td>\n",
       "      <td>-0.180727</td>\n",
       "      <td>-0.176880</td>\n",
       "      <td>-0.210981</td>\n",
       "      <td>-0.224140</td>\n",
       "      <td>0.828254</td>\n",
       "      <td>0.342548</td>\n",
       "      <td>-0.306442</td>\n",
       "      <td>-0.181580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>0.104395</td>\n",
       "      <td>0.857040</td>\n",
       "      <td>3.119619</td>\n",
       "      <td>0.715745</td>\n",
       "      <td>1.438272</td>\n",
       "      <td>0.293935</td>\n",
       "      <td>-0.215303</td>\n",
       "      <td>1.599584</td>\n",
       "      <td>0.467533</td>\n",
       "      <td>-0.220678</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.186279</td>\n",
       "      <td>-0.196470</td>\n",
       "      <td>-0.186706</td>\n",
       "      <td>-0.182859</td>\n",
       "      <td>-0.216960</td>\n",
       "      <td>-0.230118</td>\n",
       "      <td>0.822275</td>\n",
       "      <td>0.336569</td>\n",
       "      <td>-0.312421</td>\n",
       "      <td>-0.187558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.991225</td>\n",
       "      <td>2.472735</td>\n",
       "      <td>1.444250</td>\n",
       "      <td>1.438272</td>\n",
       "      <td>2.915770</td>\n",
       "      <td>1.347818</td>\n",
       "      <td>0.576217</td>\n",
       "      <td>2.799738</td>\n",
       "      <td>0.342761</td>\n",
       "      <td>0.570841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382097</td>\n",
       "      <td>-0.321241</td>\n",
       "      <td>-1.004624</td>\n",
       "      <td>-1.000777</td>\n",
       "      <td>0.063734</td>\n",
       "      <td>0.338258</td>\n",
       "      <td>2.223560</td>\n",
       "      <td>1.598092</td>\n",
       "      <td>1.066886</td>\n",
       "      <td>-1.005477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>-0.436003</td>\n",
       "      <td>0.316642</td>\n",
       "      <td>-0.224140</td>\n",
       "      <td>-0.230118</td>\n",
       "      <td>0.338258</td>\n",
       "      <td>-0.246463</td>\n",
       "      <td>-0.062554</td>\n",
       "      <td>0.317248</td>\n",
       "      <td>-0.072865</td>\n",
       "      <td>-0.067929</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033530</td>\n",
       "      <td>-0.043721</td>\n",
       "      <td>-0.033956</td>\n",
       "      <td>-0.030109</td>\n",
       "      <td>-0.064211</td>\n",
       "      <td>-0.077369</td>\n",
       "      <td>1.668171</td>\n",
       "      <td>-0.203829</td>\n",
       "      <td>-0.159672</td>\n",
       "      <td>-0.034809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>2.408150</td>\n",
       "      <td>2.309043</td>\n",
       "      <td>0.828254</td>\n",
       "      <td>0.822275</td>\n",
       "      <td>2.223560</td>\n",
       "      <td>1.142402</td>\n",
       "      <td>-0.619599</td>\n",
       "      <td>2.616674</td>\n",
       "      <td>1.161849</td>\n",
       "      <td>-0.624974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.590575</td>\n",
       "      <td>-0.600766</td>\n",
       "      <td>-0.591001</td>\n",
       "      <td>-0.587154</td>\n",
       "      <td>-0.621256</td>\n",
       "      <td>1.668171</td>\n",
       "      <td>2.919415</td>\n",
       "      <td>1.878184</td>\n",
       "      <td>1.848233</td>\n",
       "      <td>0.101293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“</th>\n",
       "      <td>1.634762</td>\n",
       "      <td>0.372504</td>\n",
       "      <td>0.342548</td>\n",
       "      <td>0.336569</td>\n",
       "      <td>1.598092</td>\n",
       "      <td>1.013371</td>\n",
       "      <td>0.504133</td>\n",
       "      <td>1.471722</td>\n",
       "      <td>0.493822</td>\n",
       "      <td>0.498758</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.159990</td>\n",
       "      <td>-0.170181</td>\n",
       "      <td>-0.160416</td>\n",
       "      <td>-0.156569</td>\n",
       "      <td>0.502476</td>\n",
       "      <td>-0.203829</td>\n",
       "      <td>1.878184</td>\n",
       "      <td>1.279149</td>\n",
       "      <td>2.758391</td>\n",
       "      <td>-0.161269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>”</th>\n",
       "      <td>0.580307</td>\n",
       "      <td>0.234340</td>\n",
       "      <td>-0.306442</td>\n",
       "      <td>-0.312421</td>\n",
       "      <td>1.066886</td>\n",
       "      <td>0.769846</td>\n",
       "      <td>0.548291</td>\n",
       "      <td>1.264565</td>\n",
       "      <td>0.537979</td>\n",
       "      <td>-0.150232</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115832</td>\n",
       "      <td>-0.126024</td>\n",
       "      <td>-0.116259</td>\n",
       "      <td>-0.112412</td>\n",
       "      <td>0.546634</td>\n",
       "      <td>-0.159672</td>\n",
       "      <td>1.848233</td>\n",
       "      <td>2.758391</td>\n",
       "      <td>1.955250</td>\n",
       "      <td>-0.117112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>❝real</th>\n",
       "      <td>0.299704</td>\n",
       "      <td>-1.250236</td>\n",
       "      <td>-0.181580</td>\n",
       "      <td>-0.187558</td>\n",
       "      <td>-1.005477</td>\n",
       "      <td>-0.203904</td>\n",
       "      <td>-0.019994</td>\n",
       "      <td>-1.249630</td>\n",
       "      <td>-0.030306</td>\n",
       "      <td>-0.025370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009030</td>\n",
       "      <td>-0.001161</td>\n",
       "      <td>0.008603</td>\n",
       "      <td>0.012450</td>\n",
       "      <td>-0.021651</td>\n",
       "      <td>-0.034809</td>\n",
       "      <td>0.101293</td>\n",
       "      <td>-0.161269</td>\n",
       "      <td>-0.117112</td>\n",
       "      <td>0.007750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2325 rows × 2325 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              !         #         (         )         ,         -        --  \\\n",
       "!      4.033677  1.782558 -0.582773  0.104395  0.991225  0.781197 -0.421188   \n",
       "#      1.782558  3.970288  0.863019  0.857040  2.472735  1.533842  0.108314   \n",
       "(     -0.582773  0.863019  0.727702  3.119619  1.444250  0.299913 -0.209324   \n",
       ")      0.104395  0.857040  3.119619  0.715745  1.438272  0.293935 -0.215303   \n",
       ",      0.991225  2.472735  1.444250  1.438272  2.915770  1.347818  0.576217   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "‘     -0.436003  0.316642 -0.224140 -0.230118  0.338258 -0.246463 -0.062554   \n",
       "’      2.408150  2.309043  0.828254  0.822275  2.223560  1.142402 -0.619599   \n",
       "“      1.634762  0.372504  0.342548  0.336569  1.598092  1.013371  0.504133   \n",
       "”      0.580307  0.234340 -0.306442 -0.312421  1.066886  0.769846  0.548291   \n",
       "❝real  0.299704 -1.250236 -0.181580 -0.187558 -1.005477 -0.203904 -0.019994   \n",
       "\n",
       "              .       ...         1  ...    zombie      zone    zoomer  \\\n",
       "!      1.986763  1.647942  0.959731  ... -0.392164 -0.402355 -0.392590   \n",
       "#      2.867662 -0.595145 -0.590209  ... -1.248956 -0.566000 -0.556236   \n",
       "(      1.451412  0.473511 -0.214700  ... -0.180300 -0.190491 -0.180727   \n",
       ")      1.599584  0.467533 -0.220678  ... -0.186279 -0.196470 -0.186706   \n",
       ",      2.799738  0.342761  0.570841  ...  0.382097 -0.321241 -1.004624   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "‘      0.317248 -0.072865 -0.067929  ... -0.033530 -0.043721 -0.033956   \n",
       "’      2.616674  1.161849 -0.624974  ... -0.590575 -0.600766 -0.591001   \n",
       "“      1.471722  0.493822  0.498758  ... -0.159990 -0.170181 -0.160416   \n",
       "”      1.264565  0.537979 -0.150232  ... -0.115832 -0.126024 -0.116259   \n",
       "❝real -1.249630 -0.030306 -0.025370  ...  0.009030 -0.001161  0.008603   \n",
       "\n",
       "       zuckerberg         —         ‘         ’         “         ”     ❝real  \n",
       "!       -0.388743  0.270302 -0.436003  2.408150  1.634762  0.580307  0.299704  \n",
       "#       -1.245536 -0.181025  0.316642  2.309043  0.372504  0.234340 -1.250236  \n",
       "(       -0.176880 -0.210981 -0.224140  0.828254  0.342548 -0.306442 -0.181580  \n",
       ")       -0.182859 -0.216960 -0.230118  0.822275  0.336569 -0.312421 -0.187558  \n",
       ",       -1.000777  0.063734  0.338258  2.223560  1.598092  1.066886 -1.005477  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "‘       -0.030109 -0.064211 -0.077369  1.668171 -0.203829 -0.159672 -0.034809  \n",
       "’       -0.587154 -0.621256  1.668171  2.919415  1.878184  1.848233  0.101293  \n",
       "“       -0.156569  0.502476 -0.203829  1.878184  1.279149  2.758391 -0.161269  \n",
       "”       -0.112412  0.546634 -0.159672  1.848233  2.758391  1.955250 -0.117112  \n",
       "❝real    0.012450 -0.021651 -0.034809  0.101293 -0.161269 -0.117112  0.007750  \n",
       "\n",
       "[2325 rows x 2325 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(word_context_matrix, index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2325, 2325)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_context_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = FastICA(n_components = 2)\n",
    "std_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.25909689e-01, -3.87629675e-02],\n",
       "       [ 2.98661076e-03, -9.26831110e-01],\n",
       "       [ 6.99563939e-02,  9.80406508e-03],\n",
       "       ...,\n",
       "       [ 6.83887346e-02,  2.50874266e-02],\n",
       "       [ 4.94899521e-02,  1.80395414e-02],\n",
       "       [-4.28346763e-03,  1.50248064e-04]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std = std_scaler.fit_transform(word_context_matrix)\n",
    "\n",
    "matrix = ica.fit_transform(X_std)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comp 1</th>\n",
       "      <th>Comp 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>0.125910</td>\n",
       "      <td>-0.038763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>0.002987</td>\n",
       "      <td>-0.926831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>0.069956</td>\n",
       "      <td>0.009804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>0.072641</td>\n",
       "      <td>0.011122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.367423</td>\n",
       "      <td>0.116170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>0.013033</td>\n",
       "      <td>0.003199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>0.194930</td>\n",
       "      <td>-0.011667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“</th>\n",
       "      <td>0.068389</td>\n",
       "      <td>0.025087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>”</th>\n",
       "      <td>0.049490</td>\n",
       "      <td>0.018040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>❝real</th>\n",
       "      <td>-0.004283</td>\n",
       "      <td>0.000150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2325 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Comp 1    Comp 2\n",
       "!      0.125910 -0.038763\n",
       "#      0.002987 -0.926831\n",
       "(      0.069956  0.009804\n",
       ")      0.072641  0.011122\n",
       ",      0.367423  0.116170\n",
       "...         ...       ...\n",
       "‘      0.013033  0.003199\n",
       "’      0.194930 -0.011667\n",
       "“      0.068389  0.025087\n",
       "”      0.049490  0.018040\n",
       "❝real -0.004283  0.000150\n",
       "\n",
       "[2325 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(matrix,\n",
    "                  index = cm.vocabulary,\n",
    "                  columns = ['Comp {}'.format(i+1) for i in range(2)])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 62222 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 62222 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = [key for key in cm.vocabulary.keys()]\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    \n",
    "    #if re.match('^co[rv]', word):\n",
    "    \n",
    "        x = df['Comp 1'][i]\n",
    "        y = df['Comp 2'][i]\n",
    "\n",
    "        plt.scatter(x, y)\n",
    "        plt.text(x, y, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set word embeddings for text classification\n",
    "ica = FastICA(n_components = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0015724 , -0.00485289, -0.00592636, ..., -0.00181885,\n",
       "        -0.00565601,  0.00160238],\n",
       "       [ 0.00301726,  0.00035001, -0.00432665, ...,  0.00287609,\n",
       "         0.00156166, -0.00185099],\n",
       "       [-0.00615536,  0.00809346, -0.00330172, ..., -0.00153324,\n",
       "         0.00200064,  0.00309819],\n",
       "       ...,\n",
       "       [ 0.00886764,  0.03545891,  0.02982997, ...,  0.00370373,\n",
       "        -0.01969881, -0.00591908],\n",
       "       [-0.01411894, -0.0231867 , -0.05352847, ..., -0.01227355,\n",
       "         0.00509935,  0.01673061],\n",
       "       [ 0.00875136, -0.00183771,  0.00212377, ..., -0.0044801 ,\n",
       "         0.00435891,  0.0004878 ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = ica.fit_transform(X_std)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out target\n",
    "y = tweets['Is_Unreliable']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derive text vectors from word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_vectors(word_embeddings,\n",
    "                     word_index_dict,\n",
    "                     text_list,\n",
    "                     remove_stopwords = True,\n",
    "                     lowercase = True,\n",
    "                     lemmatize = True,\n",
    "                     add_start_end_tokens = True):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    for k in range(len(text_list)):\n",
    "        text = text_list[k]\n",
    "        text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "        text_vec = np.zeros(word_embeddings.shape[1])\n",
    "        words = word_tokenize(text)\n",
    "        tracker = 0 # to track whether we've encountered a word for which we have an embedding (in each tweet)\n",
    "        \n",
    "        if remove_stopwords:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                if word.lower() not in set(stopwords.words('english')):\n",
    "                    clean_words.append(word)\n",
    "            words = clean_words\n",
    "\n",
    "        if lowercase:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                clean_words.append(word.lower())\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if lemmatize:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                PoS_tag = pos_tag([word])[0][1]\n",
    "\n",
    "                # to change contractions to full word form\n",
    "                if word in contractions:\n",
    "                    word = contractions[word]\n",
    "\n",
    "                if PoS_tag[0].upper() in 'JNVR':\n",
    "                    word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                else:\n",
    "                    word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                clean_words.append(word)\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if add_start_end_tokens:\n",
    "            words = ['<START>'] + words + ['<END>']\n",
    "        \n",
    "        for i in range(len(words)):\n",
    "            word = words[i]\n",
    "            if word in word_index_dict:\n",
    "                word_embed_vec = word_embeddings[word_index_dict[word],:]\n",
    "                if tracker == 0:\n",
    "                    text_matrix = word_embed_vec\n",
    "                else:\n",
    "                    text_matrix = np.vstack((text_matrix, word_embed_vec))\n",
    "                    \n",
    "                # only increment if we have come across a word in the embeddings dictionary\n",
    "                tracker += 1\n",
    "                    \n",
    "        for j in range(len(text_vec)):\n",
    "            text_vec[j] = text_matrix[:,j].mean()\n",
    "            \n",
    "        if k == 0:\n",
    "            full_matrix = text_vec\n",
    "        else:\n",
    "            full_matrix = np.vstack((full_matrix, text_vec))\n",
    "            \n",
    "    return full_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_text_vectors(embeddings, cm.vocabulary, tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 150)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.48361387e-03, -7.97198903e-02, -1.09715986e-02, ...,\n",
       "         3.10270685e-04, -4.81222353e-03,  3.17206211e-03],\n",
       "       [ 2.57770631e-05, -7.35342836e-02, -1.47735917e-02, ...,\n",
       "        -4.35540957e-03,  1.74343164e-03,  5.91719254e-04],\n",
       "       [ 2.38167414e-03, -7.36683565e-02, -7.87262037e-03, ...,\n",
       "        -1.67137675e-04,  3.44199097e-03, -5.53032110e-03],\n",
       "       ...,\n",
       "       [ 1.83860397e-03, -9.20482027e-02,  3.94603519e-03, ...,\n",
       "        -8.74659432e-04,  4.36220255e-04,  6.71184926e-03],\n",
       "       [-1.63988835e-03, -7.55621411e-02,  1.44438777e-02, ...,\n",
       "         1.29013885e-03,  6.95027700e-03,  1.94965162e-02],\n",
       "       [-8.32657116e-03, -3.14034862e-02,  4.19477670e-04, ...,\n",
       "        -6.98969675e-04, -5.74967791e-05,  1.57130518e-04]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, KFold, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipe = Pipeline([\n",
    "    ('classify', SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC hyperparams to optimize\n",
    "kernel = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "C = [0.001, 0.01, 0.1, 1, 10]\n",
    "# set up parameter grid\n",
    "params = {\n",
    "    'classify__kernel': kernel,\n",
    "    'classify__C': C\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CV scheme for inner and outer loops\n",
    "inner_cv = KFold(n_splits = 3, shuffle = True, random_state = 1)\n",
    "outer_cv = KFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "\n",
    "# Set up GridSearch for inner loop\n",
    "grid_SVC = GridSearchCV(pipe, params, cv = inner_cv)\n",
    "#grid_SVC.fit(X, y)\n",
    "\n",
    "# Nested CV scores\n",
    "scores = cross_validate(grid_SVC,\n",
    "                        X = X,\n",
    "                        y = y,\n",
    "                        cv = outer_cv,\n",
    "                        scoring = ['roc_auc', 'accuracy', 'f1', 'precision', 'recall'],\n",
    "                        return_estimator = True)\n",
    "auc = scores['test_roc_auc']\n",
    "accuracy = scores['test_accuracy']\n",
    "f1 = scores['test_f1']\n",
    "precision = scores['test_precision']\n",
    "recall = scores['test_recall']\n",
    "estimators = scores['estimator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9130682981458449"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8321428571428571"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8392856506690499"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8067342584656905"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8782069580731491"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 10, 'classify__kernel': 'linear'}\n",
      "\n",
      "\n",
      "{'classify__C': 10, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in estimators:\n",
    "    print(i.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
