{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Word Context Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.decomposition import FastICA, TruncatedSVD, PCA, NMF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert contractions picked up by word_tokenize() into full words\n",
    "contractions = {\n",
    "    \"n't\": 'not',\n",
    "    \"'ve\": 'have',\n",
    "    \"'s\": 'is', # note that this will include possessive nouns\n",
    "    'gonna': 'going to',\n",
    "    'gotta': 'got to',\n",
    "    \"'d\": 'would',\n",
    "    \"'ll\": 'will',\n",
    "    \"'re\": 'are',\n",
    "    \"'m\": 'am',\n",
    "    'wanna': 'want to'\n",
    "}\n",
    "\n",
    "# to convert nltk_pos tags to wordnet-compatible PoS tags\n",
    "def convert_pos_wordnet(tag):\n",
    "    tag_abbr = tag[0].upper()\n",
    "    tag_dict = {\n",
    "        'J': wordnet.ADJ,\n",
    "        'N': wordnet.NOUN,\n",
    "        'V': wordnet.VERB,\n",
    "        'R': wordnet.ADV\n",
    "    }\n",
    "                \n",
    "    if tag_abbr in tag_dict:\n",
    "        return tag_dict[tag_abbr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextMatrix(TransformerMixin):\n",
    "    \n",
    "    # initialize class & private variables\n",
    "    def __init__(self,\n",
    "                 window_size = 4,\n",
    "                 remove_stopwords = True,\n",
    "                 add_start_end_tokens = True,\n",
    "                 lowercase = False,\n",
    "                 lemmatize = False,\n",
    "                 pmi = False,\n",
    "                 spmi_k = 1,\n",
    "                 laplace_smoothing = 0,\n",
    "                 pmi_positive = False,\n",
    "                 sppmi_k = 1):\n",
    "        \n",
    "        \"\"\" Params:\n",
    "                window_size: size of +/- context window (default = 4)\n",
    "                remove_stopwords: boolean, whether or not to remove NLTK English stopwords\n",
    "                add_start_end_tokens: boolean, whether or not to append <START> and <END> to the\n",
    "                beginning/end of each document in the corpus (default = True)\n",
    "                lowercase: boolean, whether or not to convert words to all lowercase\n",
    "                lemmatize: boolean, whether or not to lemmatize input text\n",
    "                pmi: boolean, whether or not to compute pointwise mutual information\n",
    "                pmi_positive: boolean, whether or not to compute positive PMI\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.add_start_end_tokens = add_start_end_tokens\n",
    "        self.lowercase = lowercase\n",
    "        self.lemmatize = lemmatize\n",
    "        self.pmi = pmi\n",
    "        self.spmi_k = spmi_k\n",
    "        self.laplace_smoothing = laplace_smoothing\n",
    "        self.pmi_positive = pmi_positive\n",
    "        self.sppmi_k = sppmi_k\n",
    "        self.corpus = None\n",
    "        self.clean_corpus = None\n",
    "        self.vocabulary = None\n",
    "        self.X = None\n",
    "        self.doc_terms_lists = None\n",
    "    \n",
    "    def fit(self, corpus, y = None):\n",
    "        \n",
    "        \"\"\" Learn the dictionary of all unique tokens for given corpus.\n",
    "        \n",
    "            Params:\n",
    "                corpus: list of strings\n",
    "            \n",
    "            Returns: self\n",
    "        \"\"\"\n",
    "        self.corpus = corpus\n",
    "        \n",
    "        term_dict = dict()\n",
    "        k = 0\n",
    "        corpus_words = []\n",
    "        clean_corpus = []\n",
    "        doc_terms_lists = []\n",
    "        detokenizer = TreebankWordDetokenizer()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        for text in corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "            \n",
    "            # detokenize trick taken from this StackOverflow post:\n",
    "            # https://stackoverflow.com/questions/21948019/python-untokenize-a-sentence\n",
    "            # and NLTK treebank documentation:\n",
    "            # https://www.nltk.org/_modules/nltk/tokenize/treebank.html\n",
    "            text = detokenizer.detokenize(words)\n",
    "            clean_corpus.append(text)\n",
    "            \n",
    "            [corpus_words.append(word) for word in words]\n",
    "            \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            doc_terms_lists.append(words)\n",
    "            \n",
    "        self.clean_corpus = clean_corpus\n",
    "        \n",
    "        self.doc_terms_lists = doc_terms_lists\n",
    "        \n",
    "        corpus_words = list(set(corpus_words))\n",
    "        \n",
    "        if self.add_start_end_tokens:\n",
    "            corpus_words = ['<START>'] + corpus_words + ['<END>']\n",
    "        \n",
    "        corpus_words = sorted(corpus_words)\n",
    "        \n",
    "        for el in corpus_words:\n",
    "            term_dict[el] = k\n",
    "            k += 1\n",
    "            \n",
    "        self.vocabulary = term_dict\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def transform(self, new_corpus = None, y = None):\n",
    "        \n",
    "        \"\"\" Compute the co-occurrence matrix for given corpus and window_size, using term dictionary\n",
    "            obtained with fit method.\n",
    "        \n",
    "            Returns: term-context co-occurrence matrix (shape: target terms by context terms) with\n",
    "            raw counts\n",
    "        \"\"\"\n",
    "        num_terms = len(self.vocabulary)\n",
    "        window = self.window_size\n",
    "        X = np.full((num_terms, num_terms), self.laplace_smoothing)\n",
    "        \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        if type(new_corpus) != list:\n",
    "            new_corpus = self.corpus\n",
    "        \n",
    "        for text in new_corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            for i in range(len(words)):\n",
    "                target = words[i]\n",
    "                \n",
    "                # check to see if target word is in the dictionary; if not, skip\n",
    "                if target in self.vocabulary:\n",
    "                    \n",
    "                    # grab index from dictionary\n",
    "                    target_dict_index = self.vocabulary[target]\n",
    "                    \n",
    "                    # find left-most and right-most window indices for each target word\n",
    "                    left_end_index = max(i - window, 0)\n",
    "                    right_end_index = min(i + window, len(words) - 1)\n",
    "                    \n",
    "                    # loop over all words within window\n",
    "                    # NOTE: this will include the target word; make sure to skip over it\n",
    "                    for j in range(left_end_index, right_end_index + 1):\n",
    "                        \n",
    "                        # skip \"context word\" where the \"context word\" index is equal to the\n",
    "                        # target word index\n",
    "                        if j != i:\n",
    "                            context_word = words[j]\n",
    "                            \n",
    "                            # check to see if context word is in the fitted dictionary; if\n",
    "                            # not, skip\n",
    "                            if context_word in self.vocabulary:\n",
    "                                X[target_dict_index, self.vocabulary[context_word]] += 1\n",
    "        \n",
    "        # if pmi = True, compute pmi matrix from word-context raw frequencies\n",
    "        # more concise code taken from this StackOverflow post:\n",
    "        # https://stackoverflow.com/questions/58701337/how-to-construct-ppmi-matrix-from-a-text-corpus\n",
    "        if self.pmi:\n",
    "            denom = X.sum()\n",
    "            col_sums = X.sum(axis = 0)\n",
    "            row_sums = X.sum(axis = 1)\n",
    "            \n",
    "            expected = np.outer(row_sums, col_sums)/denom\n",
    "            \n",
    "            X = X/expected\n",
    "            \n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(X.shape[1]):\n",
    "                \n",
    "                    if X[i,j] > 0:\n",
    "                        X[i,j] = np.log(X[i,j]) - np.log(self.spmi_k)\n",
    "                        \n",
    "                        if self.pmi_positive:\n",
    "                            X[i,j] = max(X[i,j] - np.log(self.sppmi_k), 0)\n",
    "        \n",
    "        # note that X is a dense matrix\n",
    "        self.X = X\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(lowercase = True, lemmatize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [\n",
    "    \"Coronavirus is a fake liberal hoax.\",\n",
    "    \"Trump won't do anything about coronavirus.\",\n",
    "    \"The liberal fake news media always blame Pres Trump.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ContextMatrix at 0x1a1ceb9f50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.fit(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <th>always</th>\n",
       "      <th>anything</th>\n",
       "      <th>blame</th>\n",
       "      <th>coronavirus</th>\n",
       "      <th>fake</th>\n",
       "      <th>hoax</th>\n",
       "      <th>liberal</th>\n",
       "      <th>medium</th>\n",
       "      <th>news</th>\n",
       "      <th>pres</th>\n",
       "      <th>trump</th>\n",
       "      <th>wont</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>always</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anything</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blame</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronavirus</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fake</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoax</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pres</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wont</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             .  <END>  <START>  always  anything  blame  coronavirus  fake  \\\n",
       ".            0      3        0       1         1      1            2     1   \n",
       "<END>        3      0        0       0         1      1            1     1   \n",
       "<START>      0      0        0       0         1      0            2     2   \n",
       "always       1      0        0       0         0      1            0     1   \n",
       "anything     1      1        1       0         0      0            1     0   \n",
       "blame        1      1        0       1         0      0            0     1   \n",
       "coronavirus  2      1        2       0         1      0            0     1   \n",
       "fake         1      1        2       1         0      1            1     0   \n",
       "hoax         1      1        1       0         0      0            1     1   \n",
       "liberal      1      1        2       1         0      0            1     2   \n",
       "medium       0      0        1       1         0      1            0     1   \n",
       "news         0      0        1       1         0      1            0     1   \n",
       "pres         1      1        0       1         0      1            0     0   \n",
       "trump        2      1        1       1         1      1            1     0   \n",
       "wont         1      1        1       0         1      0            1     0   \n",
       "\n",
       "             hoax  liberal  medium  news  pres  trump  wont  \n",
       ".               1        1       0     0     1      2     1  \n",
       "<END>           1        1       0     0     1      1     1  \n",
       "<START>         1        2       1     1     0      1     1  \n",
       "always          0        1       1     1     1      1     0  \n",
       "anything        0        0       0     0     0      1     1  \n",
       "blame           0        0       1     1     1      1     0  \n",
       "coronavirus     1        1       0     0     0      1     1  \n",
       "fake            1        2       1     1     0      0     0  \n",
       "hoax            0        1       0     0     0      0     0  \n",
       "liberal         1        0       1     1     0      0     0  \n",
       "medium          0        1       0     1     1      1     0  \n",
       "news            0        1       1     0     1      0     0  \n",
       "pres            0        0       1     1     0      1     0  \n",
       "trump           0        0       1     0     1      0     1  \n",
       "wont            0        0       0     0     0      1     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cm.transform(tweets), index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coronavirus fake liberal hoax.',\n",
       " 'trump wont anything coronavirus.',\n",
       " 'liberal fake news medium always blame pres trump.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.clean_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coronavirus is a fake liberal hoax.',\n",
       " \"Trump won't do anything about coronavirus.\",\n",
       " 'The liberal fake news media always blame Pres Trump.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train embeddings using tweets as corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('COVID19_Dataset-text_labels_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Unreliable</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 3, 6, 9</td>\n",
       "      <td>We are living in scary times in Canada. Gov’t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 6, 8, 9</td>\n",
       "      <td>Just as bad in Canada. In fact, our government...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 4, 9</td>\n",
       "      <td>It was only a matter of time before the mainst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8</td>\n",
       "      <td>Russia's taking no chances: Foreigners infecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8, 9</td>\n",
       "      <td>Although there is now a presumptive confirmed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BREAKING: Harvard classes will move online sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singularity University is hosting a FREE Virtu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus: how does it spread and what are t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stanford just cancelled classes for the rest o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tech conferences were cancelled in #Waterloo R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Is_Unreliable    Category  \\\n",
       "0                1  1, 3, 6, 9   \n",
       "1                1  1, 6, 8, 9   \n",
       "2                1     1, 4, 9   \n",
       "3                1        6, 8   \n",
       "4                1     6, 8, 9   \n",
       "..             ...         ...   \n",
       "555              0         NaN   \n",
       "556              0         NaN   \n",
       "557              0         NaN   \n",
       "558              0         NaN   \n",
       "559              0         NaN   \n",
       "\n",
       "                                                 Tweet  \n",
       "0    We are living in scary times in Canada. Gov’t ...  \n",
       "1    Just as bad in Canada. In fact, our government...  \n",
       "2    It was only a matter of time before the mainst...  \n",
       "3    Russia's taking no chances: Foreigners infecte...  \n",
       "4    Although there is now a presumptive confirmed ...  \n",
       "..                                                 ...  \n",
       "555  BREAKING: Harvard classes will move online sta...  \n",
       "556  Singularity University is hosting a FREE Virtu...  \n",
       "557  Coronavirus: how does it spread and what are t...  \n",
       "558  Stanford just cancelled classes for the rest o...  \n",
       "559  Tech conferences were cancelled in #Waterloo R...  \n",
       "\n",
       "[560 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(window_size = 15,\n",
    "                   lowercase = True,\n",
    "                   lemmatize = True,\n",
    "                   pmi = True,\n",
    "                   spmi_k = 5,\n",
    "                   laplace_smoothing = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_context_matrix = cm.fit_transform(tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>#</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>,</th>\n",
       "      <th>-</th>\n",
       "      <th>--</th>\n",
       "      <th>.</th>\n",
       "      <th>...</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoomer</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>—</th>\n",
       "      <th>‘</th>\n",
       "      <th>’</th>\n",
       "      <th>“</th>\n",
       "      <th>”</th>\n",
       "      <th>❝real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>1.452937</td>\n",
       "      <td>-0.167051</td>\n",
       "      <td>-1.743773</td>\n",
       "      <td>-1.562852</td>\n",
       "      <td>-0.906669</td>\n",
       "      <td>-1.279030</td>\n",
       "      <td>-1.708294</td>\n",
       "      <td>0.015555</td>\n",
       "      <td>-0.834957</td>\n",
       "      <td>-1.239399</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.702385</td>\n",
       "      <td>-1.704444</td>\n",
       "      <td>-1.702471</td>\n",
       "      <td>-1.701697</td>\n",
       "      <td>-1.526314</td>\n",
       "      <td>-1.711363</td>\n",
       "      <td>0.061160</td>\n",
       "      <td>-0.783554</td>\n",
       "      <td>-1.392608</td>\n",
       "      <td>-1.520321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>-0.167051</td>\n",
       "      <td>2.446712</td>\n",
       "      <td>-1.029678</td>\n",
       "      <td>-1.031078</td>\n",
       "      <td>0.840441</td>\n",
       "      <td>-0.495942</td>\n",
       "      <td>-1.553814</td>\n",
       "      <td>1.355989</td>\n",
       "      <td>-1.843629</td>\n",
       "      <td>-1.842606</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.017909</td>\n",
       "      <td>-1.837647</td>\n",
       "      <td>-1.835673</td>\n",
       "      <td>-2.017222</td>\n",
       "      <td>-1.687687</td>\n",
       "      <td>-1.439100</td>\n",
       "      <td>0.438783</td>\n",
       "      <td>-1.361442</td>\n",
       "      <td>-1.456818</td>\n",
       "      <td>-2.018167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>-1.743773</td>\n",
       "      <td>-1.029678</td>\n",
       "      <td>-1.353637</td>\n",
       "      <td>0.309970</td>\n",
       "      <td>-0.670684</td>\n",
       "      <td>-1.513048</td>\n",
       "      <td>-1.654630</td>\n",
       "      <td>-0.577408</td>\n",
       "      <td>-1.474441</td>\n",
       "      <td>-1.655739</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.648721</td>\n",
       "      <td>-1.650780</td>\n",
       "      <td>-1.648807</td>\n",
       "      <td>-1.648034</td>\n",
       "      <td>-1.654971</td>\n",
       "      <td>-1.657699</td>\n",
       "      <td>-1.214312</td>\n",
       "      <td>-1.503080</td>\n",
       "      <td>-1.675416</td>\n",
       "      <td>-1.648979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>-1.562852</td>\n",
       "      <td>-1.031078</td>\n",
       "      <td>0.309970</td>\n",
       "      <td>-1.356437</td>\n",
       "      <td>-0.672084</td>\n",
       "      <td>-1.514448</td>\n",
       "      <td>-1.656030</td>\n",
       "      <td>-0.450975</td>\n",
       "      <td>-1.475840</td>\n",
       "      <td>-1.657139</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.650121</td>\n",
       "      <td>-1.652180</td>\n",
       "      <td>-1.650207</td>\n",
       "      <td>-1.649434</td>\n",
       "      <td>-1.656371</td>\n",
       "      <td>-1.659099</td>\n",
       "      <td>-1.215712</td>\n",
       "      <td>-1.504480</td>\n",
       "      <td>-1.676816</td>\n",
       "      <td>-1.650379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>-0.906669</td>\n",
       "      <td>0.840441</td>\n",
       "      <td>-0.670684</td>\n",
       "      <td>-0.672084</td>\n",
       "      <td>1.140281</td>\n",
       "      <td>-0.733103</td>\n",
       "      <td>-1.328351</td>\n",
       "      <td>1.157637</td>\n",
       "      <td>-1.448267</td>\n",
       "      <td>-1.329461</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.440226</td>\n",
       "      <td>-1.729967</td>\n",
       "      <td>-1.910315</td>\n",
       "      <td>-1.909542</td>\n",
       "      <td>-1.580007</td>\n",
       "      <td>-1.449203</td>\n",
       "      <td>0.238979</td>\n",
       "      <td>-0.560615</td>\n",
       "      <td>-0.981413</td>\n",
       "      <td>-1.910487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>-1.711363</td>\n",
       "      <td>-1.439100</td>\n",
       "      <td>-1.657699</td>\n",
       "      <td>-1.659099</td>\n",
       "      <td>-1.449203</td>\n",
       "      <td>-1.662959</td>\n",
       "      <td>-1.622219</td>\n",
       "      <td>-1.438815</td>\n",
       "      <td>-1.624351</td>\n",
       "      <td>-1.623328</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.616310</td>\n",
       "      <td>-1.618369</td>\n",
       "      <td>-1.616396</td>\n",
       "      <td>-1.615623</td>\n",
       "      <td>-1.622560</td>\n",
       "      <td>-1.625288</td>\n",
       "      <td>-0.740068</td>\n",
       "      <td>-1.652991</td>\n",
       "      <td>-1.643006</td>\n",
       "      <td>-1.616568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>0.061160</td>\n",
       "      <td>0.438783</td>\n",
       "      <td>-1.214312</td>\n",
       "      <td>-1.215712</td>\n",
       "      <td>0.238979</td>\n",
       "      <td>-1.018901</td>\n",
       "      <td>-1.766619</td>\n",
       "      <td>0.730420</td>\n",
       "      <td>-1.075604</td>\n",
       "      <td>-1.767728</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.760710</td>\n",
       "      <td>-1.762769</td>\n",
       "      <td>-1.760796</td>\n",
       "      <td>-1.760022</td>\n",
       "      <td>-1.766960</td>\n",
       "      <td>-0.740068</td>\n",
       "      <td>0.650862</td>\n",
       "      <td>-0.516456</td>\n",
       "      <td>-0.563630</td>\n",
       "      <td>-1.578646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“</th>\n",
       "      <td>-0.783554</td>\n",
       "      <td>-1.361442</td>\n",
       "      <td>-1.503080</td>\n",
       "      <td>-1.504480</td>\n",
       "      <td>-0.560615</td>\n",
       "      <td>-1.220658</td>\n",
       "      <td>-1.467600</td>\n",
       "      <td>-0.572700</td>\n",
       "      <td>-1.469732</td>\n",
       "      <td>-1.468709</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.644013</td>\n",
       "      <td>-1.646072</td>\n",
       "      <td>-1.644099</td>\n",
       "      <td>-1.643325</td>\n",
       "      <td>-1.467942</td>\n",
       "      <td>-1.652991</td>\n",
       "      <td>-0.516456</td>\n",
       "      <td>-1.092907</td>\n",
       "      <td>-0.061270</td>\n",
       "      <td>-1.644270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>”</th>\n",
       "      <td>-1.392608</td>\n",
       "      <td>-1.456818</td>\n",
       "      <td>-1.675416</td>\n",
       "      <td>-1.676816</td>\n",
       "      <td>-0.981413</td>\n",
       "      <td>-1.344204</td>\n",
       "      <td>-1.457615</td>\n",
       "      <td>-0.763386</td>\n",
       "      <td>-1.459747</td>\n",
       "      <td>-1.641046</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.634028</td>\n",
       "      <td>-1.636087</td>\n",
       "      <td>-1.634114</td>\n",
       "      <td>-1.633340</td>\n",
       "      <td>-1.457956</td>\n",
       "      <td>-1.643006</td>\n",
       "      <td>-0.563630</td>\n",
       "      <td>-0.061270</td>\n",
       "      <td>-0.705212</td>\n",
       "      <td>-1.634285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>❝real</th>\n",
       "      <td>-1.520321</td>\n",
       "      <td>-2.018167</td>\n",
       "      <td>-1.648979</td>\n",
       "      <td>-1.650379</td>\n",
       "      <td>-1.910487</td>\n",
       "      <td>-1.654239</td>\n",
       "      <td>-1.613499</td>\n",
       "      <td>-2.017882</td>\n",
       "      <td>-1.615631</td>\n",
       "      <td>-1.614608</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.607590</td>\n",
       "      <td>-1.609649</td>\n",
       "      <td>-1.607676</td>\n",
       "      <td>-1.606903</td>\n",
       "      <td>-1.613840</td>\n",
       "      <td>-1.616568</td>\n",
       "      <td>-1.578646</td>\n",
       "      <td>-1.644270</td>\n",
       "      <td>-1.634285</td>\n",
       "      <td>-1.607848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2325 rows × 2325 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              !         #         (         )         ,         -        --  \\\n",
       "!      1.452937 -0.167051 -1.743773 -1.562852 -0.906669 -1.279030 -1.708294   \n",
       "#     -0.167051  2.446712 -1.029678 -1.031078  0.840441 -0.495942 -1.553814   \n",
       "(     -1.743773 -1.029678 -1.353637  0.309970 -0.670684 -1.513048 -1.654630   \n",
       ")     -1.562852 -1.031078  0.309970 -1.356437 -0.672084 -1.514448 -1.656030   \n",
       ",     -0.906669  0.840441 -0.670684 -0.672084  1.140281 -0.733103 -1.328351   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "‘     -1.711363 -1.439100 -1.657699 -1.659099 -1.449203 -1.662959 -1.622219   \n",
       "’      0.061160  0.438783 -1.214312 -1.215712  0.238979 -1.018901 -1.766619   \n",
       "“     -0.783554 -1.361442 -1.503080 -1.504480 -0.560615 -1.220658 -1.467600   \n",
       "”     -1.392608 -1.456818 -1.675416 -1.676816 -0.981413 -1.344204 -1.457615   \n",
       "❝real -1.520321 -2.018167 -1.648979 -1.650379 -1.910487 -1.654239 -1.613499   \n",
       "\n",
       "              .       ...         1  ...    zombie      zone    zoomer  \\\n",
       "!      0.015555 -0.834957 -1.239399  ... -1.702385 -1.704444 -1.702471   \n",
       "#      1.355989 -1.843629 -1.842606  ... -2.017909 -1.837647 -1.835673   \n",
       "(     -0.577408 -1.474441 -1.655739  ... -1.648721 -1.650780 -1.648807   \n",
       ")     -0.450975 -1.475840 -1.657139  ... -1.650121 -1.652180 -1.650207   \n",
       ",      1.157637 -1.448267 -1.329461  ... -1.440226 -1.729967 -1.910315   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "‘     -1.438815 -1.624351 -1.623328  ... -1.616310 -1.618369 -1.616396   \n",
       "’      0.730420 -1.075604 -1.767728  ... -1.760710 -1.762769 -1.760796   \n",
       "“     -0.572700 -1.469732 -1.468709  ... -1.644013 -1.646072 -1.644099   \n",
       "”     -0.763386 -1.459747 -1.641046  ... -1.634028 -1.636087 -1.634114   \n",
       "❝real -2.017882 -1.615631 -1.614608  ... -1.607590 -1.609649 -1.607676   \n",
       "\n",
       "       zuckerberg         —         ‘         ’         “         ”     ❝real  \n",
       "!       -1.701697 -1.526314 -1.711363  0.061160 -0.783554 -1.392608 -1.520321  \n",
       "#       -2.017222 -1.687687 -1.439100  0.438783 -1.361442 -1.456818 -2.018167  \n",
       "(       -1.648034 -1.654971 -1.657699 -1.214312 -1.503080 -1.675416 -1.648979  \n",
       ")       -1.649434 -1.656371 -1.659099 -1.215712 -1.504480 -1.676816 -1.650379  \n",
       ",       -1.909542 -1.580007 -1.449203  0.238979 -0.560615 -0.981413 -1.910487  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "‘       -1.615623 -1.622560 -1.625288 -0.740068 -1.652991 -1.643006 -1.616568  \n",
       "’       -1.760022 -1.766960 -0.740068  0.650862 -0.516456 -0.563630 -1.578646  \n",
       "“       -1.643325 -1.467942 -1.652991 -0.516456 -1.092907 -0.061270 -1.644270  \n",
       "”       -1.633340 -1.457956 -1.643006 -0.563630 -0.061270 -0.705212 -1.634285  \n",
       "❝real   -1.606903 -1.613840 -1.616568 -1.578646 -1.644270 -1.634285 -1.607848  \n",
       "\n",
       "[2325 rows x 2325 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(word_context_matrix, index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2325, 2325)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_context_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = FastICA(n_components = 2)\n",
    "std_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.24314386e-03, -9.21704568e-02],\n",
       "       [ 9.50355115e-01, -1.00204407e-01],\n",
       "       [-1.09773078e-02, -4.31272269e-02],\n",
       "       ...,\n",
       "       [-2.54005594e-02, -4.18588955e-02],\n",
       "       [-1.86897664e-02, -2.98320218e-02],\n",
       "       [ 1.92380550e-04,  3.21995149e-03]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std = std_scaler.fit_transform(word_context_matrix)\n",
    "\n",
    "matrix = ica.fit_transform(X_std)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comp 1</th>\n",
       "      <th>Comp 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>0.003243</td>\n",
       "      <td>-0.092170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>0.950355</td>\n",
       "      <td>-0.100204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>-0.010977</td>\n",
       "      <td>-0.043127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>-0.012188</td>\n",
       "      <td>-0.044883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>-0.112995</td>\n",
       "      <td>-0.324347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>-0.003323</td>\n",
       "      <td>-0.006990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>-0.008756</td>\n",
       "      <td>-0.149770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“</th>\n",
       "      <td>-0.025401</td>\n",
       "      <td>-0.041859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>”</th>\n",
       "      <td>-0.018690</td>\n",
       "      <td>-0.029832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>❝real</th>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.003220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2325 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Comp 1    Comp 2\n",
       "!      0.003243 -0.092170\n",
       "#      0.950355 -0.100204\n",
       "(     -0.010977 -0.043127\n",
       ")     -0.012188 -0.044883\n",
       ",     -0.112995 -0.324347\n",
       "...         ...       ...\n",
       "‘     -0.003323 -0.006990\n",
       "’     -0.008756 -0.149770\n",
       "“     -0.025401 -0.041859\n",
       "”     -0.018690 -0.029832\n",
       "❝real  0.000192  0.003220\n",
       "\n",
       "[2325 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(matrix,\n",
    "                  index = cm.vocabulary,\n",
    "                  columns = ['Comp {}'.format(i+1) for i in range(2)])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 62222 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 62222 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = [key for key in cm.vocabulary.keys()]\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    \n",
    "    #if re.match('^co[rv]', word):\n",
    "    \n",
    "        x = df['Comp 1'][i]\n",
    "        y = df['Comp 2'][i]\n",
    "\n",
    "        plt.scatter(x, y)\n",
    "        plt.text(x, y, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set word embeddings for text classification\n",
    "ica = FastICA(n_components = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.92330548e-03, -3.79177296e-05, -6.61709359e-04, ...,\n",
       "        -6.38891782e-03,  2.89480570e-03,  5.55441941e-04],\n",
       "       [ 6.01629410e-03,  1.10646752e-03, -3.16014743e-03, ...,\n",
       "        -4.28555779e-03, -1.60678111e-04,  2.60807408e-03],\n",
       "       [ 6.20378462e-03, -6.90031081e-04, -1.69942975e-04, ...,\n",
       "         7.22603089e-03,  6.57540971e-03, -3.26283222e-03],\n",
       "       ...,\n",
       "       [ 1.59413829e-02,  2.22696710e-02,  3.86823470e-03, ...,\n",
       "         1.84009466e-02, -1.22816266e-02, -9.68138444e-03],\n",
       "       [-2.40513253e-02, -9.93882421e-03, -8.83063516e-03, ...,\n",
       "        -1.56826583e-02,  1.51504702e-02, -8.48669910e-04],\n",
       "       [ 4.26527621e-03,  5.47918036e-03, -5.69983514e-04, ...,\n",
       "         1.07883531e-02, -1.34641041e-02, -4.14536972e-03]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = ica.fit_transform(X_std)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out target\n",
    "y = tweets['Is_Unreliable']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derive text vectors from word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_vectors(word_embeddings,\n",
    "                     word_index_dict,\n",
    "                     text_list,\n",
    "                     remove_stopwords = True,\n",
    "                     lowercase = True,\n",
    "                     lemmatize = True,\n",
    "                     add_start_end_tokens = True):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    for k in range(len(text_list)):\n",
    "        text = text_list[k]\n",
    "        text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "        text_vec = np.zeros(word_embeddings.shape[1])\n",
    "        words = word_tokenize(text)\n",
    "        tracker = 0 # to track whether we've encountered a word for which we have an embedding (in each tweet)\n",
    "        \n",
    "        if remove_stopwords:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                if word.lower() not in set(stopwords.words('english')):\n",
    "                    clean_words.append(word)\n",
    "            words = clean_words\n",
    "\n",
    "        if lowercase:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                clean_words.append(word.lower())\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if lemmatize:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                PoS_tag = pos_tag([word])[0][1]\n",
    "\n",
    "                # to change contractions to full word form\n",
    "                if word in contractions:\n",
    "                    word = contractions[word]\n",
    "\n",
    "                if PoS_tag[0].upper() in 'JNVR':\n",
    "                    word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                else:\n",
    "                    word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                clean_words.append(word)\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if add_start_end_tokens:\n",
    "            words = ['<START>'] + words + ['<END>']\n",
    "        \n",
    "        for i in range(len(words)):\n",
    "            word = words[i]\n",
    "            if word in word_index_dict:\n",
    "                word_embed_vec = word_embeddings[word_index_dict[word],:]\n",
    "                if tracker == 0:\n",
    "                    text_matrix = word_embed_vec\n",
    "                else:\n",
    "                    text_matrix = np.vstack((text_matrix, word_embed_vec))\n",
    "                    \n",
    "                # only increment if we have come across a word in the embeddings dictionary\n",
    "                tracker += 1\n",
    "                    \n",
    "        for j in range(len(text_vec)):\n",
    "            text_vec[j] = text_matrix[:,j].mean()\n",
    "            \n",
    "        if k == 0:\n",
    "            full_matrix = text_vec\n",
    "        else:\n",
    "            full_matrix = np.vstack((full_matrix, text_vec))\n",
    "            \n",
    "    return full_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_text_vectors(embeddings, cm.vocabulary, tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 150)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0684215 ,  0.00036334, -0.00284855, ...,  0.00301845,\n",
       "         0.00501213,  0.00276379],\n",
       "       [ 0.06315337,  0.00513175,  0.00349444, ..., -0.00802938,\n",
       "         0.00061433,  0.00258878],\n",
       "       [ 0.06804606,  0.00064699, -0.00165579, ...,  0.00049342,\n",
       "         0.0041169 , -0.00110185],\n",
       "       ...,\n",
       "       [ 0.08442311,  0.01034284,  0.0903702 , ...,  0.00431708,\n",
       "         0.00080469, -0.00305425],\n",
       "       [ 0.00118543,  0.00445668, -0.00346889, ...,  0.00588896,\n",
       "         0.02287401,  0.00571778],\n",
       "       [-0.00169274,  0.00365775,  0.00213357, ...,  0.00059722,\n",
       "         0.0065718 , -0.00113859]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, KFold, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipe = Pipeline([\n",
    "    ('classify', SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC hyperparams to optimize\n",
    "kernel = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "C = [0.001, 0.01, 0.1, 1, 10]\n",
    "# set up parameter grid\n",
    "params = {\n",
    "    'classify__kernel': kernel,\n",
    "    'classify__C': C\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CV scheme for inner and outer loops\n",
    "inner_cv = KFold(n_splits = 3, shuffle = True, random_state = 1)\n",
    "outer_cv = KFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "\n",
    "# Set up GridSearch for inner loop\n",
    "grid_SVC = GridSearchCV(pipe, params, cv = inner_cv)\n",
    "#grid_SVC.fit(X, y)\n",
    "\n",
    "# Nested CV scores\n",
    "scores = cross_validate(grid_SVC,\n",
    "                        X = X,\n",
    "                        y = y,\n",
    "                        cv = outer_cv,\n",
    "                        scoring = ['roc_auc', 'accuracy', 'f1', 'precision', 'recall'],\n",
    "                        return_estimator = True)\n",
    "auc = scores['test_roc_auc']\n",
    "accuracy = scores['test_accuracy']\n",
    "f1 = scores['test_f1']\n",
    "precision = scores['test_precision']\n",
    "recall = scores['test_recall']\n",
    "estimators = scores['estimator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9201740273282903"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8482142857142858"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8541371137023311"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8227676832934041"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8925431162652394"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 10, 'classify__kernel': 'linear'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in estimators:\n",
    "    print(i.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
