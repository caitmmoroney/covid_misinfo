{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Word Context Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.decomposition import FastICA, TruncatedSVD, PCA, NMF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert contractions picked up by word_tokenize() into full words\n",
    "contractions = {\n",
    "    \"n't\": 'not',\n",
    "    \"'ve\": 'have',\n",
    "    \"'s\": 'is', # note that this will include possessive nouns\n",
    "    'gonna': 'going to',\n",
    "    'gotta': 'got to',\n",
    "    \"'d\": 'would',\n",
    "    \"'ll\": 'will',\n",
    "    \"'re\": 'are',\n",
    "    \"'m\": 'am',\n",
    "    'wanna': 'want to'\n",
    "}\n",
    "\n",
    "# to convert nltk_pos tags to wordnet-compatible PoS tags\n",
    "def convert_pos_wordnet(tag):\n",
    "    tag_abbr = tag[0].upper()\n",
    "    tag_dict = {\n",
    "        'J': wordnet.ADJ,\n",
    "        'N': wordnet.NOUN,\n",
    "        'V': wordnet.VERB,\n",
    "        'R': wordnet.ADV\n",
    "    }\n",
    "                \n",
    "    if tag_abbr in tag_dict:\n",
    "        return tag_dict[tag_abbr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextMatrix(TransformerMixin):\n",
    "    \n",
    "    # initialize class & private variables\n",
    "    def __init__(self,\n",
    "                 window_size = 4,\n",
    "                 remove_stopwords = True,\n",
    "                 add_start_end_tokens = True,\n",
    "                 lowercase = False,\n",
    "                 lemmatize = False,\n",
    "                 pmi = False,\n",
    "                 spmi_k = 1,\n",
    "                 laplace_smoothing = 0,\n",
    "                 pmi_positive = False,\n",
    "                 sppmi_k = 1):\n",
    "        \n",
    "        \"\"\" Params:\n",
    "                window_size: size of +/- context window (default = 4)\n",
    "                remove_stopwords: boolean, whether or not to remove NLTK English stopwords\n",
    "                add_start_end_tokens: boolean, whether or not to append <START> and <END> to the\n",
    "                beginning/end of each document in the corpus (default = True)\n",
    "                lowercase: boolean, whether or not to convert words to all lowercase\n",
    "                lemmatize: boolean, whether or not to lemmatize input text\n",
    "                pmi: boolean, whether or not to compute pointwise mutual information\n",
    "                pmi_positive: boolean, whether or not to compute positive PMI\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.add_start_end_tokens = add_start_end_tokens\n",
    "        self.lowercase = lowercase\n",
    "        self.lemmatize = lemmatize\n",
    "        self.pmi = pmi\n",
    "        self.spmi_k = spmi_k\n",
    "        self.laplace_smoothing = laplace_smoothing\n",
    "        self.pmi_positive = pmi_positive\n",
    "        self.sppmi_k = sppmi_k\n",
    "        self.corpus = None\n",
    "        self.clean_corpus = None\n",
    "        self.vocabulary = None\n",
    "        self.X = None\n",
    "        self.doc_terms_lists = None\n",
    "    \n",
    "    def fit(self, corpus, y = None):\n",
    "        \n",
    "        \"\"\" Learn the dictionary of all unique tokens for given corpus.\n",
    "        \n",
    "            Params:\n",
    "                corpus: list of strings\n",
    "            \n",
    "            Returns: self\n",
    "        \"\"\"\n",
    "        self.corpus = corpus\n",
    "        \n",
    "        term_dict = dict()\n",
    "        k = 0\n",
    "        corpus_words = []\n",
    "        clean_corpus = []\n",
    "        doc_terms_lists = []\n",
    "        detokenizer = TreebankWordDetokenizer()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        for text in corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "            \n",
    "            # detokenize trick taken from this StackOverflow post:\n",
    "            # https://stackoverflow.com/questions/21948019/python-untokenize-a-sentence\n",
    "            # and NLTK treebank documentation:\n",
    "            # https://www.nltk.org/_modules/nltk/tokenize/treebank.html\n",
    "            text = detokenizer.detokenize(words)\n",
    "            clean_corpus.append(text)\n",
    "            \n",
    "            [corpus_words.append(word) for word in words]\n",
    "            \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            doc_terms_lists.append(words)\n",
    "            \n",
    "        self.clean_corpus = clean_corpus\n",
    "        \n",
    "        self.doc_terms_lists = doc_terms_lists\n",
    "        \n",
    "        corpus_words = list(set(corpus_words))\n",
    "        \n",
    "        if self.add_start_end_tokens:\n",
    "            corpus_words = ['<START>'] + corpus_words + ['<END>']\n",
    "        \n",
    "        corpus_words = sorted(corpus_words)\n",
    "        \n",
    "        for el in corpus_words:\n",
    "            term_dict[el] = k\n",
    "            k += 1\n",
    "            \n",
    "        self.vocabulary = term_dict\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def transform(self, new_corpus = None, y = None):\n",
    "        \n",
    "        \"\"\" Compute the co-occurrence matrix for given corpus and window_size, using term dictionary\n",
    "            obtained with fit method.\n",
    "        \n",
    "            Returns: term-context co-occurrence matrix (shape: target terms by context terms) with\n",
    "            raw counts\n",
    "        \"\"\"\n",
    "        num_terms = len(self.vocabulary)\n",
    "        window = self.window_size\n",
    "        X = np.full((num_terms, num_terms), self.laplace_smoothing)\n",
    "        \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        if type(new_corpus) != list:\n",
    "            new_corpus = self.corpus\n",
    "        \n",
    "        for text in new_corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            for i in range(len(words)):\n",
    "                target = words[i]\n",
    "                \n",
    "                # check to see if target word is in the dictionary; if not, skip\n",
    "                if target in self.vocabulary:\n",
    "                    \n",
    "                    # grab index from dictionary\n",
    "                    target_dict_index = self.vocabulary[target]\n",
    "                    \n",
    "                    # find left-most and right-most window indices for each target word\n",
    "                    left_end_index = max(i - window, 0)\n",
    "                    right_end_index = min(i + window, len(words) - 1)\n",
    "                    \n",
    "                    # loop over all words within window\n",
    "                    # NOTE: this will include the target word; make sure to skip over it\n",
    "                    for j in range(left_end_index, right_end_index + 1):\n",
    "                        \n",
    "                        # skip \"context word\" where the \"context word\" index is equal to the\n",
    "                        # target word index\n",
    "                        if j != i:\n",
    "                            context_word = words[j]\n",
    "                            \n",
    "                            # check to see if context word is in the fitted dictionary; if\n",
    "                            # not, skip\n",
    "                            if context_word in self.vocabulary:\n",
    "                                X[target_dict_index, self.vocabulary[context_word]] += 1\n",
    "        \n",
    "        # if pmi = True, compute pmi matrix from word-context raw frequencies\n",
    "        # more concise code taken from this StackOverflow post:\n",
    "        # https://stackoverflow.com/questions/58701337/how-to-construct-ppmi-matrix-from-a-text-corpus\n",
    "        if self.pmi:\n",
    "            denom = X.sum()\n",
    "            col_sums = X.sum(axis = 0)\n",
    "            row_sums = X.sum(axis = 1)\n",
    "            \n",
    "            expected = np.outer(row_sums, col_sums)/denom\n",
    "            \n",
    "            X = X/expected\n",
    "            \n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(X.shape[1]):\n",
    "                \n",
    "                    if X[i,j] > 0:\n",
    "                        X[i,j] = np.log(X[i,j]) - np.log(self.spmi_k)\n",
    "                        \n",
    "                        if self.pmi_positive:\n",
    "                            X[i,j] = max(X[i,j] - np.log(self.sppmi_k), 0)\n",
    "        \n",
    "        # note that X is a dense matrix\n",
    "        self.X = X\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(lowercase = True, lemmatize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [\n",
    "    \"Coronavirus is a fake liberal hoax.\",\n",
    "    \"Trump won't do anything about coronavirus.\",\n",
    "    \"The liberal fake news media always blame Pres Trump.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ContextMatrix at 0x1a1f97ca90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.fit(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <th>always</th>\n",
       "      <th>anything</th>\n",
       "      <th>blame</th>\n",
       "      <th>coronavirus</th>\n",
       "      <th>fake</th>\n",
       "      <th>hoax</th>\n",
       "      <th>liberal</th>\n",
       "      <th>medium</th>\n",
       "      <th>news</th>\n",
       "      <th>pres</th>\n",
       "      <th>trump</th>\n",
       "      <th>wont</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>always</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anything</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blame</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronavirus</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fake</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoax</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pres</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wont</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             .  <END>  <START>  always  anything  blame  coronavirus  fake  \\\n",
       ".            0      3        0       1         1      1            2     1   \n",
       "<END>        3      0        0       0         1      1            1     1   \n",
       "<START>      0      0        0       0         1      0            2     2   \n",
       "always       1      0        0       0         0      1            0     1   \n",
       "anything     1      1        1       0         0      0            1     0   \n",
       "blame        1      1        0       1         0      0            0     1   \n",
       "coronavirus  2      1        2       0         1      0            0     1   \n",
       "fake         1      1        2       1         0      1            1     0   \n",
       "hoax         1      1        1       0         0      0            1     1   \n",
       "liberal      1      1        2       1         0      0            1     2   \n",
       "medium       0      0        1       1         0      1            0     1   \n",
       "news         0      0        1       1         0      1            0     1   \n",
       "pres         1      1        0       1         0      1            0     0   \n",
       "trump        2      1        1       1         1      1            1     0   \n",
       "wont         1      1        1       0         1      0            1     0   \n",
       "\n",
       "             hoax  liberal  medium  news  pres  trump  wont  \n",
       ".               1        1       0     0     1      2     1  \n",
       "<END>           1        1       0     0     1      1     1  \n",
       "<START>         1        2       1     1     0      1     1  \n",
       "always          0        1       1     1     1      1     0  \n",
       "anything        0        0       0     0     0      1     1  \n",
       "blame           0        0       1     1     1      1     0  \n",
       "coronavirus     1        1       0     0     0      1     1  \n",
       "fake            1        2       1     1     0      0     0  \n",
       "hoax            0        1       0     0     0      0     0  \n",
       "liberal         1        0       1     1     0      0     0  \n",
       "medium          0        1       0     1     1      1     0  \n",
       "news            0        1       1     0     1      0     0  \n",
       "pres            0        0       1     1     0      1     0  \n",
       "trump           0        0       1     0     1      0     1  \n",
       "wont            0        0       0     0     0      1     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cm.transform(tweets), index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coronavirus fake liberal hoax.',\n",
       " 'trump wont anything coronavirus.',\n",
       " 'liberal fake news medium always blame pres trump.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.clean_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coronavirus is a fake liberal hoax.',\n",
       " \"Trump won't do anything about coronavirus.\",\n",
       " 'The liberal fake news media always blame Pres Trump.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train embeddings using tweets as corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('COVID19_Dataset-text_labels_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Unreliable</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 3, 6, 9</td>\n",
       "      <td>We are living in scary times in Canada. Gov’t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 6, 8, 9</td>\n",
       "      <td>Just as bad in Canada. In fact, our government...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 4, 9</td>\n",
       "      <td>It was only a matter of time before the mainst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8</td>\n",
       "      <td>Russia's taking no chances: Foreigners infecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8, 9</td>\n",
       "      <td>Although there is now a presumptive confirmed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BREAKING: Harvard classes will move online sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singularity University is hosting a FREE Virtu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus: how does it spread and what are t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stanford just cancelled classes for the rest o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tech conferences were cancelled in #Waterloo R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Is_Unreliable    Category  \\\n",
       "0                1  1, 3, 6, 9   \n",
       "1                1  1, 6, 8, 9   \n",
       "2                1     1, 4, 9   \n",
       "3                1        6, 8   \n",
       "4                1     6, 8, 9   \n",
       "..             ...         ...   \n",
       "555              0         NaN   \n",
       "556              0         NaN   \n",
       "557              0         NaN   \n",
       "558              0         NaN   \n",
       "559              0         NaN   \n",
       "\n",
       "                                                 Tweet  \n",
       "0    We are living in scary times in Canada. Gov’t ...  \n",
       "1    Just as bad in Canada. In fact, our government...  \n",
       "2    It was only a matter of time before the mainst...  \n",
       "3    Russia's taking no chances: Foreigners infecte...  \n",
       "4    Although there is now a presumptive confirmed ...  \n",
       "..                                                 ...  \n",
       "555  BREAKING: Harvard classes will move online sta...  \n",
       "556  Singularity University is hosting a FREE Virtu...  \n",
       "557  Coronavirus: how does it spread and what are t...  \n",
       "558  Stanford just cancelled classes for the rest o...  \n",
       "559  Tech conferences were cancelled in #Waterloo R...  \n",
       "\n",
       "[560 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(window_size = 15,\n",
    "                   lowercase = True,\n",
    "                   lemmatize = True,\n",
    "                   pmi = True,\n",
    "                   spmi_k = 5,\n",
    "                   laplace_smoothing = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_context_matrix = cm.fit_transform(tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>#</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>,</th>\n",
       "      <th>-</th>\n",
       "      <th>--</th>\n",
       "      <th>.</th>\n",
       "      <th>...</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoomer</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>—</th>\n",
       "      <th>‘</th>\n",
       "      <th>’</th>\n",
       "      <th>“</th>\n",
       "      <th>”</th>\n",
       "      <th>❝real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>1.452937</td>\n",
       "      <td>-0.167051</td>\n",
       "      <td>-1.743773</td>\n",
       "      <td>-1.562852</td>\n",
       "      <td>-0.906669</td>\n",
       "      <td>-1.279030</td>\n",
       "      <td>-1.708294</td>\n",
       "      <td>0.015555</td>\n",
       "      <td>-0.834957</td>\n",
       "      <td>-1.239399</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.702385</td>\n",
       "      <td>-1.704444</td>\n",
       "      <td>-1.702471</td>\n",
       "      <td>-1.701697</td>\n",
       "      <td>-1.526314</td>\n",
       "      <td>-1.711363</td>\n",
       "      <td>0.061160</td>\n",
       "      <td>-0.783554</td>\n",
       "      <td>-1.392608</td>\n",
       "      <td>-1.520321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>-0.167051</td>\n",
       "      <td>2.446712</td>\n",
       "      <td>-1.029678</td>\n",
       "      <td>-1.031078</td>\n",
       "      <td>0.840441</td>\n",
       "      <td>-0.495942</td>\n",
       "      <td>-1.553814</td>\n",
       "      <td>1.355989</td>\n",
       "      <td>-1.843629</td>\n",
       "      <td>-1.842606</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.017909</td>\n",
       "      <td>-1.837647</td>\n",
       "      <td>-1.835673</td>\n",
       "      <td>-2.017222</td>\n",
       "      <td>-1.687687</td>\n",
       "      <td>-1.439100</td>\n",
       "      <td>0.438783</td>\n",
       "      <td>-1.361442</td>\n",
       "      <td>-1.456818</td>\n",
       "      <td>-2.018167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>-1.743773</td>\n",
       "      <td>-1.029678</td>\n",
       "      <td>-1.353637</td>\n",
       "      <td>0.309970</td>\n",
       "      <td>-0.670684</td>\n",
       "      <td>-1.513048</td>\n",
       "      <td>-1.654630</td>\n",
       "      <td>-0.577408</td>\n",
       "      <td>-1.474441</td>\n",
       "      <td>-1.655739</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.648721</td>\n",
       "      <td>-1.650780</td>\n",
       "      <td>-1.648807</td>\n",
       "      <td>-1.648034</td>\n",
       "      <td>-1.654971</td>\n",
       "      <td>-1.657699</td>\n",
       "      <td>-1.214312</td>\n",
       "      <td>-1.503080</td>\n",
       "      <td>-1.675416</td>\n",
       "      <td>-1.648979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>-1.562852</td>\n",
       "      <td>-1.031078</td>\n",
       "      <td>0.309970</td>\n",
       "      <td>-1.356437</td>\n",
       "      <td>-0.672084</td>\n",
       "      <td>-1.514448</td>\n",
       "      <td>-1.656030</td>\n",
       "      <td>-0.450975</td>\n",
       "      <td>-1.475840</td>\n",
       "      <td>-1.657139</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.650121</td>\n",
       "      <td>-1.652180</td>\n",
       "      <td>-1.650207</td>\n",
       "      <td>-1.649434</td>\n",
       "      <td>-1.656371</td>\n",
       "      <td>-1.659099</td>\n",
       "      <td>-1.215712</td>\n",
       "      <td>-1.504480</td>\n",
       "      <td>-1.676816</td>\n",
       "      <td>-1.650379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>-0.906669</td>\n",
       "      <td>0.840441</td>\n",
       "      <td>-0.670684</td>\n",
       "      <td>-0.672084</td>\n",
       "      <td>1.140281</td>\n",
       "      <td>-0.733103</td>\n",
       "      <td>-1.328351</td>\n",
       "      <td>1.157637</td>\n",
       "      <td>-1.448267</td>\n",
       "      <td>-1.329461</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.440226</td>\n",
       "      <td>-1.729967</td>\n",
       "      <td>-1.910315</td>\n",
       "      <td>-1.909542</td>\n",
       "      <td>-1.580007</td>\n",
       "      <td>-1.449203</td>\n",
       "      <td>0.238979</td>\n",
       "      <td>-0.560615</td>\n",
       "      <td>-0.981413</td>\n",
       "      <td>-1.910487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>-1.711363</td>\n",
       "      <td>-1.439100</td>\n",
       "      <td>-1.657699</td>\n",
       "      <td>-1.659099</td>\n",
       "      <td>-1.449203</td>\n",
       "      <td>-1.662959</td>\n",
       "      <td>-1.622219</td>\n",
       "      <td>-1.438815</td>\n",
       "      <td>-1.624351</td>\n",
       "      <td>-1.623328</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.616310</td>\n",
       "      <td>-1.618369</td>\n",
       "      <td>-1.616396</td>\n",
       "      <td>-1.615623</td>\n",
       "      <td>-1.622560</td>\n",
       "      <td>-1.625288</td>\n",
       "      <td>-0.740068</td>\n",
       "      <td>-1.652991</td>\n",
       "      <td>-1.643006</td>\n",
       "      <td>-1.616568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>0.061160</td>\n",
       "      <td>0.438783</td>\n",
       "      <td>-1.214312</td>\n",
       "      <td>-1.215712</td>\n",
       "      <td>0.238979</td>\n",
       "      <td>-1.018901</td>\n",
       "      <td>-1.766619</td>\n",
       "      <td>0.730420</td>\n",
       "      <td>-1.075604</td>\n",
       "      <td>-1.767728</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.760710</td>\n",
       "      <td>-1.762769</td>\n",
       "      <td>-1.760796</td>\n",
       "      <td>-1.760022</td>\n",
       "      <td>-1.766960</td>\n",
       "      <td>-0.740068</td>\n",
       "      <td>0.650862</td>\n",
       "      <td>-0.516456</td>\n",
       "      <td>-0.563630</td>\n",
       "      <td>-1.578646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“</th>\n",
       "      <td>-0.783554</td>\n",
       "      <td>-1.361442</td>\n",
       "      <td>-1.503080</td>\n",
       "      <td>-1.504480</td>\n",
       "      <td>-0.560615</td>\n",
       "      <td>-1.220658</td>\n",
       "      <td>-1.467600</td>\n",
       "      <td>-0.572700</td>\n",
       "      <td>-1.469732</td>\n",
       "      <td>-1.468709</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.644013</td>\n",
       "      <td>-1.646072</td>\n",
       "      <td>-1.644099</td>\n",
       "      <td>-1.643325</td>\n",
       "      <td>-1.467942</td>\n",
       "      <td>-1.652991</td>\n",
       "      <td>-0.516456</td>\n",
       "      <td>-1.092907</td>\n",
       "      <td>-0.061270</td>\n",
       "      <td>-1.644270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>”</th>\n",
       "      <td>-1.392608</td>\n",
       "      <td>-1.456818</td>\n",
       "      <td>-1.675416</td>\n",
       "      <td>-1.676816</td>\n",
       "      <td>-0.981413</td>\n",
       "      <td>-1.344204</td>\n",
       "      <td>-1.457615</td>\n",
       "      <td>-0.763386</td>\n",
       "      <td>-1.459747</td>\n",
       "      <td>-1.641046</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.634028</td>\n",
       "      <td>-1.636087</td>\n",
       "      <td>-1.634114</td>\n",
       "      <td>-1.633340</td>\n",
       "      <td>-1.457956</td>\n",
       "      <td>-1.643006</td>\n",
       "      <td>-0.563630</td>\n",
       "      <td>-0.061270</td>\n",
       "      <td>-0.705212</td>\n",
       "      <td>-1.634285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>❝real</th>\n",
       "      <td>-1.520321</td>\n",
       "      <td>-2.018167</td>\n",
       "      <td>-1.648979</td>\n",
       "      <td>-1.650379</td>\n",
       "      <td>-1.910487</td>\n",
       "      <td>-1.654239</td>\n",
       "      <td>-1.613499</td>\n",
       "      <td>-2.017882</td>\n",
       "      <td>-1.615631</td>\n",
       "      <td>-1.614608</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.607590</td>\n",
       "      <td>-1.609649</td>\n",
       "      <td>-1.607676</td>\n",
       "      <td>-1.606903</td>\n",
       "      <td>-1.613840</td>\n",
       "      <td>-1.616568</td>\n",
       "      <td>-1.578646</td>\n",
       "      <td>-1.644270</td>\n",
       "      <td>-1.634285</td>\n",
       "      <td>-1.607848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2325 rows × 2325 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              !         #         (         )         ,         -        --  \\\n",
       "!      1.452937 -0.167051 -1.743773 -1.562852 -0.906669 -1.279030 -1.708294   \n",
       "#     -0.167051  2.446712 -1.029678 -1.031078  0.840441 -0.495942 -1.553814   \n",
       "(     -1.743773 -1.029678 -1.353637  0.309970 -0.670684 -1.513048 -1.654630   \n",
       ")     -1.562852 -1.031078  0.309970 -1.356437 -0.672084 -1.514448 -1.656030   \n",
       ",     -0.906669  0.840441 -0.670684 -0.672084  1.140281 -0.733103 -1.328351   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "‘     -1.711363 -1.439100 -1.657699 -1.659099 -1.449203 -1.662959 -1.622219   \n",
       "’      0.061160  0.438783 -1.214312 -1.215712  0.238979 -1.018901 -1.766619   \n",
       "“     -0.783554 -1.361442 -1.503080 -1.504480 -0.560615 -1.220658 -1.467600   \n",
       "”     -1.392608 -1.456818 -1.675416 -1.676816 -0.981413 -1.344204 -1.457615   \n",
       "❝real -1.520321 -2.018167 -1.648979 -1.650379 -1.910487 -1.654239 -1.613499   \n",
       "\n",
       "              .       ...         1  ...    zombie      zone    zoomer  \\\n",
       "!      0.015555 -0.834957 -1.239399  ... -1.702385 -1.704444 -1.702471   \n",
       "#      1.355989 -1.843629 -1.842606  ... -2.017909 -1.837647 -1.835673   \n",
       "(     -0.577408 -1.474441 -1.655739  ... -1.648721 -1.650780 -1.648807   \n",
       ")     -0.450975 -1.475840 -1.657139  ... -1.650121 -1.652180 -1.650207   \n",
       ",      1.157637 -1.448267 -1.329461  ... -1.440226 -1.729967 -1.910315   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "‘     -1.438815 -1.624351 -1.623328  ... -1.616310 -1.618369 -1.616396   \n",
       "’      0.730420 -1.075604 -1.767728  ... -1.760710 -1.762769 -1.760796   \n",
       "“     -0.572700 -1.469732 -1.468709  ... -1.644013 -1.646072 -1.644099   \n",
       "”     -0.763386 -1.459747 -1.641046  ... -1.634028 -1.636087 -1.634114   \n",
       "❝real -2.017882 -1.615631 -1.614608  ... -1.607590 -1.609649 -1.607676   \n",
       "\n",
       "       zuckerberg         —         ‘         ’         “         ”     ❝real  \n",
       "!       -1.701697 -1.526314 -1.711363  0.061160 -0.783554 -1.392608 -1.520321  \n",
       "#       -2.017222 -1.687687 -1.439100  0.438783 -1.361442 -1.456818 -2.018167  \n",
       "(       -1.648034 -1.654971 -1.657699 -1.214312 -1.503080 -1.675416 -1.648979  \n",
       ")       -1.649434 -1.656371 -1.659099 -1.215712 -1.504480 -1.676816 -1.650379  \n",
       ",       -1.909542 -1.580007 -1.449203  0.238979 -0.560615 -0.981413 -1.910487  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "‘       -1.615623 -1.622560 -1.625288 -0.740068 -1.652991 -1.643006 -1.616568  \n",
       "’       -1.760022 -1.766960 -0.740068  0.650862 -0.516456 -0.563630 -1.578646  \n",
       "“       -1.643325 -1.467942 -1.652991 -0.516456 -1.092907 -0.061270 -1.644270  \n",
       "”       -1.633340 -1.457956 -1.643006 -0.563630 -0.061270 -0.705212 -1.634285  \n",
       "❝real   -1.606903 -1.613840 -1.616568 -1.578646 -1.644270 -1.634285 -1.607848  \n",
       "\n",
       "[2325 rows x 2325 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(word_context_matrix, index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2325, 2325)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_context_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = FastICA(n_components = 2)\n",
    "std_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07939531,  0.04692862],\n",
       "       [ 0.5964604 , -0.74662625],\n",
       "       [ 0.03041754,  0.03248434],\n",
       "       ...,\n",
       "       [ 0.02157791,  0.04395167],\n",
       "       [ 0.01506173,  0.03181825],\n",
       "       [-0.00260896, -0.00189695]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std = std_scaler.fit_transform(word_context_matrix)\n",
    "\n",
    "matrix = ica.fit_transform(X_std)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comp 1</th>\n",
       "      <th>Comp 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>0.079395</td>\n",
       "      <td>0.046929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>0.596460</td>\n",
       "      <td>-0.746626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>0.030418</td>\n",
       "      <td>0.032484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>0.031244</td>\n",
       "      <td>0.034450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.212362</td>\n",
       "      <td>0.269948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>0.004098</td>\n",
       "      <td>0.006565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>0.121454</td>\n",
       "      <td>0.088072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“</th>\n",
       "      <td>0.021578</td>\n",
       "      <td>0.043952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>”</th>\n",
       "      <td>0.015062</td>\n",
       "      <td>0.031818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>❝real</th>\n",
       "      <td>-0.002609</td>\n",
       "      <td>-0.001897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2325 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Comp 1    Comp 2\n",
       "!      0.079395  0.046929\n",
       "#      0.596460 -0.746626\n",
       "(      0.030418  0.032484\n",
       ")      0.031244  0.034450\n",
       ",      0.212362  0.269948\n",
       "...         ...       ...\n",
       "‘      0.004098  0.006565\n",
       "’      0.121454  0.088072\n",
       "“      0.021578  0.043952\n",
       "”      0.015062  0.031818\n",
       "❝real -0.002609 -0.001897\n",
       "\n",
       "[2325 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(matrix,\n",
    "                  index = cm.vocabulary,\n",
    "                  columns = ['Comp {}'.format(i+1) for i in range(2)])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 62222 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 62222 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = [key for key in cm.vocabulary.keys()]\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    \n",
    "    #if re.match('^co[rv]', word):\n",
    "    \n",
    "        x = df['Comp 1'][i]\n",
    "        y = df['Comp 2'][i]\n",
    "\n",
    "        plt.scatter(x, y)\n",
    "        plt.text(x, y, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set word embeddings for text classification\n",
    "ica = FastICA(n_components = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00153101,  0.0010119 , -0.00090222, ...,  0.00101982,\n",
       "         0.00012206, -0.00038451],\n",
       "       [ 0.0004737 ,  0.00191862, -0.00112544, ..., -0.0010941 ,\n",
       "        -0.00016633,  0.00060084],\n",
       "       [-0.00327405,  0.0021063 ,  0.0096288 , ...,  0.00324687,\n",
       "         0.00078901, -0.01345225],\n",
       "       ...,\n",
       "       [-0.00076578, -0.00183123, -0.00039772, ..., -0.00010112,\n",
       "         0.00434484,  0.0027538 ],\n",
       "       [ 0.00826986,  0.00247771, -0.00067697, ...,  0.00012779,\n",
       "        -0.00288695, -0.03482063],\n",
       "       [ 0.00872174, -0.00056048,  0.00101617, ..., -0.00498523,\n",
       "        -0.00684118,  0.01726375]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = ica.fit_transform(X_std)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out target\n",
    "y = tweets['Is_Unreliable']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derive text vectors from word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_vectors(word_embeddings,\n",
    "                     word_index_dict,\n",
    "                     text_list,\n",
    "                     remove_stopwords = True,\n",
    "                     lowercase = True,\n",
    "                     lemmatize = True,\n",
    "                     add_start_end_tokens = True):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    for k in range(len(text_list)):\n",
    "        text = text_list[k]\n",
    "        text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "        text_vec = np.zeros(word_embeddings.shape[1])\n",
    "        words = word_tokenize(text)\n",
    "        tracker = 0 # to track whether we've encountered a word for which we have an embedding (in each tweet)\n",
    "        \n",
    "        if remove_stopwords:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                if word.lower() not in set(stopwords.words('english')):\n",
    "                    clean_words.append(word)\n",
    "            words = clean_words\n",
    "\n",
    "        if lowercase:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                clean_words.append(word.lower())\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if lemmatize:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                PoS_tag = pos_tag([word])[0][1]\n",
    "\n",
    "                # to change contractions to full word form\n",
    "                if word in contractions:\n",
    "                    word = contractions[word]\n",
    "\n",
    "                if PoS_tag[0].upper() in 'JNVR':\n",
    "                    word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                else:\n",
    "                    word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                clean_words.append(word)\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if add_start_end_tokens:\n",
    "            words = ['<START>'] + words + ['<END>']\n",
    "        \n",
    "        for i in range(len(words)):\n",
    "            word = words[i]\n",
    "            if word in word_index_dict:\n",
    "                word_embed_vec = word_embeddings[word_index_dict[word],:]\n",
    "                if tracker == 0:\n",
    "                    text_matrix = word_embed_vec\n",
    "                else:\n",
    "                    text_matrix = np.vstack((text_matrix, word_embed_vec))\n",
    "                    \n",
    "                # only increment if we have come across a word in the embeddings dictionary\n",
    "                tracker += 1\n",
    "                    \n",
    "        for j in range(len(text_vec)):\n",
    "            text_vec[j] = text_matrix[:,j].mean()\n",
    "            \n",
    "        if k == 0:\n",
    "            full_matrix = text_vec\n",
    "        else:\n",
    "            full_matrix = np.vstack((full_matrix, text_vec))\n",
    "            \n",
    "    return full_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_text_vectors(embeddings, cm.vocabulary, tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 500)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.23422417e-04,  8.71934056e-04, -8.98442818e-05, ...,\n",
       "        -1.07627104e-05, -1.62204522e-03, -7.68201056e-04],\n",
       "       [ 9.25526502e-04,  2.81284711e-04, -1.48198940e-03, ...,\n",
       "         2.33852667e-04,  1.69877612e-05,  1.55078508e-04],\n",
       "       [ 1.14195485e-03,  8.61212223e-04,  1.70316965e-04, ...,\n",
       "        -2.84517267e-04, -1.57871354e-03, -1.10073082e-03],\n",
       "       ...,\n",
       "       [ 1.43176105e-03, -3.00537163e-04,  5.26612013e-04, ...,\n",
       "        -4.33400742e-04,  6.41766064e-05,  1.28485124e-03],\n",
       "       [-2.79490458e-05, -6.30952749e-05, -1.13872851e-03, ...,\n",
       "         1.10204695e-04, -1.88628170e-04,  5.72058571e-05],\n",
       "       [ 5.71555671e-04,  7.70744649e-04, -1.25200029e-03, ...,\n",
       "        -8.82659588e-05, -5.78190475e-04,  7.32218289e-04]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, KFold, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipe = Pipeline([\n",
    "    ('classify', SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC hyperparams to optimize\n",
    "kernel = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "C = [0.001, 0.01, 0.1, 1, 10]\n",
    "# set up parameter grid\n",
    "params = {\n",
    "    'classify__kernel': kernel,\n",
    "    'classify__C': C\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CV scheme for inner and outer loops\n",
    "inner_cv = KFold(n_splits = 3, shuffle = True, random_state = 1)\n",
    "outer_cv = KFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "\n",
    "# Set up GridSearch for inner loop\n",
    "grid_SVC = GridSearchCV(pipe, params, cv = inner_cv)\n",
    "#grid_SVC.fit(X, y)\n",
    "\n",
    "# Nested CV scores\n",
    "scores = cross_validate(grid_SVC,\n",
    "                        X = X,\n",
    "                        y = y,\n",
    "                        cv = outer_cv,\n",
    "                        scoring = ['roc_auc', 'accuracy', 'f1', 'precision', 'recall'],\n",
    "                        return_estimator = True)\n",
    "auc = scores['test_roc_auc']\n",
    "accuracy = scores['test_accuracy']\n",
    "f1 = scores['test_f1']\n",
    "precision = scores['test_precision']\n",
    "recall = scores['test_recall']\n",
    "estimators = scores['estimator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9261482716293645"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8696428571428572"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.876628608295861"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8303330981404752"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9305572193194852"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classify__C': 10, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 10, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 10, 'classify__kernel': 'linear'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in estimators:\n",
    "    print(i.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
