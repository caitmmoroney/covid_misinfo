{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Word Context Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.decomposition import FastICA, TruncatedSVD, PCA, NMF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert contractions picked up by word_tokenize() into full words\n",
    "contractions = {\n",
    "    \"n't\": 'not',\n",
    "    \"'ve\": 'have',\n",
    "    \"'s\": 'is', # note that this will include possessive nouns\n",
    "    'gonna': 'going to',\n",
    "    'gotta': 'got to',\n",
    "    \"'d\": 'would',\n",
    "    \"'ll\": 'will',\n",
    "    \"'re\": 'are',\n",
    "    \"'m\": 'am',\n",
    "    'wanna': 'want to'\n",
    "}\n",
    "\n",
    "# to convert nltk_pos tags to wordnet-compatible PoS tags\n",
    "def convert_pos_wordnet(tag):\n",
    "    tag_abbr = tag[0].upper()\n",
    "    tag_dict = {\n",
    "        'J': wordnet.ADJ,\n",
    "        'N': wordnet.NOUN,\n",
    "        'V': wordnet.VERB,\n",
    "        'R': wordnet.ADV\n",
    "    }\n",
    "                \n",
    "    if tag_abbr in tag_dict:\n",
    "        return tag_dict[tag_abbr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextMatrix(TransformerMixin):\n",
    "    \n",
    "    # initialize class & private variables\n",
    "    def __init__(self,\n",
    "                 window_size = 4,\n",
    "                 remove_stopwords = True,\n",
    "                 add_start_end_tokens = True,\n",
    "                 lowercase = False,\n",
    "                 lemmatize = False,\n",
    "                 pmi = False,\n",
    "                 spmi_k = 1,\n",
    "                 laplace_smoothing = 0,\n",
    "                 pmi_positive = False,\n",
    "                 sppmi_k = 1):\n",
    "        \n",
    "        \"\"\" Params:\n",
    "                window_size: size of +/- context window (default = 4)\n",
    "                remove_stopwords: boolean, whether or not to remove NLTK English stopwords\n",
    "                add_start_end_tokens: boolean, whether or not to append <START> and <END> to the\n",
    "                beginning/end of each document in the corpus (default = True)\n",
    "                lowercase: boolean, whether or not to convert words to all lowercase\n",
    "                lemmatize: boolean, whether or not to lemmatize input text\n",
    "                pmi: boolean, whether or not to compute pointwise mutual information\n",
    "                pmi_positive: boolean, whether or not to compute positive PMI\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.add_start_end_tokens = add_start_end_tokens\n",
    "        self.lowercase = lowercase\n",
    "        self.lemmatize = lemmatize\n",
    "        self.pmi = pmi\n",
    "        self.spmi_k = spmi_k\n",
    "        self.laplace_smoothing = laplace_smoothing\n",
    "        self.pmi_positive = pmi_positive\n",
    "        self.sppmi_k = sppmi_k\n",
    "        self.corpus = None\n",
    "        self.clean_corpus = None\n",
    "        self.vocabulary = None\n",
    "        self.X = None\n",
    "        self.doc_terms_lists = None\n",
    "    \n",
    "    def fit(self, corpus, y = None):\n",
    "        \n",
    "        \"\"\" Learn the dictionary of all unique tokens for given corpus.\n",
    "        \n",
    "            Params:\n",
    "                corpus: list of strings\n",
    "            \n",
    "            Returns: self\n",
    "        \"\"\"\n",
    "        self.corpus = corpus\n",
    "        \n",
    "        term_dict = dict()\n",
    "        k = 0\n",
    "        corpus_words = []\n",
    "        clean_corpus = []\n",
    "        doc_terms_lists = []\n",
    "        detokenizer = TreebankWordDetokenizer()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        for text in corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "            \n",
    "            # detokenize trick taken from this StackOverflow post:\n",
    "            # https://stackoverflow.com/questions/21948019/python-untokenize-a-sentence\n",
    "            # and NLTK treebank documentation:\n",
    "            # https://www.nltk.org/_modules/nltk/tokenize/treebank.html\n",
    "            text = detokenizer.detokenize(words)\n",
    "            clean_corpus.append(text)\n",
    "            \n",
    "            [corpus_words.append(word) for word in words]\n",
    "            \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            doc_terms_lists.append(words)\n",
    "            \n",
    "        self.clean_corpus = clean_corpus\n",
    "        \n",
    "        self.doc_terms_lists = doc_terms_lists\n",
    "        \n",
    "        corpus_words = list(set(corpus_words))\n",
    "        \n",
    "        if self.add_start_end_tokens:\n",
    "            corpus_words = ['<START>'] + corpus_words + ['<END>']\n",
    "        \n",
    "        corpus_words = sorted(corpus_words)\n",
    "        \n",
    "        for el in corpus_words:\n",
    "            term_dict[el] = k\n",
    "            k += 1\n",
    "            \n",
    "        self.vocabulary = term_dict\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def transform(self, new_corpus = None, y = None):\n",
    "        \n",
    "        \"\"\" Compute the co-occurrence matrix for given corpus and window_size, using term dictionary\n",
    "            obtained with fit method.\n",
    "        \n",
    "            Returns: term-context co-occurrence matrix (shape: target terms by context terms) with\n",
    "            raw counts\n",
    "        \"\"\"\n",
    "        num_terms = len(self.vocabulary)\n",
    "        window = self.window_size\n",
    "        X = np.full((num_terms, num_terms), self.laplace_smoothing)\n",
    "        \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        if type(new_corpus) != list:\n",
    "            new_corpus = self.corpus\n",
    "        \n",
    "        for text in new_corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            for i in range(len(words)):\n",
    "                target = words[i]\n",
    "                \n",
    "                # check to see if target word is in the dictionary; if not, skip\n",
    "                if target in self.vocabulary:\n",
    "                    \n",
    "                    # grab index from dictionary\n",
    "                    target_dict_index = self.vocabulary[target]\n",
    "                    \n",
    "                    # find left-most and right-most window indices for each target word\n",
    "                    left_end_index = max(i - window, 0)\n",
    "                    right_end_index = min(i + window, len(words) - 1)\n",
    "                    \n",
    "                    # loop over all words within window\n",
    "                    # NOTE: this will include the target word; make sure to skip over it\n",
    "                    for j in range(left_end_index, right_end_index + 1):\n",
    "                        \n",
    "                        # skip \"context word\" where the \"context word\" index is equal to the\n",
    "                        # target word index\n",
    "                        if j != i:\n",
    "                            context_word = words[j]\n",
    "                            \n",
    "                            # check to see if context word is in the fitted dictionary; if\n",
    "                            # not, skip\n",
    "                            if context_word in self.vocabulary:\n",
    "                                X[target_dict_index, self.vocabulary[context_word]] += 1\n",
    "        \n",
    "        # if pmi = True, compute pmi matrix from word-context raw frequencies\n",
    "        # more concise code taken from this StackOverflow post:\n",
    "        # https://stackoverflow.com/questions/58701337/how-to-construct-ppmi-matrix-from-a-text-corpus\n",
    "        if self.pmi:\n",
    "            denom = X.sum()\n",
    "            col_sums = X.sum(axis = 0)\n",
    "            row_sums = X.sum(axis = 1)\n",
    "            \n",
    "            expected = np.outer(row_sums, col_sums)/denom\n",
    "            \n",
    "            X = X/expected\n",
    "            \n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(X.shape[1]):\n",
    "                \n",
    "                    if X[i,j] > 0:\n",
    "                        X[i,j] = np.log(X[i,j]) - np.log(self.spmi_k)\n",
    "                        \n",
    "                        if self.pmi_positive:\n",
    "                            X[i,j] = max(X[i,j] - np.log(self.sppmi_k), 0)\n",
    "        \n",
    "        # note that X is a dense matrix\n",
    "        self.X = X\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(lowercase = True, lemmatize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [\n",
    "    \"Coronavirus is a fake liberal hoax.\",\n",
    "    \"Trump won't do anything about coronavirus.\",\n",
    "    \"The liberal fake news media always blame Pres Trump.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ContextMatrix at 0x1a18339c90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.fit(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <th>always</th>\n",
       "      <th>anything</th>\n",
       "      <th>blame</th>\n",
       "      <th>coronavirus</th>\n",
       "      <th>fake</th>\n",
       "      <th>hoax</th>\n",
       "      <th>liberal</th>\n",
       "      <th>medium</th>\n",
       "      <th>news</th>\n",
       "      <th>pres</th>\n",
       "      <th>trump</th>\n",
       "      <th>wont</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>always</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anything</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blame</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronavirus</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fake</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoax</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pres</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wont</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             .  <END>  <START>  always  anything  blame  coronavirus  fake  \\\n",
       ".            0      3        0       1         1      1            2     1   \n",
       "<END>        3      0        0       0         1      1            1     1   \n",
       "<START>      0      0        0       0         1      0            2     2   \n",
       "always       1      0        0       0         0      1            0     1   \n",
       "anything     1      1        1       0         0      0            1     0   \n",
       "blame        1      1        0       1         0      0            0     1   \n",
       "coronavirus  2      1        2       0         1      0            0     1   \n",
       "fake         1      1        2       1         0      1            1     0   \n",
       "hoax         1      1        1       0         0      0            1     1   \n",
       "liberal      1      1        2       1         0      0            1     2   \n",
       "medium       0      0        1       1         0      1            0     1   \n",
       "news         0      0        1       1         0      1            0     1   \n",
       "pres         1      1        0       1         0      1            0     0   \n",
       "trump        2      1        1       1         1      1            1     0   \n",
       "wont         1      1        1       0         1      0            1     0   \n",
       "\n",
       "             hoax  liberal  medium  news  pres  trump  wont  \n",
       ".               1        1       0     0     1      2     1  \n",
       "<END>           1        1       0     0     1      1     1  \n",
       "<START>         1        2       1     1     0      1     1  \n",
       "always          0        1       1     1     1      1     0  \n",
       "anything        0        0       0     0     0      1     1  \n",
       "blame           0        0       1     1     1      1     0  \n",
       "coronavirus     1        1       0     0     0      1     1  \n",
       "fake            1        2       1     1     0      0     0  \n",
       "hoax            0        1       0     0     0      0     0  \n",
       "liberal         1        0       1     1     0      0     0  \n",
       "medium          0        1       0     1     1      1     0  \n",
       "news            0        1       1     0     1      0     0  \n",
       "pres            0        0       1     1     0      1     0  \n",
       "trump           0        0       1     0     1      0     1  \n",
       "wont            0        0       0     0     0      1     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cm.transform(tweets), index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coronavirus fake liberal hoax.',\n",
       " 'trump wont anything coronavirus.',\n",
       " 'liberal fake news medium always blame pres trump.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.clean_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coronavirus is a fake liberal hoax.',\n",
       " \"Trump won't do anything about coronavirus.\",\n",
       " 'The liberal fake news media always blame Pres Trump.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train embeddings using tweets as corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('COVID19_Dataset-text_labels_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Unreliable</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 3, 6, 9</td>\n",
       "      <td>We are living in scary times in Canada. Gov’t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 6, 8, 9</td>\n",
       "      <td>Just as bad in Canada. In fact, our government...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 4, 9</td>\n",
       "      <td>It was only a matter of time before the mainst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8</td>\n",
       "      <td>Russia's taking no chances: Foreigners infecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8, 9</td>\n",
       "      <td>Although there is now a presumptive confirmed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BREAKING: Harvard classes will move online sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singularity University is hosting a FREE Virtu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus: how does it spread and what are t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stanford just cancelled classes for the rest o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tech conferences were cancelled in #Waterloo R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Is_Unreliable    Category  \\\n",
       "0                1  1, 3, 6, 9   \n",
       "1                1  1, 6, 8, 9   \n",
       "2                1     1, 4, 9   \n",
       "3                1        6, 8   \n",
       "4                1     6, 8, 9   \n",
       "..             ...         ...   \n",
       "555              0         NaN   \n",
       "556              0         NaN   \n",
       "557              0         NaN   \n",
       "558              0         NaN   \n",
       "559              0         NaN   \n",
       "\n",
       "                                                 Tweet  \n",
       "0    We are living in scary times in Canada. Gov’t ...  \n",
       "1    Just as bad in Canada. In fact, our government...  \n",
       "2    It was only a matter of time before the mainst...  \n",
       "3    Russia's taking no chances: Foreigners infecte...  \n",
       "4    Although there is now a presumptive confirmed ...  \n",
       "..                                                 ...  \n",
       "555  BREAKING: Harvard classes will move online sta...  \n",
       "556  Singularity University is hosting a FREE Virtu...  \n",
       "557  Coronavirus: how does it spread and what are t...  \n",
       "558  Stanford just cancelled classes for the rest o...  \n",
       "559  Tech conferences were cancelled in #Waterloo R...  \n",
       "\n",
       "[560 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(window_size = 15, lowercase = True, lemmatize = True, pmi = True, laplace_smoothing = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_context_matrix = cm.fit_transform(tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>#</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>,</th>\n",
       "      <th>-</th>\n",
       "      <th>--</th>\n",
       "      <th>.</th>\n",
       "      <th>...</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoomer</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>—</th>\n",
       "      <th>‘</th>\n",
       "      <th>’</th>\n",
       "      <th>“</th>\n",
       "      <th>”</th>\n",
       "      <th>❝real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>4.033677</td>\n",
       "      <td>1.782558</td>\n",
       "      <td>-0.582773</td>\n",
       "      <td>0.104395</td>\n",
       "      <td>0.991225</td>\n",
       "      <td>0.781197</td>\n",
       "      <td>-0.421188</td>\n",
       "      <td>1.986763</td>\n",
       "      <td>1.647942</td>\n",
       "      <td>0.959731</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.392164</td>\n",
       "      <td>-0.402355</td>\n",
       "      <td>-0.392590</td>\n",
       "      <td>-0.388743</td>\n",
       "      <td>0.270302</td>\n",
       "      <td>-0.436003</td>\n",
       "      <td>2.408150</td>\n",
       "      <td>1.634762</td>\n",
       "      <td>0.580307</td>\n",
       "      <td>0.299704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>1.782558</td>\n",
       "      <td>3.970288</td>\n",
       "      <td>0.863019</td>\n",
       "      <td>0.857040</td>\n",
       "      <td>2.472735</td>\n",
       "      <td>1.533842</td>\n",
       "      <td>0.108314</td>\n",
       "      <td>2.867662</td>\n",
       "      <td>-0.595145</td>\n",
       "      <td>-0.590209</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.248956</td>\n",
       "      <td>-0.566000</td>\n",
       "      <td>-0.556236</td>\n",
       "      <td>-1.245536</td>\n",
       "      <td>-0.181025</td>\n",
       "      <td>0.316642</td>\n",
       "      <td>2.309043</td>\n",
       "      <td>0.372504</td>\n",
       "      <td>0.234340</td>\n",
       "      <td>-1.250236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>-0.582773</td>\n",
       "      <td>0.863019</td>\n",
       "      <td>0.727702</td>\n",
       "      <td>3.119619</td>\n",
       "      <td>1.444250</td>\n",
       "      <td>0.299913</td>\n",
       "      <td>-0.209324</td>\n",
       "      <td>1.451412</td>\n",
       "      <td>0.473511</td>\n",
       "      <td>-0.214700</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.180300</td>\n",
       "      <td>-0.190491</td>\n",
       "      <td>-0.180727</td>\n",
       "      <td>-0.176880</td>\n",
       "      <td>-0.210981</td>\n",
       "      <td>-0.224140</td>\n",
       "      <td>0.828254</td>\n",
       "      <td>0.342548</td>\n",
       "      <td>-0.306442</td>\n",
       "      <td>-0.181580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>0.104395</td>\n",
       "      <td>0.857040</td>\n",
       "      <td>3.119619</td>\n",
       "      <td>0.715745</td>\n",
       "      <td>1.438272</td>\n",
       "      <td>0.293935</td>\n",
       "      <td>-0.215303</td>\n",
       "      <td>1.599584</td>\n",
       "      <td>0.467533</td>\n",
       "      <td>-0.220678</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.186279</td>\n",
       "      <td>-0.196470</td>\n",
       "      <td>-0.186706</td>\n",
       "      <td>-0.182859</td>\n",
       "      <td>-0.216960</td>\n",
       "      <td>-0.230118</td>\n",
       "      <td>0.822275</td>\n",
       "      <td>0.336569</td>\n",
       "      <td>-0.312421</td>\n",
       "      <td>-0.187558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.991225</td>\n",
       "      <td>2.472735</td>\n",
       "      <td>1.444250</td>\n",
       "      <td>1.438272</td>\n",
       "      <td>2.915770</td>\n",
       "      <td>1.347818</td>\n",
       "      <td>0.576217</td>\n",
       "      <td>2.799738</td>\n",
       "      <td>0.342761</td>\n",
       "      <td>0.570841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382097</td>\n",
       "      <td>-0.321241</td>\n",
       "      <td>-1.004624</td>\n",
       "      <td>-1.000777</td>\n",
       "      <td>0.063734</td>\n",
       "      <td>0.338258</td>\n",
       "      <td>2.223560</td>\n",
       "      <td>1.598092</td>\n",
       "      <td>1.066886</td>\n",
       "      <td>-1.005477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>-0.436003</td>\n",
       "      <td>0.316642</td>\n",
       "      <td>-0.224140</td>\n",
       "      <td>-0.230118</td>\n",
       "      <td>0.338258</td>\n",
       "      <td>-0.246463</td>\n",
       "      <td>-0.062554</td>\n",
       "      <td>0.317248</td>\n",
       "      <td>-0.072865</td>\n",
       "      <td>-0.067929</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033530</td>\n",
       "      <td>-0.043721</td>\n",
       "      <td>-0.033956</td>\n",
       "      <td>-0.030109</td>\n",
       "      <td>-0.064211</td>\n",
       "      <td>-0.077369</td>\n",
       "      <td>1.668171</td>\n",
       "      <td>-0.203829</td>\n",
       "      <td>-0.159672</td>\n",
       "      <td>-0.034809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>2.408150</td>\n",
       "      <td>2.309043</td>\n",
       "      <td>0.828254</td>\n",
       "      <td>0.822275</td>\n",
       "      <td>2.223560</td>\n",
       "      <td>1.142402</td>\n",
       "      <td>-0.619599</td>\n",
       "      <td>2.616674</td>\n",
       "      <td>1.161849</td>\n",
       "      <td>-0.624974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.590575</td>\n",
       "      <td>-0.600766</td>\n",
       "      <td>-0.591001</td>\n",
       "      <td>-0.587154</td>\n",
       "      <td>-0.621256</td>\n",
       "      <td>1.668171</td>\n",
       "      <td>2.919415</td>\n",
       "      <td>1.878184</td>\n",
       "      <td>1.848233</td>\n",
       "      <td>0.101293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“</th>\n",
       "      <td>1.634762</td>\n",
       "      <td>0.372504</td>\n",
       "      <td>0.342548</td>\n",
       "      <td>0.336569</td>\n",
       "      <td>1.598092</td>\n",
       "      <td>1.013371</td>\n",
       "      <td>0.504133</td>\n",
       "      <td>1.471722</td>\n",
       "      <td>0.493822</td>\n",
       "      <td>0.498758</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.159990</td>\n",
       "      <td>-0.170181</td>\n",
       "      <td>-0.160416</td>\n",
       "      <td>-0.156569</td>\n",
       "      <td>0.502476</td>\n",
       "      <td>-0.203829</td>\n",
       "      <td>1.878184</td>\n",
       "      <td>1.279149</td>\n",
       "      <td>2.758391</td>\n",
       "      <td>-0.161269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>”</th>\n",
       "      <td>0.580307</td>\n",
       "      <td>0.234340</td>\n",
       "      <td>-0.306442</td>\n",
       "      <td>-0.312421</td>\n",
       "      <td>1.066886</td>\n",
       "      <td>0.769846</td>\n",
       "      <td>0.548291</td>\n",
       "      <td>1.264565</td>\n",
       "      <td>0.537979</td>\n",
       "      <td>-0.150232</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115832</td>\n",
       "      <td>-0.126024</td>\n",
       "      <td>-0.116259</td>\n",
       "      <td>-0.112412</td>\n",
       "      <td>0.546634</td>\n",
       "      <td>-0.159672</td>\n",
       "      <td>1.848233</td>\n",
       "      <td>2.758391</td>\n",
       "      <td>1.955250</td>\n",
       "      <td>-0.117112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>❝real</th>\n",
       "      <td>0.299704</td>\n",
       "      <td>-1.250236</td>\n",
       "      <td>-0.181580</td>\n",
       "      <td>-0.187558</td>\n",
       "      <td>-1.005477</td>\n",
       "      <td>-0.203904</td>\n",
       "      <td>-0.019994</td>\n",
       "      <td>-1.249630</td>\n",
       "      <td>-0.030306</td>\n",
       "      <td>-0.025370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009030</td>\n",
       "      <td>-0.001161</td>\n",
       "      <td>0.008603</td>\n",
       "      <td>0.012450</td>\n",
       "      <td>-0.021651</td>\n",
       "      <td>-0.034809</td>\n",
       "      <td>0.101293</td>\n",
       "      <td>-0.161269</td>\n",
       "      <td>-0.117112</td>\n",
       "      <td>0.007750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2325 rows × 2325 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              !         #         (         )         ,         -        --  \\\n",
       "!      4.033677  1.782558 -0.582773  0.104395  0.991225  0.781197 -0.421188   \n",
       "#      1.782558  3.970288  0.863019  0.857040  2.472735  1.533842  0.108314   \n",
       "(     -0.582773  0.863019  0.727702  3.119619  1.444250  0.299913 -0.209324   \n",
       ")      0.104395  0.857040  3.119619  0.715745  1.438272  0.293935 -0.215303   \n",
       ",      0.991225  2.472735  1.444250  1.438272  2.915770  1.347818  0.576217   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "‘     -0.436003  0.316642 -0.224140 -0.230118  0.338258 -0.246463 -0.062554   \n",
       "’      2.408150  2.309043  0.828254  0.822275  2.223560  1.142402 -0.619599   \n",
       "“      1.634762  0.372504  0.342548  0.336569  1.598092  1.013371  0.504133   \n",
       "”      0.580307  0.234340 -0.306442 -0.312421  1.066886  0.769846  0.548291   \n",
       "❝real  0.299704 -1.250236 -0.181580 -0.187558 -1.005477 -0.203904 -0.019994   \n",
       "\n",
       "              .       ...         1  ...    zombie      zone    zoomer  \\\n",
       "!      1.986763  1.647942  0.959731  ... -0.392164 -0.402355 -0.392590   \n",
       "#      2.867662 -0.595145 -0.590209  ... -1.248956 -0.566000 -0.556236   \n",
       "(      1.451412  0.473511 -0.214700  ... -0.180300 -0.190491 -0.180727   \n",
       ")      1.599584  0.467533 -0.220678  ... -0.186279 -0.196470 -0.186706   \n",
       ",      2.799738  0.342761  0.570841  ...  0.382097 -0.321241 -1.004624   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "‘      0.317248 -0.072865 -0.067929  ... -0.033530 -0.043721 -0.033956   \n",
       "’      2.616674  1.161849 -0.624974  ... -0.590575 -0.600766 -0.591001   \n",
       "“      1.471722  0.493822  0.498758  ... -0.159990 -0.170181 -0.160416   \n",
       "”      1.264565  0.537979 -0.150232  ... -0.115832 -0.126024 -0.116259   \n",
       "❝real -1.249630 -0.030306 -0.025370  ...  0.009030 -0.001161  0.008603   \n",
       "\n",
       "       zuckerberg         —         ‘         ’         “         ”     ❝real  \n",
       "!       -0.388743  0.270302 -0.436003  2.408150  1.634762  0.580307  0.299704  \n",
       "#       -1.245536 -0.181025  0.316642  2.309043  0.372504  0.234340 -1.250236  \n",
       "(       -0.176880 -0.210981 -0.224140  0.828254  0.342548 -0.306442 -0.181580  \n",
       ")       -0.182859 -0.216960 -0.230118  0.822275  0.336569 -0.312421 -0.187558  \n",
       ",       -1.000777  0.063734  0.338258  2.223560  1.598092  1.066886 -1.005477  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "‘       -0.030109 -0.064211 -0.077369  1.668171 -0.203829 -0.159672 -0.034809  \n",
       "’       -0.587154 -0.621256  1.668171  2.919415  1.878184  1.848233  0.101293  \n",
       "“       -0.156569  0.502476 -0.203829  1.878184  1.279149  2.758391 -0.161269  \n",
       "”       -0.112412  0.546634 -0.159672  1.848233  2.758391  1.955250 -0.117112  \n",
       "❝real    0.012450 -0.021651 -0.034809  0.101293 -0.161269 -0.117112  0.007750  \n",
       "\n",
       "[2325 rows x 2325 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(word_context_matrix, index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2325, 2325)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_context_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = FastICA(n_components = 2)\n",
    "std_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.26056670e-01, -3.82822859e-02],\n",
       "       [-6.52284715e-03, -9.26812968e-01],\n",
       "       [-6.99184780e-02,  1.00709074e-02],\n",
       "       ...,\n",
       "       [-6.82925176e-02,  2.53481764e-02],\n",
       "       [-4.94207633e-02,  1.82282355e-02],\n",
       "       [ 4.28400971e-03,  1.33903704e-04]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std = std_scaler.fit_transform(word_context_matrix)\n",
    "\n",
    "matrix = ica.fit_transform(X_std)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comp 1</th>\n",
       "      <th>Comp 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>-0.126057</td>\n",
       "      <td>-0.038282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>-0.006523</td>\n",
       "      <td>-0.926813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>-0.069918</td>\n",
       "      <td>0.010071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>-0.072598</td>\n",
       "      <td>0.011399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>-0.366977</td>\n",
       "      <td>0.117571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>-0.013020</td>\n",
       "      <td>0.003249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>-0.194973</td>\n",
       "      <td>-0.010923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“</th>\n",
       "      <td>-0.068293</td>\n",
       "      <td>0.025348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>”</th>\n",
       "      <td>-0.049421</td>\n",
       "      <td>0.018228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>❝real</th>\n",
       "      <td>0.004284</td>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2325 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Comp 1    Comp 2\n",
       "!     -0.126057 -0.038282\n",
       "#     -0.006523 -0.926813\n",
       "(     -0.069918  0.010071\n",
       ")     -0.072598  0.011399\n",
       ",     -0.366977  0.117571\n",
       "...         ...       ...\n",
       "‘     -0.013020  0.003249\n",
       "’     -0.194973 -0.010923\n",
       "“     -0.068293  0.025348\n",
       "”     -0.049421  0.018228\n",
       "❝real  0.004284  0.000134\n",
       "\n",
       "[2325 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(matrix,\n",
    "                  index = cm.vocabulary,\n",
    "                  columns = ['Comp {}'.format(i+1) for i in range(2)])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 62222 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 62222 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAD4CAYAAAD1oX97AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxU1f3/8ddnlmwEQiDsq7IICgElgmzqV0RQVLSKqIha3FqrWKzWtZa61SoqULUWV1x+orUoIrgRQKtSK8guKCAgIAEk7CEJST6/P2YSSAwCJhAc38/HYx4z986Ze88cwrznnHvuHXN3RERE5OcvUNUVEBERkcqhUBcREYkRCnUREZEYoVAXERGJEQp1ERGRGBGq6grsTVpamjdv3ryqqyEi8rMya9as7929TlXXQ6rGYRvqzZs3Z+bMmVVdDRGRnxUzW1nVdZCqo+F3ERGRGKFQFxERiREKdRERkRihUBcREYkRCnUREZEYoVAXERGJEQp1ERGRGKFQFxERiRGH7cVnfqm+/iyLGROWsT07j+Ra8XTt34LWXepXdbVERORnQKF+GPn6syymvbyYgvwiALZn5zHt5cUACnYREdmnmA31efPmkZmZyZYtW0hJSaFXr16kp6dXdbV+1IwJy0oCHWD0xJu49JRbmDEhrFAXEZF9islQnzdvHhMnTmTXrl0AbNmyhYkTJwIc1sG+PTuv5HGRF7Fh6xqS4muUWi8iIrI3MTlRLjMzsyTQi+3atYvMzMwqqtH+Sa4VX/I4a9NKOh7Rk7hQfKn1IiIiexOTob5ly5ZSyy+//DLbtm37wfrDTdf+LQjFRf5JGtY6gvO6XUsoLkDX/i2quGYiIvJzEJPD7ykpKaUCfNCgQSXrD2fFx801+11ERH6KmAz1Xr16lTqmDhAOh+nVq1cV1mr/tO5SXyEuIiI/SUyGevFkuJ/b7HcREZGKiMlQh0iwK8RFROSXJCYnyomIiPwSKdRFRERihEJdREQkRijUReSg27FjB/369aNDhw60a9eOV199lbvvvpvjjz+edu3acfXVV+PuLFu2jOOOO67kdUuWLKFTp05VWHORnxeFuogcdO+++y4NGzZk7ty5LFiwgL59+3Ldddfx+eefs2DBAnbu3Mnbb79NixYtSElJYc6cOQA899xzXH755Xvd7rBhw1i4cGHJvcgvnUJdRA6af2dlk/HpQn6zI8QLk97hnOuG8p///IeUlBSmTZtGly5daN++PVOnTi0J5SuvvJLnnnuOwsJCXn31VS6++OJyt71z507Gjx9P8+bNGT9+PG3bti31/ObNm3niiSd+8LqTTz6Z6dOnl9yXZ+TIkeTk5DB69Gjatm1Lo0aNuO6660qef/755+ncuTMjRoxg+PDhjBgxotTrw+Ewr7/++oE0Fd26dTug8j/GzJqbWfkNJzFNoS4iB8W/s7K56atVrM7bRbBJM1L+8TKfpNTn6j/czN133821117L66+/zvz587nqqqvIzc0F4LzzzuOdd97h7bffplOnTtSuXbtkm/n5+Zx44okUFBSwZs0atm7dysaNG2nZsiWBQOmPs72F+saNG0lPTy+5L09xqD/xxBNMnjyZ++67r9TzOTk5rF+/HoAVK1bw7LPPEgwGAWjbti0FBQUMGDAAM8PMqFOnDsFgEDMjFAoRCAQIh8OYGeFwmNq1azNnzhxSU1MJhUKYGU2bNiUUClG9enVq1qxJ586deeKJJ3j00UdJTU3FzGjXrh0JCQnExcURFxdHOBwGOBa4HXjOzIrMbJGZZZrZgj3fg5kNN7Obyr53MzvZzNaaWVp0+TdmdumP/VvL4cPcvarrUK6MjAyfOXNmVVdDRH6ijE8XsjovclXHwu/XE6iRgsXFk/zZR7T771RmzJjBihUrKCws5IQTTuD8889n+PDhAFx//fX8+9//5plnnuH0008v2eakbyYx9Lah5NfMJ7kwmZ4NejLmnjHl7v/CCy9kwoQJHHXUUfTu3Zu6devyyiuvsGTJEs4991wmTZrEkUceycyZMzEz6tatS6dOnZg8eXKp7cTFxbFr1y7MjEAgQEFBwcFpsNjkgEXvtwPVgV3R5bg9ys0DGgLrgGOANcAm4EPgYmA10BwoAKa5+3lm9igwAPgeCAOtgDeAK4H/7LHtxsBL7v77g/IODzMxe/EZEalaa/J2X6a5YPlStv9zJJixMRRi3EtjefPNN2nfvj3Nmzfn+OOPL/XaQYMGMX78eE477bSSdZO+mcTwT4dj7YzNr29mY85GwteGmfTNJPod2Y/nn3+eqVOn8vnnn9OjRw9mzZpFMBjk3TvvZOyf/sTDS5dSOz4BKyrkvffeIzs7m+zsbMyMevXqkZWVVRLoZkZycjI5OTnUqlWLrKws3J2ioqJD03ixw/a4r77H43CZci2BBCAtutwoemsXXR4B3Bt97a/MbCcwm8gXgfuj23sYqAXMcPd2AGYWBP4HjN9rBc2WEPmy8Cd3L/eYiZmtADLc/XszSwL+BbQA4oGP3X1wtFw88ALQCdgIDHT3FWbWG3iAyBeZfOBmd58afU0n4HkgEZgM3OAV6G2rpy4iB8WePfU9NY4PM7PbMT/62hEjRrBlyxbuueeeknWnvX4aa3esxYucxUMXYwHjqEePomGNhvT9ti8PP/wwO3bsYOvWrbz99tv8/ve/J2vNGu5MS+Pe1aspciclGGRtQQEOYEYwtTaF2d8TDoTYVRTpgdesWZPNmzdXZlNI1dgRvTci4VsIZAFfATOAOsBFQEq0zGYiXyo6As8BRwJFREYL0oFOe4R6F3efZmb3AIOA37n7O2Z2LZDu7r8xswuBc919oJkdC6xz9+/MrB3wnrs3AjCz/wE3AP8lEuqjo9sKunvhAb9rdz8sb506dXKRWNKjRw//9NNPK217Y8eO9fbt23t6erpfcskl/tZbb3nnzp29Y8eO3qtXL8/KynJ39+nTp3uHDh28Q4cO3rFjR9+6dau7uz/44IOekZHh7du397vuuqtS6rRp0yZ//PHH3d399bUbvfn0OV5v6myvN3W2p/2/SR5q0txPGjDQ27dv7+edd57v2LHDZ86c6d27d/caNWp4cnKyJycne5MmTbxevXreoEEDT0xM9JRq1bzFn1t4u+fbebBG0AngGB5MDnqDyxp6MLmGB+o1iNwHgv7Hi0Z6OBjngIciQ72eYOZHxcd7qHhdIOgkV3fAA4GQEy2nW8zecsosFxHpNRdGH2+LlikicojgfWBSdF0h8DHwBTAfaEPkcEAWkcMK3wI9iRw2GA9MA74h8kXhWWAR8LxHOtEG5AKziHzB+N6juQdsAD6P7utCIqMB70bL/gdo4/vIzioP773dFOoSS/Lz871Hjx5eVFRUKdtbsGCBt27d2jds2ODu7hs3bvTs7OyS7T/11FN+4403urv7mWee6R9//LG7u2/bts137drl7733nl911VVeVFTkhYWF3q9fP//www/3ud/ly5d7mzZt/Morr/Sjjz7ae/fu7Tk5Ob506VLv06ePH3PMMZ6UlOSLFi3ygoICr9u0mR/38Xyv88a0kg/Tjz/+2Hv06OHnnXeeP/jgg961a1d/5pln/Morr/Rx48b5r3/9a9+8ebOHw2G/4oorfPNbb/n/Va/u8bXCHogPREIdnBB+xG1HuMWbJ3RJ9xp//IvX6XyqmwW8Xs2mbhbwAHhKIOCAG3hGYqIHwYPg1K7jgXB8VQeNbofPbTuR8HYiwV58v51I4H8NnANcCzztkRB+gMgw+5HR5U3ABCLB3T/6+p5EJqXPIjIKcD4wPVq+c/Q16dHltcAi3x3ymUCr6OMuwFTfR3ZWSgADfYl841gK3FrO8/HAq9HnPwOa72ubCnWJJfn5+SUBXBFz5871Rx55xPv27eunnnqqz507t+S5efPmee/evb1du3beunVr79Onj7u7//Wvf/XOnTv7qFGjfNWqVe7u/oc//MGbNWtW0oNv0aKFP/300/vc//Llyz0YDPrs2bPd3X3AgAH+4osv+imnnOJff/21Dxw40OPj4z05OdkzMjK8ZnKyn1SrltcPhfyIxEQPmHlubq43b97c+17Y1xPqJnggIeCBuIBbwDwUCnlCQoJPnTrVAW9Yv573bdPCb+7TM/LBa7iFLHIfNm/z9zZOINJjD6alekJ8dTfMgxbpeQfKfHDXC4U8QCTgg3EJ3rt1z6oOEt0O3a2wnHXLyyzvJBLEXxMZov8MmEKkR78aeIZIuE4hMidtCTDBd2fdJuD66OMjo6+rHV1+AbgeWAbcSaTXvyRa5kLfHepToo+To/WZs8etJPD3dqvwRLnoRITHgd7RN/25mb3l7l/uUewKYJO7t4weZ/gbMLCi+xb5uQiHw6Slpe274I+YN28eEydOZNeuyHHqvLw8Jk6cCER+lfD666/nxhtv5Oyzz2b69OklM8lvvfVW+vXrx+TJkznhhBOYMmUK7s5tt93GNddcs1/7Lf4Z48LCQho1akTHjh0B6NSpEytWrODTTz9lwIAB5OfnY2Y0btyYP597LufeeSfp8Qm0qF6D5ECAv+/cybSRI2l8dGNmrptJUaCI+EbxWMhIbpbM4D6DGf/YeM4++2zMjMuOT+eJKf+hZcO6kco4eIET1zCO/HX5rHt9HQBFhUUEPQeKgpgFMDNwaJnalJMshze3bGJDYSEpgSDfU0ByUjW278xhWfaikvcZChgFRV6hfyM5rJV3CnfzMstOJNQbRx+3IDIjfxvwSLR8IZFAHwNkU3qmfQ6lJwQGomUgMhHwNmAokR7+8dF1i6P3RLe7Zo/6bnb3jhV9kweqM7DU3b9x93xgHJFhhz31B8ZGH78O9DIzQ+QAVObFOQ6Jea/Bo+1geM3I/bzXKrS5zMzMkkA/4ogjWLhwIVu2bCEzM5Ps7Gy2bNlCo0aNABg7dmzJ65YtW0b79u255ZZbyMjIYPHixfTp04dnn32W7du3A7BmzZqS865LvYXoF4ktW7YAsG3bNnJzc5k3bx4AwWCQ7OxsatasyZw5c5g8eTItWrRg0aJFbP7X67SKi+Ob/Hzm5+6kY0ICDjw3ahQb6m9gx4odhGuFKdxWSOH2QpI6JjGn4RzOOOMMEhMTCZgxbeFX1KqWxDvzvyIlMR4ACxmBcIBg9SBbv9iKhY1QYohgXiHGLpLigtSsloBhrM7ZzH+DNSmyyEfd2GNb0619B3Jzc3B3eh19JAABM4Jl52NLrNrzFIay3+KKT7fLBVoDQSLhXEgkxzKj5Y4gMsHuX+wOcYBVwMnRx2cAO9zdzawmcCrwMpHe+Q5gS7QuSUCLaCZWA94BcPetwHIzGwBgER329eYq45S2RtE3Umw1keGJcsu4e4GZbQFqEzm/sISZXQ1cDdC0adNKqJocCgUFBYRCB//syE8//fQH6woLC0su+nFYmfcaTBwKu3ZGlresiiwDpF/wkzZZHKwAdevWpWfPnjz//PMEAgHmzp3L8OHDGTBgAI0aNeKEE05g+fLlQORCKtOmTSMYDHL00Udz+umnEx8fz6JFi+jatSsAycnJvPTSS9StW7fUPjMzM/nggw+Ii4sr+VLl7mRmZpZcuKVGjRo0apzCPfe05cgWOeTkfM+UzJEUbtxIWjDE7J05NImLIyEYIABMzMqicNJGLGhUO6Ya9QfW55v7vmHFwytYaStZUHsBRx11FPNmfs6itevZujOX+ATj9jvqcNef1mMhI5gcJHdNLmZG4hGJ5K/MZVe+4zihQIAmqSl8v20bOXlbWbBhOxaM/H0O2bGcnUvzKYx+lD/7n88BKHKn8MDnGcvhJ5/S57+XVTzMXmwhkfPiITLZrR6Rzm4iMJVIb3ojcBQwz90nmNkZQFMivfKjgeZm9msis+CXEAnopUSOxWdFt30dkfA/n8iodhMiPfQlRHr6vyZyPn4BkaH9YoOAf5jZnURO2xsHzP2xBqiMT+Lyetxlv/3sTxncfQyRIQ0yMjI0DlYFXnjhBUaMGIGZkZ6ezr333suQIUPYsGEDderU4bnnnqNp06Zcfvnl1KpVi9mzZ3Pcccdxxx130Lp165Ih2nA4THx8PCeeeCKzZs0iKyuLcDhMQUEB6enpzJ8/n2OOOYZwOMwXX3xBKBQiKSmJ6tWr06pVKzIzMxkyZAhvv/02AI0aNeLrr79m586d9OjRgzlz5mBm5OTkcNRRR7F8+XIyMzPp1q0bI0aMYPv27QwfPpzRo0fz5JNPEgqFOProoxk3btyhacjMu3cHerFdOyPrf2Kop6SklAr2jh070rFjR1JSUhg2bBgA/fuXHSSDv//97+Vu74YbbuCGG2740X3uub+9rd+2fTE33ljEo4+uZsP6Alav3sXLL91Pt061CXywkfrhMOkJiaQGgzgQDATo+nAPZtw1Awsaic0SSWicQMG2Ak5+4mRuT7udESNGEA6HuHNIO56bOpdrflubca9sAqBegxDxvWqzc/lO6p5Vl+2LttMgpQY3nNydz5evYtHa9azftoNmtVNZlb2ZIndqpdVm47q1LPkulSOK1pMYF6ZdhxPY3uO3LBh1KXgRhUXFc6MgMdHYuVMfQTHAKZ0/RmQofRXQnt3nwRfPCfuOyDnzT7I7pO9x9zfNLN7Mktx9MuVnGpQeit9dCfd7iZxnf2CVd19OZM7afquM4ffVRL51FGtMpGHKLWNmISLDFtnIYWXhwoXcd999TJ06lblz5zJq1Ciuu+46Lr30UubNm8egQYMYOnRoSfmvv/6ayZMnc+edd3L77bdTrVo1atasySuvvELbtm3ZsGEDzZs3JxQK0bhxY6655hrcnc8//5zExESmT5/OrFmzSEhIIBgMkpSUxJtvvslnn33GX/7yFyAS5v/6178YOXIkeXl5ANx77724O2PGjOH0008vGfLt1q0bmzZtKvWeHnjgAWbPns28efN48sknD11jbll9YOv3Q69evYovA1oiHA7Tq1evn7zNfUlJSSm1XLNmTa699tqS9TfddBO/OncN9eoV8sADDXjm2SaceFI1pk/fzCNffguBIC81bcawOnUImVE7FKJOnTpk/yObpIZJpbZtGDcct/tLRny1ZOpnfP+DT6m8rYVsGZeFuVH7lNo0OaEJNULx0VCGjdtzaNugDnWqV2PQCcfS+P8GcdfttxIXn8DRF93GmKOPpd3Rnfg6rjHbwtWJb3gU1dqdioWTqN+0Jk2ahBToB0cRkEfk6nHFsoE9L0ji0TJFRIa8txPpvX5KZJLaKCLHuPOB30fvtwEfAbvcPZ7IEPYadvfKC4gMnf8fkSzKIhLq3wN/cXcDfhPdf35039cA9xA5rWyomc2L1qF+pbTEQVQZPfXPgVZmdgSRhryQyDDCnt4CLiMym/B8ItPy9b/mMFE8Eer999+nadOmfPfdd6SlpVGrVi1mzJjB+PGRizENHjyYP/7xj0Ckp7Z582bq169PcnIy1atXJy0tjeXLl3P22Wdz0003kZubS1paGq1ateLEE0/k+eefx8xYty4yuWn06NG88cYb5ObmEh8fz3HHHVfyU5sjR47k9NNPZ/Xq1fz617+mf//+7Pkn07lzZxo0aPCD93L99dczY8YMOnToQG5uLunp6QwaNIhzzjmHc8455xC0ZlRK48iQe3nrf6Li4e7iSWspKSn06tVrr9cvrwy9evUqmYxXrOwXidy8taWev+OOetFHRsaOR1n/6EgK1q6lWbPmLB05kpSzzgIiV4gb9cUosnZk0ekPnVjxyAre/OubfPrppzRq1Ii/3HMvN992LRs3FnDrLWsp7kXXrxdi1ep8goVhwv8Ik5SUxJzvl/HoBx+zJWcneQWFbN2Zx/a8POavWUdC9W/5vscRFBUWsO71v3D6pk3kFUJS26SSg6Fx9Y5kx/z3yavWhQ1f/5d69YL071udZ17cTGLNmmzfsgMKCyhngLGE/eizh63inmzxceREImEaLFMmm8jwcT6Rs5m2sjswE6Plq0XXrSNyZbcXgTOjZdYRGbKuQeRc7G+J9I67E7n6GkRCNpHIjPQwkfPBuxEJ4xFEhq3Tovt6wN1HEQn50m/IPYdI57I8Tcpb6e7Tgel7ec0pe1l/WKpwT93dC4gcL3iPyAn2r7n7QjO728zOjhZ7BqgdPc5wI3BrRfcrlaPsRKjiGdXFE6H2tGPHDvLy8mjVqhVvv/02S5cu5b777mPx4sUkJCQQCoUoLCykRo0arFmzhgEDBkROsQiFSE5OZsiQIbg7BQUFFBYWMmXKFGbMmIGZ0bFjR04++WReeeUVLr/8cvLy8li6dCndunVj/vz5Jdfb7tGjB++88w4JCQkl9QqFQiWX73zppZc47bTTWLVqFccccwwtWrSgb9++zJo1i06dOh2663b3ugvCiaXXhRMj6ysgPT2dYcOGMXz4cIYNG3bQAv3N2Wvo/sBU+v+/VawllWA4jmnTprFu3TrOOuusUvv9cmEid9ye9YNtJMQ34MWVKzn925UcvXgRqa+9WhLomzZt4uk/PE3W3VkkPJ7AnS3uZO2Ktfzud79j4cKFBAIB/vSnP1GrViL/eLIxY19owpFHxhEIwMhRDXnowfY0btyY2bNnc9ZZZ2GBMDf1OYX2jesTDBhJ8WE6NGlIMBBHvbRanHvuucTFxTFo0CC25+Rg8UnsXDEbgEBcInG1m9Dg14+x9bsVxAWM6ruKmDM1hyKH/GqNaHjlPyAQBNv9kVmvGlTfY4qUWwCLr1Zue6amVuyjdn/njVSrVrL/4nOui4iEavE0/1VEJmmtIjLj+gUiPeP+7p4UfW4JMMLdLXoLuHuau8e7e3V3jyMyzLwWaO/uNaPrA+4edPeG7p7g7le5ewN3b+LuGe5el8is73fdvZm7n+bu1aKvM3ev4+7J7t7e3du4+wB3b+TuxT3586LlE9z9zxVq0BhWKb/S5u6T3b21u7dw9/ui6+5y97eij3Oj/0At3b2zu39TGfuVitvXjOojjzmOCy66gNV3taBBWirbt2+nRriQM888k8cee4zrrruO6tWrc+KJJ7J+/XoyMzP55z//ScOGDdmwYQMTJkwo2Vfx0P22bdtwd1JTU0t+bnPOnDkcd9xxfPHFF5xyyink5+fz7bffMmvWLDp06MDYsWNJTExkzJgxvP3223zwwQcl261Xrx7r169n48aN5OXlMXv2bPr168f8+fOpXbs2v/vd72jYsCGbN28ume190KVfAGeNhpQmgEXuzxr9k4+nH0pvzl7DbePns2bzzsiJu52HsOK46xg28v/xj3/84wdfJBo2GohZ6Y+SQCCRI1vcRPfu3ZkyZQrNmjUr9fz999/P0fVa8d7FT/Ngh6HcefXNNG/YlDU11nDa66fx6bpPyU3NZfFXOdxz9wZuvmkt33yzi9TUIKFQEq1aD2HlypW0b9+eMWPGUFBQSCipNxCmVlISnY9syVdZm8gvyKdPnz6kpqZSUFDAxIkTOfbYY/FdOynKjVxFtFr7U9n4/uN8//YIUk4YQG4omaWbg8zaHMDiA+zKWsbGSY8QrFaTUFpTGv3mGQiGWLfDSEyMHA6pXTtIjdR4KMiD0O55Wl0aGs1rGg1DTvMUw4DUuDjqxO8uk9w+OdpoYEEjGP21uS5duhAMBklJSWHs2LG0bt0aiMyF+N3vfkft2rXZsGEDzZo1o2HDhtSuXZvf/77kN0viiUzkeppIj/hBIkG/hMipWaOJ9KwBLnH3iQDRUG3r7jf/2N+Iu5/r7unu/v2PlSvndcPdfcS+S8pPpZ9e/YXb24zqv/3tb5x/+W/o0KEV2bMmccY/V9CmToDOjYwly1bwzqS3ef7551m5ciUAw4cPZ9u2bVx00UWMGTOGyZMn88EHH/Dll7svV1CzZk0g0psOBoMUFBRwxhlnlAyrDxo0iK1btzJu3DhCoRA7d+5k9OjRLF26lBtvvJHc3Fx+9atflfyaVrFwOMxdd91Fly5dOPPMM2ndujVfffUVF110EQ8//DCpqak888wzDBs2rKQOh0T6BTBsAQzfHLnfS6CfccYZfPdd2Wkole+FF14gPT2dDh06MHjwYFauXFkyfN+rVy++/fZbtmzZwoWndCInP/JFr2hXLqufuJyc3DyuvnJIyW+Ev/vuu7Rp04YePXrw4fT1JCe3ISG+IWAkxDekTZv7aFC/P8ceeyzNmzf/QV3m/3cOGTubU7g5j5a1m/HdpnV4TgGZk99i7Y61YJFRI08w/j7+FsaO7UzXrtX4/e9b0abNfdz9lzcIhULMnz+f+++/HwdC8W0JxrUhGK5Dny4Pk35ETxqlHcGvfvUr3J1AIMCTTz7JvHnz6PZ/fQiEI6fIVTuqO42u+icNfz2a6h1Po3rzDtSsU5dQNaPOmXVo9sensGCI+oNHEJfWjPXj7yWUUp/GJ17Ki9cMo2nTOLp2TaJ2SiHdu8Xx5JN1iEsOEAgGiIuP4+RmIeonBTmnfnXaNomnfkujeuTMQ0LhIIUbi4hrEEcgFCBIAPfI6FNGRgbx8fG0bNmSK664guXLlxMOh8nIyPhBex5//PEEg8HiQyV5ROY1nURkMlhLYDCR65fPBX5LZMT0Z/N76+5+8h49dvkR+pW2X7gfm1H9el4H/pxzFY0vKz2MvDGniH8uTOLx2bNp164dHTp04KWXXqJt27ZccsklJRc0mTJlCq1bty51fnlSUhKvvfYahYWFTJo0iWbNmpGYmEhOTg4Ab7zxBldeeSW33XYbK1euZP369Zx22mls2LCBhg0bcs899zBgwAAApk+fXrLdoUOHMnToUB555BEee+wxevbsyW9/+9tSIwWHk7VZE/hm2Qhy89Zyxx0NsMDn/PDyDpWneBLkJ598QlpaGtnZ2Vx22WVceumlXHbZZTz77LMMHTqUN998k0Bac/K+XUBCs3R2Lv0foRp12LHoQ3LzI+d85ebmctVVVzF16lRatmzJwIEDiY+vR/fub+93fVqHGjH5yw85vkF7Zn/3JVnbvqdJzfoMyjqdD6p/Sly9OHZ8vYP4uvHcOvYNpt0xjfr1h7F1az3O+9XfmD17Nvn5+Xz//ff8+9//JhgyQnGl+yiJCdVIKIp8xG3dupVgMEhycjLr1q3jqy8+pVpckNRk2LTdCQW3cVxwNQvgDjcAABaySURBVG0D29l5cVf+1/gcltdOoPqmZ8nPfpddm74jkFCdOmdHOrDxwC0kUH3DRuLyU7n22nqE47azqdB4a1sq9f/fbeQldycnPsxz0R+veW3UQ/Q58jVCSdkU5NSi4Mtf0S67O6E9LtlRFMgjeNouGp0c+bnZxx57rNz2u+SSS0o99/TTT5dc3MjMFrh7cfKXvbjDjdGbxCj11H/hfmxG9Xebd9LQfji6VjspwO3H57FmzRoyMzO55ZZbCAaDuDs33ngjCQkJJCYmcv755/P888+Xeq2Zce6555KXl8dHH31Eo0aNyMvLo2PHjhxzzDH8+c9/ZteuXVx99dUABAIB7r///pLZ+PuawZ6ens6cOXMYO3YsJ554YsUa5yBZmzWBxYvvIDfvO8DJzfuOxYvvYG1WJX8B2ePiN1P/dCrnn3hMyQd/8STIiy+OdNYGDx7Mxx9/DEDjTr3YsfgjAHYs+oiU7heT3K4XSXGR47qLFy/miCOOoFWrVpgZl1xyyQFX7bcdL2RL7jb6PDeE578YT+u05oBRp6AWAOGUMNVaV6Mwp5AFTyygZcuWTJgwgfnz5/PSSy8xbtw43J2MjAxSU1OxgPF/g9oQio/UMblWPFf/7nLWZH3LVVddRXJyMsnJyVxwwQUMGTKEzp07ExcKMPvOfjx+tXHksc+xuMWLzGg3g5MuPontrfuSl9ydbalDKNj5FdWPSyOYlAs49TBuIYHToqdDBwuTSEx8g6tC47k+/Dof1HqKvOTuJAaM247cPZmz4wmDWfnBQ3z1r6dYNulvrFzehXl5heSHd+A4BYmbSgW6yE+hn16VUpcB3XNGdfcHpvJqzlU0DpRz2CylSWRIWQ7YJ5/0jAZ6aQnxDenevdzTXA9cmYvfjP4sj/U7Q9w7+tmSwwBpaWmsXbuWcDjMrl27SuZBvPLJ11x6Rk/qXz6Ktc8NpdFvniYpPo4Gc5/l2ksvoGXLltxwww18+OGHALz11lslcx369OnDunXryMjI4Omnny6pTvPmzZk5c2bJl4q1D/yPws2RUxTdnW5PDuT9Ic+RUy2Xy1v9qdRbaVCtAe+f//4P3uKwYcNo1KgRN910U+W02R7+nZXNTV+tYucel41NDBgjjmpC37UFbH1vBYWb8wjWjKdGn+ZUO7Yu/87K5q/frGVN3i4axYe57cgGnFe/Vqntfv1ZFjMmLGN7dh7JteLp2r8FrbtU7llSZjZrj566/MJo+F1IT08vdxb1zX2OYuQbF3K3jyHJ8kvWFwQTCFVwFvcvWdlTwG6/bS03/qEOaWlr9/KKn6DMxW96HRHi3Fd3Muytu6idfgHZ2dl069aNcePGMXjwYF5++WV69OgBwEXdW/P3zsez9KNnSGp5PI1rJXNzn6N4c1XkvPI2bdqwfPlyli1bRosWLXjllVdK9vPee+/tV/WKuqWy6901hIuCvDL3bbo06UC1akk8Vf+NUuUSggmlzl3fcz/vvvsuM2bMOOCm2R/FYVxuSNeHasfWLfc1ZUO8rNZd6ld6iIvsSaEue3XOsY2Aa3lwUogr81+iYWAjuYn1STr9p18VTSKneu3ZU7//rw1K1leaMhe5OaZukDt6xnHS6CUE/9WBY489ltGjRzNkyBAeeuihkqsFFrvxmssZMGAA06dP56STTgLgzeL6JyQwZswY+vXrR1paGj169GDBgvJHbUaPHs2DDz5IVlYW6enpnHHGGTz99NN8G/6ewS8NgdwiWqU25ZEL76L2OW3olXI2C75YTtaOLOpXq18S6Ke9flrJuus7Xs9vr/gt06ZNO6gTH/cnpEUONxp+FznEio+pFxXt7kkHAoklM8YrxaPt9nLxm5/XYZNJ30xi+KfDyS3MLVkX2BJg82ObWfn1yiqs2eFLw++/bJooJ3KINajfnzZt7iv3FLBKc5AufnOojfpiVKlAByhIKKD2gNpVVCORw5uG30WqQIP6/Ss3xMsqPjySeXdkKD6lcSTQf2aHTbJ2/PBKdYU5hSx7fxncVwUVEjnMKdRFYlX6BT+7EC+rfrX6kYvR7CGcGqbLLWV/3VlEQMPvInIYu+G4G0gIJpRat7cZ8SKinrqIHMb6HdkPoOTX3IpnxBevF5HSFOoicljrd2Q/hbjIftLwu4iISIxQqIuIiMQIhbqIiEiMUKiLiIjECIW6iIhIjFCoi4iIxAiFuoiISIxQqIuIiMQIhbqIiEiMUKiLiFSRu+66iylTpvxg/fTp0znzzDMBWLx4MV27diU+Pp4RI0aUKjdq1CjatWvHMcccw8iRIw9JneXwpsvEiohUkbvvvnufZWrVqsXo0aN58803S61fsGABTz31FP/73/+Ii4ujb9++9Ouny+n+0qmnLiLyE73wwgukp6fToUMHBg8ezMqVK+nVqxfp6en06tWLb7/9li1bttC8eXOKiooAyMnJoUmTJuzatYvLL7+c119/HYB3332XNm3a0KNHD8aPH1+yj7p163L88ccTDodL7XvRokWccMIJJCUlEQqFOOmkk3jjjTcO3ZuXw5JCXUTkJ1i4cCH33XcfU6dOZe7cuYwaNYrrrruOSy+9lHnz5jFo0CCGDh1KSkoKHTp04MMPPwRg4sSJ9OnTp1RI5+bmctVVVzFx4kT+85//kJWVtc/9t2vXjo8++oiNGzeSk5PD5MmTWbVq1UF7v/LzoFAXETkAX3+WxdjbP2H4NU/SOq0L2csKgMgw+YwZM7j44osBGDx4MB9//DEAAwcO5NVXXwVg3LhxDBw4sNQ2Fy9ezBFHHEGrVq0wMy655JJ91qNt27bccsst9O7dm759+9KhQwdCIR1R/aVTqIuI7KevP8ti2suL2Z6dB+7s2lnEtJcX8/Vn5feszQyAs88+m3feeYfs7GxmzZrFKaecsteyB+KKK67giy++4KOPPqJWrVq0atXqgLchsaVCoW5mtczsAzNbEr1PLadMRzObYWYLzWyemQ0sb1siIoe7GROWUZAfOTZ+VKPj+OKb6WzeuokZE5aRnZ1Nt27dGDduHAAvv/wyPXr0ACA5OZnOnTtzww03cOaZZxIMBkttt02bNixfvpxly5YB8Morr+xXfdavXw/At99+y/jx47nooosq5X3Kz1dFx2puBTLd/QEzuzW6fEuZMjnApe6+xMwaArPM7D1331zBfYuIHFLbs/NKHjeo1Zw+xw5i1Fs3ErAA077ryejRoxkyZAgPPfQQderU4bnnnispP3DgQAYMGMD06dN/sN2EhATGjBlDv379SEtLo0ePHixYsACArKwsMjIy2Lp1K4FAgJEjR/Lll19So0YNzjvvPDZu3Eg4HObxxx8nNfUH/Sr5hTF3/+kvNvsKONnd15pZA2C6ux+1j9fMBc539yU/Vi4jI8Nnzpz5k+smIlLZxt7+SalgL5ZcK57L7u9eBTX6ITOb5e4ZVV0PqRoVPaZez93XAkTv6/5YYTPrDMQBy/by/NVmNtPMZm7YsKGCVRMRqVxd+7cgFFf6YzMUF6Br/xZVVCOR0vY5/G5mU4D65Tx1x4HsKNqTfxG4zN2Lyivj7mOAMRDpqR/I9kVEDrbWXSIfhTMmLGN7dh7JteLp2r9FyXqRqrbPUHf3U/f2nJmtM7MGewy/r99LuRrAJOBOd//vT66tiEgVa92lvkJcDlsVHX5/C7gs+vgyYELZAmYWB7wBvODu/6rg/kRERGQvKhrqDwC9zWwJ0Du6jJllmNnT0TIXACcCl5vZnOitYwX3KyIiImVUaPb7waTZ7yIiB06z33/ZdEU5ERGRGKFQFxERiREKdRERkRihUBcREYkRCnUREZEYoVAXERGJEQp1ERGRGKFQFxERiREKdRERkRihUBcREYkRCnUREZEYoVAXERGJEQp1ERGRGKFQFxERiREKdRERkRihUBcREYkRCnUREZEYoVAXERGJEQp1ERGRGKFQFxERiREKdRERkRihUBcREYkRCnUREZEYoVAXERGJEQp1ERGRGKFQFxERiREKdRERkRihUBcREYkRFQp1M6tlZh+Y2ZLofeqPlK1hZmvM7LGK7FNERETKV9Ge+q1Apru3AjKjy3tzD/BhBfcnIiIie1HRUO8PjI0+HgucU14hM+sE1APer+D+REREZC8qGur13H0tQPS+btkCZhYAHgZuruC+RERE5EeE9lXAzKYA9ct56o793Me1wGR3X2Vm+9rX1cDVAE2bNt3PzYuIiAjsR6i7+6l7e87M1plZA3dfa2YNgPXlFOsK9DSza4FkIM7Mtrv7D46/u/sYYAxARkaG7++bEBERkf0I9X14C7gMeCB6P6FsAXcfVPzYzC4HMsoLdBEREamYih5TfwDobWZLgN7RZcwsw8yermjlREREZP+Z++E5yp2RkeEzZ86s6mqIiPysmNksd8+o6npI1dAV5URERGKEQl1ERCRGKNRFRERihEJdREQkRijURUREYoRCXUREJEYo1EVERGKEQl1ERCRGKNRFRERihEJdREQkRijURUREYoRCXUREJEYo1EVERGKEQl1ERCRGKNRFRERihEJdREQkRijURUREYoRCXUREJEYo1EVERGKEQl1ERCRGKNRFRERihEJdREQkRijURUREYoRCXUREJEYo1EVERGKEQl1ERCRGKNRFRERihEJdREQkRijURUREYkSFQt3MapnZB2a2JHqfupdyTc3sfTNbZGZfmlnziuxXREREfqiiPfVbgUx3bwVkRpfL8wLwkLu3BToD6yu4XxERESmjoqHeHxgbfTwWOKdsATM7Ggi5+wcA7r7d3XMquF8REREpo6KhXs/d1wJE7+uWU6Y1sNnMxpvZbDN7yMyC5W3MzK42s5lmNnPDhg0VrJqIiMgvS2hfBcxsClC/nKfuOIB99ASOBb4FXgUuB54pW9DdxwBjADIyMnw/ty8iIiLsR6i7+6l7e87M1plZA3dfa2YNKP9Y+Wpgtrt/E33Nm8AJlBPqIiIi8tNVdPj9LeCy6OPLgAnllPkcSDWzOtHlU4AvK7hfERERKaOiof4A0NvMlgC9o8uYWYaZPQ3g7oXATUCmmc0HDHiqgvsVERGRMvY5/P5j3H0j0Kuc9TOBK/dY/gBIr8i+RERE5MfpinIiIiIxQqEuIiISIxTqIiIiMUKhLiIiEiMU6iIiIjFCoS4iIhIjFOoiIiIxQqEuIiISIxTqIiIiMUKhLiIiEiMU6iIiIjFCoS4iIhIjFOoiIiIxQqEuIiISIxTqIiIiMUKhLiIiEiMU6iIiIjFCoS4iIhIjFOoiIiIxQqEuIiISIxTqIiIiMUKhLiIiEiMU6iIiIjFCoS4iIhIjFOoiIiIxQqEuIiISIxTqIiIiMUKhLiIiEiMqFOpmVsvMPjCzJdH71L2Ue9DMFprZIjMbbWZWkf2KiIjID1W0p34rkOnurYDM6HIpZtYN6A6kA+2A44GTKrhfERERKaOiod4fGBt9PBY4p5wyDiQAcUA8EAbWVXC/IiIiUkZFQ72eu68FiN7XLVvA3WcA04C10dt77r6ovI2Z2dVmNtPMZm7YsKGCVRMREfllCe2rgJlNAeqX89Qd+7MDM2sJtAUaR1d9YGYnuvtHZcu6+xhgDEBGRobvz/ZFREQkYp+h7u6n7u05M1tnZg3cfa2ZNQDWl1PsXOC/7r49+pp3gBOAH4S6iIiI/HQVHX5/C7gs+vgyYEI5Zb4FTjKzkJmFiUySK3f4XURERH66iob6A0BvM1sC9I4uY2YZZvZ0tMzrwDJgPjAXmOvuEyu4XxERESljn8PvP8bdNwK9ylk/E7gy+rgQuKYi+xEREZF90xXlREREYoRCXUREJEYo1EVERGKEQl1ERCRGKNRFRERihEJdREQkRijURUREYoRCXUREJEYo1EVERGKEQl1ERCRGKNRFRERiRIWu/S4iIvvvtttuo0+fPmzevJnFixdz6623VnWVJMaopy4icoh89tlndOnShQ8//JCePXtWdXUkBqmnLiJykN1888289957LF++nK5du7Js2TIyMzM5//zzueuuu6q6ehJDzN2rug7lysjI8JkzZ1Z1NUREKsX//vc/XnzxRR555BFOPvlkPvnkk4OyHzOb5e4ZB2XjcthTT11EpLLNew0y74YtqyGlMfS6i9mzN9GxY0cWL17M0UcfXdU1lBilUBcRqUzzXoOJQ2HXTgDmfLWCyx8cxOrcRNLqNSQnJwd3p2PHjsyYMYPExMQqrrDEEk2UExGpTJl3lwQ6QMf6QeZck0TrmgV8+eWXnHLKKbz33nvMmTNHgS6VTqEuIlKZtqz+waoNO4pIDe8iEAho+F0OKoW6iEhlSmn8g1V1qgWY9NujAPjvf/97qGskvyAKdRGRytTrLgiXGVYPJ0bWixxkCnURkcqUfgGcNRpSmgAWuT9rdGS9yEGm2e8iIpUt/QKFuFQJ9dRFRERihEJdREQkRijURUREYoRCXUREJEYo1EVERGLEYfsrbWa2AVhZ1fXYhzTg+6quxGFE7bGb2mI3tcVuh6Itmrl7nYO8DzlMHbah/nNgZjP1E4e7qT12U1vsprbYTW0hB5uG30VERGKEQl1ERCRGKNQrZkxVV+Awo/bYTW2xm9piN7WFHFQ6pi4iIhIj1FMXERGJEQp1ERGRGKFQPwBmVsvMPjCzJdH71B8pW8PM1pjZY4eyjofS/rSHmTUzs1lmNsfMFprZb6qirgfbfrZFRzObEW2HeWY2sCrqerDt7/8TM3vXzDab2duHuo4Hm5n1NbOvzGypmd1azvPxZvZq9PnPzKz5oa+lxCKF+oG5Fch091ZAZnR5b+4BPjwktao6+9Mea4Fu7t4R6ALcamYND2EdD5X9aYsc4FJ3PwboC4w0s5qHsI6Hyv7+P3kIGHzIanWImFkQeBw4HTgauMjMji5T7Apgk7u3BB4F/nZoaymxSqF+YPoDY6OPxwLnlFfIzDoB9YD3D1G9qso+28Pd8909L7oYT+z+ze1PW3zt7kuij78D1gOxeOWv/fp/4u6ZwLZDValDqDOw1N2/cfd8YByRNtnTnm30OtDLzOwQ1lFiVKx+wB4s9dx9LUD0vm7ZAmYWAB4Gbj7EdasK+2wPADNrYmbzgFXA36KBFmv2qy2KmVlnIA5YdgjqdqgdUFvEoEZE/taLrY6uK7eMuxcAW4Dah6R2EtNCVV2Bw42ZTQHql/PUHfu5iWuBye6+Kha+eFdCe+Duq4D06LD7m2b2uruvq6w6HiqV0RbR7TQAXgQuc/eiyqjboVZZbRGjyvuPX/bc4f0pI3LAFOpluPupe3vOzNaZWQN3Xxv9YF5fTrGuQE8zuxZIBuLMbLu7/9jx98NWJbTHntv6zswWAj2JDDn+rFRGW5hZDWAScKe7//cgVfWgq8y/ixi0Gmiyx3JjoOzoVHGZ1WYWAlKA7ENTPYllGn4/MG8Bl0UfXwZMKFvA3Qe5e1N3bw7cBLzwcw30/bDP9jCzxmaWGH2cCnQHvjpkNTx09qct4oA3iPxN/OsQ1u1Q22dbxLjPgVZmdkT03/xCIm2ypz3b6HxgqutKYFIJFOoH5gGgt5ktAXpHlzGzDDN7ukprVjX2pz3aAp+Z2VwiZwOMcPf5VVLbg2t/2uIC4ETg8ugpfnPMrGPVVPeg2q//J2b2H+BfRCaJrTazPlVS20oWPUZ+HfAesAh4zd0XmtndZnZ2tNgzQG0zWwrcyI+fSSOy33SZWBERkRihnrqIiEiMUKiLiIjECIW6iIhIjFCoi4iIxAiFuoiISIxQqIuIiMQIhbqIiEiM+P8sfTdUJS8CyQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = [key for key in cm.vocabulary.keys()]\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    \n",
    "    #if re.match('^co[rv]', word):\n",
    "    \n",
    "        x = df['Comp 1'][i]\n",
    "        y = df['Comp 2'][i]\n",
    "\n",
    "        plt.scatter(x, y)\n",
    "        plt.text(x, y, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set word embeddings for text classification\n",
    "ica = FastICA(n_components = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.33524698e-04, -4.17835202e-04, -5.09492480e-04, ...,\n",
       "        -9.91474670e-04, -1.46379377e-03, -1.53105772e-03],\n",
       "       [-9.38286950e-05,  1.22172476e-03, -3.15525128e-04, ...,\n",
       "         3.90453098e-05, -2.21300630e-03,  3.01903137e-03],\n",
       "       [ 4.63546795e-03, -2.46155607e-03,  4.31392668e-03, ...,\n",
       "        -3.65094594e-03,  3.58118656e-03, -2.51265833e-04],\n",
       "       ...,\n",
       "       [-3.07922023e-03,  8.46195076e-03,  1.76973005e-03, ...,\n",
       "        -8.82802564e-04, -1.19697933e-02,  8.66202708e-03],\n",
       "       [ 5.95683668e-03, -1.40974066e-02, -3.34381692e-04, ...,\n",
       "         1.04900551e-03,  9.31252654e-03, -1.24390303e-02],\n",
       "       [-4.47150497e-03, -4.54460251e-03, -1.23200213e-02, ...,\n",
       "        -8.15236677e-03, -4.93547222e-03, -1.83287074e-03]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = ica.fit_transform(X_std)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out target\n",
    "y = tweets['Is_Unreliable']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derive text vectors from word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_vectors(word_embeddings,\n",
    "                     word_index_dict,\n",
    "                     text_list,\n",
    "                     remove_stopwords = True,\n",
    "                     lowercase = True,\n",
    "                     lemmatize = True,\n",
    "                     add_start_end_tokens = True):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    for k in range(len(text_list)):\n",
    "        text = text_list[k]\n",
    "        text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "        text_vec = np.zeros(word_embeddings.shape[1])\n",
    "        words = word_tokenize(text)\n",
    "        tracker = 0 # to track whether we've encountered a word for which we have an embedding (in each tweet)\n",
    "        \n",
    "        if remove_stopwords:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                if word.lower() not in set(stopwords.words('english')):\n",
    "                    clean_words.append(word)\n",
    "            words = clean_words\n",
    "\n",
    "        if lowercase:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                clean_words.append(word.lower())\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if lemmatize:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                PoS_tag = pos_tag([word])[0][1]\n",
    "\n",
    "                # to change contractions to full word form\n",
    "                if word in contractions:\n",
    "                    word = contractions[word]\n",
    "\n",
    "                if PoS_tag[0].upper() in 'JNVR':\n",
    "                    word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                else:\n",
    "                    word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                clean_words.append(word)\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if add_start_end_tokens:\n",
    "            words = ['<START>'] + words + ['<END>']\n",
    "        \n",
    "        for i in range(len(words)):\n",
    "            word = words[i]\n",
    "            if word in word_index_dict:\n",
    "                word_embed_vec = word_embeddings[word_index_dict[word],:]\n",
    "                if tracker == 0:\n",
    "                    text_matrix = word_embed_vec\n",
    "                else:\n",
    "                    text_matrix = np.vstack((text_matrix, word_embed_vec))\n",
    "                    \n",
    "                # only increment if we have come across a word in the embeddings dictionary\n",
    "                tracker += 1\n",
    "                    \n",
    "        for j in range(len(text_vec)):\n",
    "            text_vec[j] = text_matrix[:,j].mean()\n",
    "            \n",
    "        if k == 0:\n",
    "            full_matrix = text_vec\n",
    "        else:\n",
    "            full_matrix = np.vstack((full_matrix, text_vec))\n",
    "            \n",
    "    return full_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_text_vectors(embeddings, cm.vocabulary, tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 500)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.74483229e-04,  1.59245950e-03,  4.03064553e-04, ...,\n",
       "        -7.02985195e-04,  9.73085677e-04, -9.21984284e-07],\n",
       "       [-4.22710704e-04,  3.28182390e-03, -2.69513808e-04, ...,\n",
       "         6.09529421e-04, -3.94066151e-03, -1.81785166e-03],\n",
       "       [ 1.58291567e-03,  3.65140738e-04,  5.19516407e-04, ...,\n",
       "         3.71624119e-04, -5.84852316e-04, -1.36507607e-03],\n",
       "       ...,\n",
       "       [-1.27312338e-03,  3.15311086e-03,  9.49098647e-04, ...,\n",
       "        -9.46022586e-05, -3.67210088e-04, -7.82953717e-04],\n",
       "       [ 3.10901527e-04, -7.70030667e-04,  3.43656404e-04, ...,\n",
       "        -4.30984857e-04, -5.45103533e-04, -6.61427248e-05],\n",
       "       [ 4.21906951e-04,  1.36934859e-04, -5.63595811e-04, ...,\n",
       "         2.08698857e-04, -6.34002845e-04, -1.09132275e-03]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, KFold, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipe = Pipeline([\n",
    "    ('classify', SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC hyperparams to optimize\n",
    "kernel = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "C = [0.001, 0.01, 0.1, 1, 10]\n",
    "# set up parameter grid\n",
    "params = {\n",
    "    'classify__kernel': kernel,\n",
    "    'classify__C': C\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CV scheme for inner and outer loops\n",
    "inner_cv = KFold(n_splits = 3, shuffle = True, random_state = 1)\n",
    "outer_cv = KFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "\n",
    "# Set up GridSearch for inner loop\n",
    "grid_SVC = GridSearchCV(pipe, params, cv = inner_cv)\n",
    "#grid_SVC.fit(X, y)\n",
    "\n",
    "# Nested CV scores\n",
    "scores = cross_validate(grid_SVC,\n",
    "                        X = X,\n",
    "                        y = y,\n",
    "                        cv = outer_cv,\n",
    "                        scoring = ['roc_auc', 'accuracy', 'f1', 'precision', 'recall'],\n",
    "                        return_estimator = True)\n",
    "auc = scores['test_roc_auc']\n",
    "accuracy = scores['test_accuracy']\n",
    "f1 = scores['test_f1']\n",
    "precision = scores['test_precision']\n",
    "recall = scores['test_recall']\n",
    "estimators = scores['estimator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9269809907379946"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8732142857142857"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8800614429596127"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333974358974359"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9338905526528185"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classify__C': 10, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 10, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 10, 'classify__kernel': 'linear'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in estimators:\n",
    "    print(i.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
