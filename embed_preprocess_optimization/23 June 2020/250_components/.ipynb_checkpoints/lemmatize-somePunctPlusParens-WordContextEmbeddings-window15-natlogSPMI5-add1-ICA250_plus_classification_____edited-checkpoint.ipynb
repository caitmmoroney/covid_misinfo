{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Word Context Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.decomposition import FastICA, TruncatedSVD, PCA, NMF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert contractions picked up by word_tokenize() into full words\n",
    "contractions = {\n",
    "    \"n't\": 'not',\n",
    "    \"'ve\": 'have',\n",
    "    \"'s\": 'is', # note that this will include possessive nouns\n",
    "    'gonna': 'going to',\n",
    "    'gotta': 'got to',\n",
    "    \"'d\": 'would',\n",
    "    \"'ll\": 'will',\n",
    "    \"'re\": 'are',\n",
    "    \"'m\": 'am',\n",
    "    'wanna': 'want to'\n",
    "}\n",
    "\n",
    "# to convert nltk_pos tags to wordnet-compatible PoS tags\n",
    "def convert_pos_wordnet(tag):\n",
    "    tag_abbr = tag[0].upper()\n",
    "    tag_dict = {\n",
    "        'J': wordnet.ADJ,\n",
    "        'N': wordnet.NOUN,\n",
    "        'V': wordnet.VERB,\n",
    "        'R': wordnet.ADV\n",
    "    }\n",
    "                \n",
    "    if tag_abbr in tag_dict:\n",
    "        return tag_dict[tag_abbr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextMatrix(TransformerMixin):\n",
    "    \n",
    "    # initialize class & private variables\n",
    "    def __init__(self,\n",
    "                 window_size = 4,\n",
    "                 remove_stopwords = True,\n",
    "                 add_start_end_tokens = True,\n",
    "                 lowercase = False,\n",
    "                 lemmatize = False,\n",
    "                 pmi = False,\n",
    "                 spmi_k = 1,\n",
    "                 laplace_smoothing = 0,\n",
    "                 pmi_positive = False,\n",
    "                 sppmi_k = 1):\n",
    "        \n",
    "        \"\"\" Params:\n",
    "                window_size: size of +/- context window (default = 4)\n",
    "                remove_stopwords: boolean, whether or not to remove NLTK English stopwords\n",
    "                add_start_end_tokens: boolean, whether or not to append <START> and <END> to the\n",
    "                beginning/end of each document in the corpus (default = True)\n",
    "                lowercase: boolean, whether or not to convert words to all lowercase\n",
    "                lemmatize: boolean, whether or not to lemmatize input text\n",
    "                pmi: boolean, whether or not to compute pointwise mutual information\n",
    "                pmi_positive: boolean, whether or not to compute positive PMI\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.add_start_end_tokens = add_start_end_tokens\n",
    "        self.lowercase = lowercase\n",
    "        self.lemmatize = lemmatize\n",
    "        self.pmi = pmi\n",
    "        self.spmi_k = spmi_k\n",
    "        self.laplace_smoothing = laplace_smoothing\n",
    "        self.pmi_positive = pmi_positive\n",
    "        self.sppmi_k = sppmi_k\n",
    "        self.corpus = None\n",
    "        self.clean_corpus = None\n",
    "        self.vocabulary = None\n",
    "        self.X = None\n",
    "        self.doc_terms_lists = None\n",
    "    \n",
    "    def fit(self, corpus, y = None):\n",
    "        \n",
    "        \"\"\" Learn the dictionary of all unique tokens for given corpus.\n",
    "        \n",
    "            Params:\n",
    "                corpus: list of strings\n",
    "            \n",
    "            Returns: self\n",
    "        \"\"\"\n",
    "        self.corpus = corpus\n",
    "        \n",
    "        term_dict = dict()\n",
    "        k = 0\n",
    "        corpus_words = []\n",
    "        clean_corpus = []\n",
    "        doc_terms_lists = []\n",
    "        detokenizer = TreebankWordDetokenizer()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        for text in corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "            \n",
    "            # detokenize trick taken from this StackOverflow post:\n",
    "            # https://stackoverflow.com/questions/21948019/python-untokenize-a-sentence\n",
    "            # and NLTK treebank documentation:\n",
    "            # https://www.nltk.org/_modules/nltk/tokenize/treebank.html\n",
    "            text = detokenizer.detokenize(words)\n",
    "            clean_corpus.append(text)\n",
    "            \n",
    "            [corpus_words.append(word) for word in words]\n",
    "            \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            doc_terms_lists.append(words)\n",
    "            \n",
    "        self.clean_corpus = clean_corpus\n",
    "        \n",
    "        self.doc_terms_lists = doc_terms_lists\n",
    "        \n",
    "        corpus_words = list(set(corpus_words))\n",
    "        \n",
    "        if self.add_start_end_tokens:\n",
    "            corpus_words = ['<START>'] + corpus_words + ['<END>']\n",
    "        \n",
    "        corpus_words = sorted(corpus_words)\n",
    "        \n",
    "        for el in corpus_words:\n",
    "            term_dict[el] = k\n",
    "            k += 1\n",
    "            \n",
    "        self.vocabulary = term_dict\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def transform(self, new_corpus = None, y = None):\n",
    "        \n",
    "        \"\"\" Compute the co-occurrence matrix for given corpus and window_size, using term dictionary\n",
    "            obtained with fit method.\n",
    "        \n",
    "            Returns: term-context co-occurrence matrix (shape: target terms by context terms) with\n",
    "            raw counts\n",
    "        \"\"\"\n",
    "        num_terms = len(self.vocabulary)\n",
    "        window = self.window_size\n",
    "        X = np.full((num_terms, num_terms), self.laplace_smoothing)\n",
    "        \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        if type(new_corpus) != list:\n",
    "            new_corpus = self.corpus\n",
    "        \n",
    "        for text in new_corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            for i in range(len(words)):\n",
    "                target = words[i]\n",
    "                \n",
    "                # check to see if target word is in the dictionary; if not, skip\n",
    "                if target in self.vocabulary:\n",
    "                    \n",
    "                    # grab index from dictionary\n",
    "                    target_dict_index = self.vocabulary[target]\n",
    "                    \n",
    "                    # find left-most and right-most window indices for each target word\n",
    "                    left_end_index = max(i - window, 0)\n",
    "                    right_end_index = min(i + window, len(words) - 1)\n",
    "                    \n",
    "                    # loop over all words within window\n",
    "                    # NOTE: this will include the target word; make sure to skip over it\n",
    "                    for j in range(left_end_index, right_end_index + 1):\n",
    "                        \n",
    "                        # skip \"context word\" where the \"context word\" index is equal to the\n",
    "                        # target word index\n",
    "                        if j != i:\n",
    "                            context_word = words[j]\n",
    "                            \n",
    "                            # check to see if context word is in the fitted dictionary; if\n",
    "                            # not, skip\n",
    "                            if context_word in self.vocabulary:\n",
    "                                X[target_dict_index, self.vocabulary[context_word]] += 1\n",
    "        \n",
    "        # if pmi = True, compute pmi matrix from word-context raw frequencies\n",
    "        # more concise code taken from this StackOverflow post:\n",
    "        # https://stackoverflow.com/questions/58701337/how-to-construct-ppmi-matrix-from-a-text-corpus\n",
    "        if self.pmi:\n",
    "            denom = X.sum()\n",
    "            col_sums = X.sum(axis = 0)\n",
    "            row_sums = X.sum(axis = 1)\n",
    "            \n",
    "            expected = np.outer(row_sums, col_sums)/denom\n",
    "            \n",
    "            X = X/expected\n",
    "            \n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(X.shape[1]):\n",
    "                \n",
    "                    if X[i,j] > 0:\n",
    "                        X[i,j] = np.log(X[i,j]) - np.log(self.spmi_k)\n",
    "                        \n",
    "                        if self.pmi_positive:\n",
    "                            X[i,j] = max(X[i,j] - np.log(self.sppmi_k), 0)\n",
    "        \n",
    "        # note that X is a dense matrix\n",
    "        self.X = X\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(lowercase = True, lemmatize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [\n",
    "    \"Coronavirus is a fake liberal hoax.\",\n",
    "    \"Trump won't do anything about coronavirus.\",\n",
    "    \"The liberal fake news media always blame Pres Trump.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ContextMatrix at 0x1a1a601f90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.fit(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <th>always</th>\n",
       "      <th>anything</th>\n",
       "      <th>blame</th>\n",
       "      <th>coronavirus</th>\n",
       "      <th>fake</th>\n",
       "      <th>hoax</th>\n",
       "      <th>liberal</th>\n",
       "      <th>medium</th>\n",
       "      <th>news</th>\n",
       "      <th>pres</th>\n",
       "      <th>trump</th>\n",
       "      <th>wont</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>always</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anything</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blame</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronavirus</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fake</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoax</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pres</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wont</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             .  <END>  <START>  always  anything  blame  coronavirus  fake  \\\n",
       ".            0      3        0       1         1      1            2     1   \n",
       "<END>        3      0        0       0         1      1            1     1   \n",
       "<START>      0      0        0       0         1      0            2     2   \n",
       "always       1      0        0       0         0      1            0     1   \n",
       "anything     1      1        1       0         0      0            1     0   \n",
       "blame        1      1        0       1         0      0            0     1   \n",
       "coronavirus  2      1        2       0         1      0            0     1   \n",
       "fake         1      1        2       1         0      1            1     0   \n",
       "hoax         1      1        1       0         0      0            1     1   \n",
       "liberal      1      1        2       1         0      0            1     2   \n",
       "medium       0      0        1       1         0      1            0     1   \n",
       "news         0      0        1       1         0      1            0     1   \n",
       "pres         1      1        0       1         0      1            0     0   \n",
       "trump        2      1        1       1         1      1            1     0   \n",
       "wont         1      1        1       0         1      0            1     0   \n",
       "\n",
       "             hoax  liberal  medium  news  pres  trump  wont  \n",
       ".               1        1       0     0     1      2     1  \n",
       "<END>           1        1       0     0     1      1     1  \n",
       "<START>         1        2       1     1     0      1     1  \n",
       "always          0        1       1     1     1      1     0  \n",
       "anything        0        0       0     0     0      1     1  \n",
       "blame           0        0       1     1     1      1     0  \n",
       "coronavirus     1        1       0     0     0      1     1  \n",
       "fake            1        2       1     1     0      0     0  \n",
       "hoax            0        1       0     0     0      0     0  \n",
       "liberal         1        0       1     1     0      0     0  \n",
       "medium          0        1       0     1     1      1     0  \n",
       "news            0        1       1     0     1      0     0  \n",
       "pres            0        0       1     1     0      1     0  \n",
       "trump           0        0       1     0     1      0     1  \n",
       "wont            0        0       0     0     0      1     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cm.transform(tweets), index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coronavirus fake liberal hoax.',\n",
       " 'trump wont anything coronavirus.',\n",
       " 'liberal fake news medium always blame pres trump.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.clean_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coronavirus is a fake liberal hoax.',\n",
       " \"Trump won't do anything about coronavirus.\",\n",
       " 'The liberal fake news media always blame Pres Trump.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train embeddings using tweets as corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('COVID19_Dataset-text_labels_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Unreliable</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 3, 6, 9</td>\n",
       "      <td>We are living in scary times in Canada. Gov’t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 6, 8, 9</td>\n",
       "      <td>Just as bad in Canada. In fact, our government...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 4, 9</td>\n",
       "      <td>It was only a matter of time before the mainst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8</td>\n",
       "      <td>Russia's taking no chances: Foreigners infecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8, 9</td>\n",
       "      <td>Although there is now a presumptive confirmed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BREAKING: Harvard classes will move online sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singularity University is hosting a FREE Virtu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus: how does it spread and what are t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stanford just cancelled classes for the rest o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tech conferences were cancelled in #Waterloo R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Is_Unreliable    Category  \\\n",
       "0                1  1, 3, 6, 9   \n",
       "1                1  1, 6, 8, 9   \n",
       "2                1     1, 4, 9   \n",
       "3                1        6, 8   \n",
       "4                1     6, 8, 9   \n",
       "..             ...         ...   \n",
       "555              0         NaN   \n",
       "556              0         NaN   \n",
       "557              0         NaN   \n",
       "558              0         NaN   \n",
       "559              0         NaN   \n",
       "\n",
       "                                                 Tweet  \n",
       "0    We are living in scary times in Canada. Gov’t ...  \n",
       "1    Just as bad in Canada. In fact, our government...  \n",
       "2    It was only a matter of time before the mainst...  \n",
       "3    Russia's taking no chances: Foreigners infecte...  \n",
       "4    Although there is now a presumptive confirmed ...  \n",
       "..                                                 ...  \n",
       "555  BREAKING: Harvard classes will move online sta...  \n",
       "556  Singularity University is hosting a FREE Virtu...  \n",
       "557  Coronavirus: how does it spread and what are t...  \n",
       "558  Stanford just cancelled classes for the rest o...  \n",
       "559  Tech conferences were cancelled in #Waterloo R...  \n",
       "\n",
       "[560 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(window_size = 15,\n",
    "                   lowercase = True,\n",
    "                   lemmatize = True,\n",
    "                   pmi = True,\n",
    "                   spmi_k = 5,\n",
    "                   laplace_smoothing = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_context_matrix = cm.fit_transform(tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>#</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>,</th>\n",
       "      <th>-</th>\n",
       "      <th>--</th>\n",
       "      <th>.</th>\n",
       "      <th>...</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoomer</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>—</th>\n",
       "      <th>‘</th>\n",
       "      <th>’</th>\n",
       "      <th>“</th>\n",
       "      <th>”</th>\n",
       "      <th>❝real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>2.424239</td>\n",
       "      <td>0.173120</td>\n",
       "      <td>-2.192211</td>\n",
       "      <td>-1.505043</td>\n",
       "      <td>-0.618213</td>\n",
       "      <td>-0.828241</td>\n",
       "      <td>-2.030626</td>\n",
       "      <td>0.377325</td>\n",
       "      <td>0.038504</td>\n",
       "      <td>-0.649706</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.001601</td>\n",
       "      <td>-2.011793</td>\n",
       "      <td>-2.002028</td>\n",
       "      <td>-1.998181</td>\n",
       "      <td>-1.339135</td>\n",
       "      <td>-2.045441</td>\n",
       "      <td>0.798712</td>\n",
       "      <td>0.025324</td>\n",
       "      <td>-1.029131</td>\n",
       "      <td>-1.309734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>0.173120</td>\n",
       "      <td>2.360850</td>\n",
       "      <td>-0.746419</td>\n",
       "      <td>-0.752397</td>\n",
       "      <td>0.863298</td>\n",
       "      <td>-0.075596</td>\n",
       "      <td>-1.501124</td>\n",
       "      <td>1.258224</td>\n",
       "      <td>-2.204583</td>\n",
       "      <td>-2.199646</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.858394</td>\n",
       "      <td>-2.175438</td>\n",
       "      <td>-2.165674</td>\n",
       "      <td>-2.854974</td>\n",
       "      <td>-1.790463</td>\n",
       "      <td>-1.292796</td>\n",
       "      <td>0.699605</td>\n",
       "      <td>-1.236934</td>\n",
       "      <td>-1.375098</td>\n",
       "      <td>-2.859674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>-2.192211</td>\n",
       "      <td>-0.746419</td>\n",
       "      <td>-0.881736</td>\n",
       "      <td>1.510181</td>\n",
       "      <td>-0.165188</td>\n",
       "      <td>-1.309525</td>\n",
       "      <td>-1.818762</td>\n",
       "      <td>-0.158026</td>\n",
       "      <td>-1.135927</td>\n",
       "      <td>-1.824138</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.789738</td>\n",
       "      <td>-1.799929</td>\n",
       "      <td>-1.790165</td>\n",
       "      <td>-1.786318</td>\n",
       "      <td>-1.820419</td>\n",
       "      <td>-1.833577</td>\n",
       "      <td>-0.781184</td>\n",
       "      <td>-1.266890</td>\n",
       "      <td>-1.915880</td>\n",
       "      <td>-1.791018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>-1.505043</td>\n",
       "      <td>-0.752397</td>\n",
       "      <td>1.510181</td>\n",
       "      <td>-0.893693</td>\n",
       "      <td>-0.171166</td>\n",
       "      <td>-1.315503</td>\n",
       "      <td>-1.824741</td>\n",
       "      <td>-0.009854</td>\n",
       "      <td>-1.141905</td>\n",
       "      <td>-1.830116</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.795717</td>\n",
       "      <td>-1.805908</td>\n",
       "      <td>-1.796144</td>\n",
       "      <td>-1.792297</td>\n",
       "      <td>-1.826398</td>\n",
       "      <td>-1.839556</td>\n",
       "      <td>-0.787163</td>\n",
       "      <td>-1.272869</td>\n",
       "      <td>-1.921859</td>\n",
       "      <td>-1.796996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>-0.618213</td>\n",
       "      <td>0.863298</td>\n",
       "      <td>-0.165188</td>\n",
       "      <td>-0.171166</td>\n",
       "      <td>1.306332</td>\n",
       "      <td>-0.261620</td>\n",
       "      <td>-1.033221</td>\n",
       "      <td>1.190300</td>\n",
       "      <td>-1.266676</td>\n",
       "      <td>-1.038597</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.227341</td>\n",
       "      <td>-1.930679</td>\n",
       "      <td>-2.614062</td>\n",
       "      <td>-2.610215</td>\n",
       "      <td>-1.545704</td>\n",
       "      <td>-1.271180</td>\n",
       "      <td>0.614122</td>\n",
       "      <td>-0.011346</td>\n",
       "      <td>-0.542552</td>\n",
       "      <td>-2.614915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>-2.045441</td>\n",
       "      <td>-1.292796</td>\n",
       "      <td>-1.833577</td>\n",
       "      <td>-1.839556</td>\n",
       "      <td>-1.271180</td>\n",
       "      <td>-1.855901</td>\n",
       "      <td>-1.671992</td>\n",
       "      <td>-1.292190</td>\n",
       "      <td>-1.682303</td>\n",
       "      <td>-1.677367</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.642968</td>\n",
       "      <td>-1.653159</td>\n",
       "      <td>-1.643394</td>\n",
       "      <td>-1.639547</td>\n",
       "      <td>-1.673649</td>\n",
       "      <td>-1.686807</td>\n",
       "      <td>0.058733</td>\n",
       "      <td>-1.813267</td>\n",
       "      <td>-1.769109</td>\n",
       "      <td>-1.644247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>0.798712</td>\n",
       "      <td>0.699605</td>\n",
       "      <td>-0.781184</td>\n",
       "      <td>-0.787163</td>\n",
       "      <td>0.614122</td>\n",
       "      <td>-0.467036</td>\n",
       "      <td>-2.229037</td>\n",
       "      <td>1.007236</td>\n",
       "      <td>-0.447589</td>\n",
       "      <td>-2.234412</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.200012</td>\n",
       "      <td>-2.210204</td>\n",
       "      <td>-2.200439</td>\n",
       "      <td>-2.196592</td>\n",
       "      <td>-2.230694</td>\n",
       "      <td>0.058733</td>\n",
       "      <td>1.309977</td>\n",
       "      <td>0.268746</td>\n",
       "      <td>0.238795</td>\n",
       "      <td>-1.508145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“</th>\n",
       "      <td>0.025324</td>\n",
       "      <td>-1.236934</td>\n",
       "      <td>-1.266890</td>\n",
       "      <td>-1.272869</td>\n",
       "      <td>-0.011346</td>\n",
       "      <td>-0.596067</td>\n",
       "      <td>-1.105304</td>\n",
       "      <td>-0.137716</td>\n",
       "      <td>-1.115616</td>\n",
       "      <td>-1.110680</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.769428</td>\n",
       "      <td>-1.779619</td>\n",
       "      <td>-1.769854</td>\n",
       "      <td>-1.766007</td>\n",
       "      <td>-1.106961</td>\n",
       "      <td>-1.813267</td>\n",
       "      <td>0.268746</td>\n",
       "      <td>-0.330289</td>\n",
       "      <td>1.148953</td>\n",
       "      <td>-1.770707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>”</th>\n",
       "      <td>-1.029131</td>\n",
       "      <td>-1.375098</td>\n",
       "      <td>-1.915880</td>\n",
       "      <td>-1.921859</td>\n",
       "      <td>-0.542552</td>\n",
       "      <td>-0.839592</td>\n",
       "      <td>-1.061147</td>\n",
       "      <td>-0.344873</td>\n",
       "      <td>-1.071459</td>\n",
       "      <td>-1.759670</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.725270</td>\n",
       "      <td>-1.735461</td>\n",
       "      <td>-1.725697</td>\n",
       "      <td>-1.721850</td>\n",
       "      <td>-1.062804</td>\n",
       "      <td>-1.769109</td>\n",
       "      <td>0.238795</td>\n",
       "      <td>1.148953</td>\n",
       "      <td>0.345813</td>\n",
       "      <td>-1.726550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>❝real</th>\n",
       "      <td>-1.309734</td>\n",
       "      <td>-2.859674</td>\n",
       "      <td>-1.791018</td>\n",
       "      <td>-1.796996</td>\n",
       "      <td>-2.614915</td>\n",
       "      <td>-1.813342</td>\n",
       "      <td>-1.629432</td>\n",
       "      <td>-2.859068</td>\n",
       "      <td>-1.639744</td>\n",
       "      <td>-1.634807</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.600408</td>\n",
       "      <td>-1.610599</td>\n",
       "      <td>-1.600835</td>\n",
       "      <td>-1.596988</td>\n",
       "      <td>-1.631089</td>\n",
       "      <td>-1.644247</td>\n",
       "      <td>-1.508145</td>\n",
       "      <td>-1.770707</td>\n",
       "      <td>-1.726550</td>\n",
       "      <td>-1.601688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2325 rows × 2325 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              !         #         (         )         ,         -        --  \\\n",
       "!      2.424239  0.173120 -2.192211 -1.505043 -0.618213 -0.828241 -2.030626   \n",
       "#      0.173120  2.360850 -0.746419 -0.752397  0.863298 -0.075596 -1.501124   \n",
       "(     -2.192211 -0.746419 -0.881736  1.510181 -0.165188 -1.309525 -1.818762   \n",
       ")     -1.505043 -0.752397  1.510181 -0.893693 -0.171166 -1.315503 -1.824741   \n",
       ",     -0.618213  0.863298 -0.165188 -0.171166  1.306332 -0.261620 -1.033221   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "‘     -2.045441 -1.292796 -1.833577 -1.839556 -1.271180 -1.855901 -1.671992   \n",
       "’      0.798712  0.699605 -0.781184 -0.787163  0.614122 -0.467036 -2.229037   \n",
       "“      0.025324 -1.236934 -1.266890 -1.272869 -0.011346 -0.596067 -1.105304   \n",
       "”     -1.029131 -1.375098 -1.915880 -1.921859 -0.542552 -0.839592 -1.061147   \n",
       "❝real -1.309734 -2.859674 -1.791018 -1.796996 -2.614915 -1.813342 -1.629432   \n",
       "\n",
       "              .       ...         1  ...    zombie      zone    zoomer  \\\n",
       "!      0.377325  0.038504 -0.649706  ... -2.001601 -2.011793 -2.002028   \n",
       "#      1.258224 -2.204583 -2.199646  ... -2.858394 -2.175438 -2.165674   \n",
       "(     -0.158026 -1.135927 -1.824138  ... -1.789738 -1.799929 -1.790165   \n",
       ")     -0.009854 -1.141905 -1.830116  ... -1.795717 -1.805908 -1.796144   \n",
       ",      1.190300 -1.266676 -1.038597  ... -1.227341 -1.930679 -2.614062   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "‘     -1.292190 -1.682303 -1.677367  ... -1.642968 -1.653159 -1.643394   \n",
       "’      1.007236 -0.447589 -2.234412  ... -2.200012 -2.210204 -2.200439   \n",
       "“     -0.137716 -1.115616 -1.110680  ... -1.769428 -1.779619 -1.769854   \n",
       "”     -0.344873 -1.071459 -1.759670  ... -1.725270 -1.735461 -1.725697   \n",
       "❝real -2.859068 -1.639744 -1.634807  ... -1.600408 -1.610599 -1.600835   \n",
       "\n",
       "       zuckerberg         —         ‘         ’         “         ”     ❝real  \n",
       "!       -1.998181 -1.339135 -2.045441  0.798712  0.025324 -1.029131 -1.309734  \n",
       "#       -2.854974 -1.790463 -1.292796  0.699605 -1.236934 -1.375098 -2.859674  \n",
       "(       -1.786318 -1.820419 -1.833577 -0.781184 -1.266890 -1.915880 -1.791018  \n",
       ")       -1.792297 -1.826398 -1.839556 -0.787163 -1.272869 -1.921859 -1.796996  \n",
       ",       -2.610215 -1.545704 -1.271180  0.614122 -0.011346 -0.542552 -2.614915  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "‘       -1.639547 -1.673649 -1.686807  0.058733 -1.813267 -1.769109 -1.644247  \n",
       "’       -2.196592 -2.230694  0.058733  1.309977  0.268746  0.238795 -1.508145  \n",
       "“       -1.766007 -1.106961 -1.813267  0.268746 -0.330289  1.148953 -1.770707  \n",
       "”       -1.721850 -1.062804 -1.769109  0.238795  1.148953  0.345813 -1.726550  \n",
       "❝real   -1.596988 -1.631089 -1.644247 -1.508145 -1.770707 -1.726550 -1.601688  \n",
       "\n",
       "[2325 rows x 2325 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(word_context_matrix, index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2325, 2325)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_context_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = FastICA(n_components = 2)\n",
    "std_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.28019289e-01, -3.10946823e-02],\n",
       "       [-5.89080641e-02, -9.24961981e-01],\n",
       "       [-6.92373190e-02,  1.40075124e-02],\n",
       "       ...,\n",
       "       [-6.67502869e-02,  2.91684282e-02],\n",
       "       [-4.83112264e-02,  2.09929945e-02],\n",
       "       [ 4.28472839e-03, -1.08498972e-04]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std = std_scaler.fit_transform(word_context_matrix)\n",
    "\n",
    "matrix = ica.fit_transform(X_std)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comp 1</th>\n",
       "      <th>Comp 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>-0.128019</td>\n",
       "      <td>-0.031095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>-0.058908</td>\n",
       "      <td>-0.924962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>-0.069237</td>\n",
       "      <td>0.014008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>-0.071837</td>\n",
       "      <td>0.015485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>-0.359744</td>\n",
       "      <td>0.138129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>-0.012816</td>\n",
       "      <td>0.003980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>-0.195279</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“</th>\n",
       "      <td>-0.066750</td>\n",
       "      <td>0.029168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>”</th>\n",
       "      <td>-0.048311</td>\n",
       "      <td>0.020993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>❝real</th>\n",
       "      <td>0.004285</td>\n",
       "      <td>-0.000108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2325 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Comp 1    Comp 2\n",
       "!     -0.128019 -0.031095\n",
       "#     -0.058908 -0.924962\n",
       "(     -0.069237  0.014008\n",
       ")     -0.071837  0.015485\n",
       ",     -0.359744  0.138129\n",
       "...         ...       ...\n",
       "‘     -0.012816  0.003980\n",
       "’     -0.195279  0.000117\n",
       "“     -0.066750  0.029168\n",
       "”     -0.048311  0.020993\n",
       "❝real  0.004285 -0.000108\n",
       "\n",
       "[2325 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(matrix,\n",
    "                  index = cm.vocabulary,\n",
    "                  columns = ['Comp {}'.format(i+1) for i in range(2)])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 62222 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 62222 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = [key for key in cm.vocabulary.keys()]\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    \n",
    "    #if re.match('^co[rv]', word):\n",
    "    \n",
    "        x = df['Comp 1'][i]\n",
    "        y = df['Comp 2'][i]\n",
    "\n",
    "        plt.scatter(x, y)\n",
    "        plt.text(x, y, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set word embeddings for text classification\n",
    "ica = FastICA(n_components = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00135197, -0.00161768, -0.00058273, ..., -0.00428919,\n",
       "        -0.0020004 ,  0.00468029],\n",
       "       [-0.0012104 , -0.00161311, -0.00066262, ...,  0.00013151,\n",
       "        -0.00329915,  0.00026453],\n",
       "       [-0.00321644, -0.00234192, -0.00019857, ...,  0.01112857,\n",
       "         0.00195988,  0.00259193],\n",
       "       ...,\n",
       "       [-0.00413063, -0.01172052, -0.00221625, ..., -0.00327423,\n",
       "         0.00680228,  0.01736448],\n",
       "       [-0.00530173,  0.00468326,  0.00518072, ...,  0.00361696,\n",
       "        -0.00094083, -0.02141735],\n",
       "       [ 0.0009765 ,  0.00419485,  0.00183033, ..., -0.0056804 ,\n",
       "         0.00054511,  0.00042905]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = ica.fit_transform(X_std)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out target\n",
    "y = tweets['Is_Unreliable']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derive text vectors from word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_vectors(word_embeddings,\n",
    "                     word_index_dict,\n",
    "                     text_list,\n",
    "                     remove_stopwords = True,\n",
    "                     lowercase = True,\n",
    "                     lemmatize = True,\n",
    "                     add_start_end_tokens = True):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    for k in range(len(text_list)):\n",
    "        text = text_list[k]\n",
    "        text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "        text_vec = np.zeros(word_embeddings.shape[1])\n",
    "        words = word_tokenize(text)\n",
    "        tracker = 0 # to track whether we've encountered a word for which we have an embedding (in each tweet)\n",
    "        \n",
    "        if remove_stopwords:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                if word.lower() not in set(stopwords.words('english')):\n",
    "                    clean_words.append(word)\n",
    "            words = clean_words\n",
    "\n",
    "        if lowercase:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                clean_words.append(word.lower())\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if lemmatize:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                PoS_tag = pos_tag([word])[0][1]\n",
    "\n",
    "                # to change contractions to full word form\n",
    "                if word in contractions:\n",
    "                    word = contractions[word]\n",
    "\n",
    "                if PoS_tag[0].upper() in 'JNVR':\n",
    "                    word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                else:\n",
    "                    word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                clean_words.append(word)\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if add_start_end_tokens:\n",
    "            words = ['<START>'] + words + ['<END>']\n",
    "        \n",
    "        for i in range(len(words)):\n",
    "            word = words[i]\n",
    "            if word in word_index_dict:\n",
    "                word_embed_vec = word_embeddings[word_index_dict[word],:]\n",
    "                if tracker == 0:\n",
    "                    text_matrix = word_embed_vec\n",
    "                else:\n",
    "                    text_matrix = np.vstack((text_matrix, word_embed_vec))\n",
    "                    \n",
    "                # only increment if we have come across a word in the embeddings dictionary\n",
    "                tracker += 1\n",
    "                    \n",
    "        for j in range(len(text_vec)):\n",
    "            text_vec[j] = text_matrix[:,j].mean()\n",
    "            \n",
    "        if k == 0:\n",
    "            full_matrix = text_vec\n",
    "        else:\n",
    "            full_matrix = np.vstack((full_matrix, text_vec))\n",
    "            \n",
    "    return full_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_text_vectors(embeddings, cm.vocabulary, tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 250)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.96829794e-04,  1.33335773e-02,  1.50263627e-03, ...,\n",
       "         6.81351083e-03,  6.92629764e-03, -1.65820213e-02],\n",
       "       [-5.27388363e-04,  1.30326511e-02, -4.26490313e-03, ...,\n",
       "         8.59080118e-03, -3.13314158e-03, -4.85245736e-03],\n",
       "       [-2.94272083e-03,  4.39016427e-04, -3.76504354e-07, ...,\n",
       "         4.79516414e-04,  1.50264557e-03,  2.85140345e-03],\n",
       "       ...,\n",
       "       [-5.31273557e-03,  5.08915902e-04,  1.04298233e-03, ...,\n",
       "        -2.41018097e-05, -5.61021969e-03,  9.86288159e-03],\n",
       "       [-4.13170286e-03, -5.11050962e-03, -6.38441814e-04, ...,\n",
       "        -6.21521027e-04, -5.87425879e-03,  4.01968485e-03],\n",
       "       [ 6.93345995e-02, -1.49004916e-03, -2.72494820e-04, ...,\n",
       "         8.51784668e-04,  5.27591363e-04,  9.06339358e-04]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, KFold, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipe = Pipeline([\n",
    "    ('classify', SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC hyperparams to optimize\n",
    "kernel = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "C = [0.001, 0.01, 0.1, 1, 10]\n",
    "# set up parameter grid\n",
    "params = {\n",
    "    'classify__kernel': kernel,\n",
    "    'classify__C': C\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CV scheme for inner and outer loops\n",
    "inner_cv = KFold(n_splits = 3, shuffle = True, random_state = 1)\n",
    "outer_cv = KFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "\n",
    "# Set up GridSearch for inner loop\n",
    "grid_SVC = GridSearchCV(pipe, params, cv = inner_cv)\n",
    "#grid_SVC.fit(X, y)\n",
    "\n",
    "# Nested CV scores\n",
    "scores = cross_validate(grid_SVC,\n",
    "                        X = X,\n",
    "                        y = y,\n",
    "                        cv = outer_cv,\n",
    "                        scoring = ['roc_auc', 'accuracy', 'f1', 'precision', 'recall'],\n",
    "                        return_estimator = True)\n",
    "auc = scores['test_roc_auc']\n",
    "accuracy = scores['test_accuracy']\n",
    "f1 = scores['test_f1']\n",
    "precision = scores['test_precision']\n",
    "recall = scores['test_recall']\n",
    "estimators = scores['estimator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9271220371227569"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8625"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8685628897333473"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8303853426280299"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9125306911346162"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classify__C': 10, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in estimators:\n",
    "    print(i.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
