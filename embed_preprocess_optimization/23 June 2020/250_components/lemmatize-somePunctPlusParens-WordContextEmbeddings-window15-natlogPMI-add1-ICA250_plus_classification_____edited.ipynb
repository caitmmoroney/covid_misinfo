{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Word Context Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.decomposition import FastICA, TruncatedSVD, PCA, NMF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert contractions picked up by word_tokenize() into full words\n",
    "contractions = {\n",
    "    \"n't\": 'not',\n",
    "    \"'ve\": 'have',\n",
    "    \"'s\": 'is', # note that this will include possessive nouns\n",
    "    'gonna': 'going to',\n",
    "    'gotta': 'got to',\n",
    "    \"'d\": 'would',\n",
    "    \"'ll\": 'will',\n",
    "    \"'re\": 'are',\n",
    "    \"'m\": 'am',\n",
    "    'wanna': 'want to'\n",
    "}\n",
    "\n",
    "# to convert nltk_pos tags to wordnet-compatible PoS tags\n",
    "def convert_pos_wordnet(tag):\n",
    "    tag_abbr = tag[0].upper()\n",
    "    tag_dict = {\n",
    "        'J': wordnet.ADJ,\n",
    "        'N': wordnet.NOUN,\n",
    "        'V': wordnet.VERB,\n",
    "        'R': wordnet.ADV\n",
    "    }\n",
    "                \n",
    "    if tag_abbr in tag_dict:\n",
    "        return tag_dict[tag_abbr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextMatrix(TransformerMixin):\n",
    "    \n",
    "    # initialize class & private variables\n",
    "    def __init__(self,\n",
    "                 window_size = 4,\n",
    "                 remove_stopwords = True,\n",
    "                 add_start_end_tokens = True,\n",
    "                 lowercase = False,\n",
    "                 lemmatize = False,\n",
    "                 pmi = False,\n",
    "                 spmi_k = 1,\n",
    "                 laplace_smoothing = 0,\n",
    "                 pmi_positive = False,\n",
    "                 sppmi_k = 1):\n",
    "        \n",
    "        \"\"\" Params:\n",
    "                window_size: size of +/- context window (default = 4)\n",
    "                remove_stopwords: boolean, whether or not to remove NLTK English stopwords\n",
    "                add_start_end_tokens: boolean, whether or not to append <START> and <END> to the\n",
    "                beginning/end of each document in the corpus (default = True)\n",
    "                lowercase: boolean, whether or not to convert words to all lowercase\n",
    "                lemmatize: boolean, whether or not to lemmatize input text\n",
    "                pmi: boolean, whether or not to compute pointwise mutual information\n",
    "                pmi_positive: boolean, whether or not to compute positive PMI\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.add_start_end_tokens = add_start_end_tokens\n",
    "        self.lowercase = lowercase\n",
    "        self.lemmatize = lemmatize\n",
    "        self.pmi = pmi\n",
    "        self.spmi_k = spmi_k\n",
    "        self.laplace_smoothing = laplace_smoothing\n",
    "        self.pmi_positive = pmi_positive\n",
    "        self.sppmi_k = sppmi_k\n",
    "        self.corpus = None\n",
    "        self.clean_corpus = None\n",
    "        self.vocabulary = None\n",
    "        self.X = None\n",
    "        self.doc_terms_lists = None\n",
    "    \n",
    "    def fit(self, corpus, y = None):\n",
    "        \n",
    "        \"\"\" Learn the dictionary of all unique tokens for given corpus.\n",
    "        \n",
    "            Params:\n",
    "                corpus: list of strings\n",
    "            \n",
    "            Returns: self\n",
    "        \"\"\"\n",
    "        self.corpus = corpus\n",
    "        \n",
    "        term_dict = dict()\n",
    "        k = 0\n",
    "        corpus_words = []\n",
    "        clean_corpus = []\n",
    "        doc_terms_lists = []\n",
    "        detokenizer = TreebankWordDetokenizer()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        for text in corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "            \n",
    "            # detokenize trick taken from this StackOverflow post:\n",
    "            # https://stackoverflow.com/questions/21948019/python-untokenize-a-sentence\n",
    "            # and NLTK treebank documentation:\n",
    "            # https://www.nltk.org/_modules/nltk/tokenize/treebank.html\n",
    "            text = detokenizer.detokenize(words)\n",
    "            clean_corpus.append(text)\n",
    "            \n",
    "            [corpus_words.append(word) for word in words]\n",
    "            \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            doc_terms_lists.append(words)\n",
    "            \n",
    "        self.clean_corpus = clean_corpus\n",
    "        \n",
    "        self.doc_terms_lists = doc_terms_lists\n",
    "        \n",
    "        corpus_words = list(set(corpus_words))\n",
    "        \n",
    "        if self.add_start_end_tokens:\n",
    "            corpus_words = ['<START>'] + corpus_words + ['<END>']\n",
    "        \n",
    "        corpus_words = sorted(corpus_words)\n",
    "        \n",
    "        for el in corpus_words:\n",
    "            term_dict[el] = k\n",
    "            k += 1\n",
    "            \n",
    "        self.vocabulary = term_dict\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def transform(self, new_corpus = None, y = None):\n",
    "        \n",
    "        \"\"\" Compute the co-occurrence matrix for given corpus and window_size, using term dictionary\n",
    "            obtained with fit method.\n",
    "        \n",
    "            Returns: term-context co-occurrence matrix (shape: target terms by context terms) with\n",
    "            raw counts\n",
    "        \"\"\"\n",
    "        num_terms = len(self.vocabulary)\n",
    "        window = self.window_size\n",
    "        X = np.full((num_terms, num_terms), self.laplace_smoothing)\n",
    "        \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        if type(new_corpus) != list:\n",
    "            new_corpus = self.corpus\n",
    "        \n",
    "        for text in new_corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            for i in range(len(words)):\n",
    "                target = words[i]\n",
    "                \n",
    "                # check to see if target word is in the dictionary; if not, skip\n",
    "                if target in self.vocabulary:\n",
    "                    \n",
    "                    # grab index from dictionary\n",
    "                    target_dict_index = self.vocabulary[target]\n",
    "                    \n",
    "                    # find left-most and right-most window indices for each target word\n",
    "                    left_end_index = max(i - window, 0)\n",
    "                    right_end_index = min(i + window, len(words) - 1)\n",
    "                    \n",
    "                    # loop over all words within window\n",
    "                    # NOTE: this will include the target word; make sure to skip over it\n",
    "                    for j in range(left_end_index, right_end_index + 1):\n",
    "                        \n",
    "                        # skip \"context word\" where the \"context word\" index is equal to the\n",
    "                        # target word index\n",
    "                        if j != i:\n",
    "                            context_word = words[j]\n",
    "                            \n",
    "                            # check to see if context word is in the fitted dictionary; if\n",
    "                            # not, skip\n",
    "                            if context_word in self.vocabulary:\n",
    "                                X[target_dict_index, self.vocabulary[context_word]] += 1\n",
    "        \n",
    "        # if pmi = True, compute pmi matrix from word-context raw frequencies\n",
    "        # more concise code taken from this StackOverflow post:\n",
    "        # https://stackoverflow.com/questions/58701337/how-to-construct-ppmi-matrix-from-a-text-corpus\n",
    "        if self.pmi:\n",
    "            denom = X.sum()\n",
    "            col_sums = X.sum(axis = 0)\n",
    "            row_sums = X.sum(axis = 1)\n",
    "            \n",
    "            expected = np.outer(row_sums, col_sums)/denom\n",
    "            \n",
    "            X = X/expected\n",
    "            \n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(X.shape[1]):\n",
    "                \n",
    "                    if X[i,j] > 0:\n",
    "                        X[i,j] = np.log(X[i,j]) - np.log(self.spmi_k)\n",
    "                        \n",
    "                        if self.pmi_positive:\n",
    "                            X[i,j] = max(X[i,j] - np.log(self.sppmi_k), 0)\n",
    "        \n",
    "        # note that X is a dense matrix\n",
    "        self.X = X\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(lowercase = True, lemmatize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [\n",
    "    \"Coronavirus is a fake liberal hoax.\",\n",
    "    \"Trump won't do anything about coronavirus.\",\n",
    "    \"The liberal fake news media always blame Pres Trump.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ContextMatrix at 0x1a1e135050>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.fit(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <th>always</th>\n",
       "      <th>anything</th>\n",
       "      <th>blame</th>\n",
       "      <th>coronavirus</th>\n",
       "      <th>fake</th>\n",
       "      <th>hoax</th>\n",
       "      <th>liberal</th>\n",
       "      <th>medium</th>\n",
       "      <th>news</th>\n",
       "      <th>pres</th>\n",
       "      <th>trump</th>\n",
       "      <th>wont</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>always</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anything</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blame</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronavirus</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fake</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoax</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pres</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wont</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             .  <END>  <START>  always  anything  blame  coronavirus  fake  \\\n",
       ".            0      3        0       1         1      1            2     1   \n",
       "<END>        3      0        0       0         1      1            1     1   \n",
       "<START>      0      0        0       0         1      0            2     2   \n",
       "always       1      0        0       0         0      1            0     1   \n",
       "anything     1      1        1       0         0      0            1     0   \n",
       "blame        1      1        0       1         0      0            0     1   \n",
       "coronavirus  2      1        2       0         1      0            0     1   \n",
       "fake         1      1        2       1         0      1            1     0   \n",
       "hoax         1      1        1       0         0      0            1     1   \n",
       "liberal      1      1        2       1         0      0            1     2   \n",
       "medium       0      0        1       1         0      1            0     1   \n",
       "news         0      0        1       1         0      1            0     1   \n",
       "pres         1      1        0       1         0      1            0     0   \n",
       "trump        2      1        1       1         1      1            1     0   \n",
       "wont         1      1        1       0         1      0            1     0   \n",
       "\n",
       "             hoax  liberal  medium  news  pres  trump  wont  \n",
       ".               1        1       0     0     1      2     1  \n",
       "<END>           1        1       0     0     1      1     1  \n",
       "<START>         1        2       1     1     0      1     1  \n",
       "always          0        1       1     1     1      1     0  \n",
       "anything        0        0       0     0     0      1     1  \n",
       "blame           0        0       1     1     1      1     0  \n",
       "coronavirus     1        1       0     0     0      1     1  \n",
       "fake            1        2       1     1     0      0     0  \n",
       "hoax            0        1       0     0     0      0     0  \n",
       "liberal         1        0       1     1     0      0     0  \n",
       "medium          0        1       0     1     1      1     0  \n",
       "news            0        1       1     0     1      0     0  \n",
       "pres            0        0       1     1     0      1     0  \n",
       "trump           0        0       1     0     1      0     1  \n",
       "wont            0        0       0     0     0      1     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cm.transform(tweets), index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coronavirus fake liberal hoax.',\n",
       " 'trump wont anything coronavirus.',\n",
       " 'liberal fake news medium always blame pres trump.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.clean_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coronavirus is a fake liberal hoax.',\n",
       " \"Trump won't do anything about coronavirus.\",\n",
       " 'The liberal fake news media always blame Pres Trump.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train embeddings using tweets as corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('COVID19_Dataset-text_labels_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Unreliable</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 3, 6, 9</td>\n",
       "      <td>We are living in scary times in Canada. Gov’t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 6, 8, 9</td>\n",
       "      <td>Just as bad in Canada. In fact, our government...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 4, 9</td>\n",
       "      <td>It was only a matter of time before the mainst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8</td>\n",
       "      <td>Russia's taking no chances: Foreigners infecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8, 9</td>\n",
       "      <td>Although there is now a presumptive confirmed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BREAKING: Harvard classes will move online sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singularity University is hosting a FREE Virtu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus: how does it spread and what are t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stanford just cancelled classes for the rest o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tech conferences were cancelled in #Waterloo R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Is_Unreliable    Category  \\\n",
       "0                1  1, 3, 6, 9   \n",
       "1                1  1, 6, 8, 9   \n",
       "2                1     1, 4, 9   \n",
       "3                1        6, 8   \n",
       "4                1     6, 8, 9   \n",
       "..             ...         ...   \n",
       "555              0         NaN   \n",
       "556              0         NaN   \n",
       "557              0         NaN   \n",
       "558              0         NaN   \n",
       "559              0         NaN   \n",
       "\n",
       "                                                 Tweet  \n",
       "0    We are living in scary times in Canada. Gov’t ...  \n",
       "1    Just as bad in Canada. In fact, our government...  \n",
       "2    It was only a matter of time before the mainst...  \n",
       "3    Russia's taking no chances: Foreigners infecte...  \n",
       "4    Although there is now a presumptive confirmed ...  \n",
       "..                                                 ...  \n",
       "555  BREAKING: Harvard classes will move online sta...  \n",
       "556  Singularity University is hosting a FREE Virtu...  \n",
       "557  Coronavirus: how does it spread and what are t...  \n",
       "558  Stanford just cancelled classes for the rest o...  \n",
       "559  Tech conferences were cancelled in #Waterloo R...  \n",
       "\n",
       "[560 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(window_size = 15, lowercase = True, lemmatize = True, pmi = True, laplace_smoothing = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_context_matrix = cm.fit_transform(tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>#</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>,</th>\n",
       "      <th>-</th>\n",
       "      <th>--</th>\n",
       "      <th>.</th>\n",
       "      <th>...</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoomer</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>—</th>\n",
       "      <th>‘</th>\n",
       "      <th>’</th>\n",
       "      <th>“</th>\n",
       "      <th>”</th>\n",
       "      <th>❝real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>4.033677</td>\n",
       "      <td>1.782558</td>\n",
       "      <td>-0.582773</td>\n",
       "      <td>0.104395</td>\n",
       "      <td>0.991225</td>\n",
       "      <td>0.781197</td>\n",
       "      <td>-0.421188</td>\n",
       "      <td>1.986763</td>\n",
       "      <td>1.647942</td>\n",
       "      <td>0.959731</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.392164</td>\n",
       "      <td>-0.402355</td>\n",
       "      <td>-0.392590</td>\n",
       "      <td>-0.388743</td>\n",
       "      <td>0.270302</td>\n",
       "      <td>-0.436003</td>\n",
       "      <td>2.408150</td>\n",
       "      <td>1.634762</td>\n",
       "      <td>0.580307</td>\n",
       "      <td>0.299704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>1.782558</td>\n",
       "      <td>3.970288</td>\n",
       "      <td>0.863019</td>\n",
       "      <td>0.857040</td>\n",
       "      <td>2.472735</td>\n",
       "      <td>1.533842</td>\n",
       "      <td>0.108314</td>\n",
       "      <td>2.867662</td>\n",
       "      <td>-0.595145</td>\n",
       "      <td>-0.590209</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.248956</td>\n",
       "      <td>-0.566000</td>\n",
       "      <td>-0.556236</td>\n",
       "      <td>-1.245536</td>\n",
       "      <td>-0.181025</td>\n",
       "      <td>0.316642</td>\n",
       "      <td>2.309043</td>\n",
       "      <td>0.372504</td>\n",
       "      <td>0.234340</td>\n",
       "      <td>-1.250236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>-0.582773</td>\n",
       "      <td>0.863019</td>\n",
       "      <td>0.727702</td>\n",
       "      <td>3.119619</td>\n",
       "      <td>1.444250</td>\n",
       "      <td>0.299913</td>\n",
       "      <td>-0.209324</td>\n",
       "      <td>1.451412</td>\n",
       "      <td>0.473511</td>\n",
       "      <td>-0.214700</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.180300</td>\n",
       "      <td>-0.190491</td>\n",
       "      <td>-0.180727</td>\n",
       "      <td>-0.176880</td>\n",
       "      <td>-0.210981</td>\n",
       "      <td>-0.224140</td>\n",
       "      <td>0.828254</td>\n",
       "      <td>0.342548</td>\n",
       "      <td>-0.306442</td>\n",
       "      <td>-0.181580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>0.104395</td>\n",
       "      <td>0.857040</td>\n",
       "      <td>3.119619</td>\n",
       "      <td>0.715745</td>\n",
       "      <td>1.438272</td>\n",
       "      <td>0.293935</td>\n",
       "      <td>-0.215303</td>\n",
       "      <td>1.599584</td>\n",
       "      <td>0.467533</td>\n",
       "      <td>-0.220678</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.186279</td>\n",
       "      <td>-0.196470</td>\n",
       "      <td>-0.186706</td>\n",
       "      <td>-0.182859</td>\n",
       "      <td>-0.216960</td>\n",
       "      <td>-0.230118</td>\n",
       "      <td>0.822275</td>\n",
       "      <td>0.336569</td>\n",
       "      <td>-0.312421</td>\n",
       "      <td>-0.187558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.991225</td>\n",
       "      <td>2.472735</td>\n",
       "      <td>1.444250</td>\n",
       "      <td>1.438272</td>\n",
       "      <td>2.915770</td>\n",
       "      <td>1.347818</td>\n",
       "      <td>0.576217</td>\n",
       "      <td>2.799738</td>\n",
       "      <td>0.342761</td>\n",
       "      <td>0.570841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382097</td>\n",
       "      <td>-0.321241</td>\n",
       "      <td>-1.004624</td>\n",
       "      <td>-1.000777</td>\n",
       "      <td>0.063734</td>\n",
       "      <td>0.338258</td>\n",
       "      <td>2.223560</td>\n",
       "      <td>1.598092</td>\n",
       "      <td>1.066886</td>\n",
       "      <td>-1.005477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>-0.436003</td>\n",
       "      <td>0.316642</td>\n",
       "      <td>-0.224140</td>\n",
       "      <td>-0.230118</td>\n",
       "      <td>0.338258</td>\n",
       "      <td>-0.246463</td>\n",
       "      <td>-0.062554</td>\n",
       "      <td>0.317248</td>\n",
       "      <td>-0.072865</td>\n",
       "      <td>-0.067929</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033530</td>\n",
       "      <td>-0.043721</td>\n",
       "      <td>-0.033956</td>\n",
       "      <td>-0.030109</td>\n",
       "      <td>-0.064211</td>\n",
       "      <td>-0.077369</td>\n",
       "      <td>1.668171</td>\n",
       "      <td>-0.203829</td>\n",
       "      <td>-0.159672</td>\n",
       "      <td>-0.034809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>2.408150</td>\n",
       "      <td>2.309043</td>\n",
       "      <td>0.828254</td>\n",
       "      <td>0.822275</td>\n",
       "      <td>2.223560</td>\n",
       "      <td>1.142402</td>\n",
       "      <td>-0.619599</td>\n",
       "      <td>2.616674</td>\n",
       "      <td>1.161849</td>\n",
       "      <td>-0.624974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.590575</td>\n",
       "      <td>-0.600766</td>\n",
       "      <td>-0.591001</td>\n",
       "      <td>-0.587154</td>\n",
       "      <td>-0.621256</td>\n",
       "      <td>1.668171</td>\n",
       "      <td>2.919415</td>\n",
       "      <td>1.878184</td>\n",
       "      <td>1.848233</td>\n",
       "      <td>0.101293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“</th>\n",
       "      <td>1.634762</td>\n",
       "      <td>0.372504</td>\n",
       "      <td>0.342548</td>\n",
       "      <td>0.336569</td>\n",
       "      <td>1.598092</td>\n",
       "      <td>1.013371</td>\n",
       "      <td>0.504133</td>\n",
       "      <td>1.471722</td>\n",
       "      <td>0.493822</td>\n",
       "      <td>0.498758</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.159990</td>\n",
       "      <td>-0.170181</td>\n",
       "      <td>-0.160416</td>\n",
       "      <td>-0.156569</td>\n",
       "      <td>0.502476</td>\n",
       "      <td>-0.203829</td>\n",
       "      <td>1.878184</td>\n",
       "      <td>1.279149</td>\n",
       "      <td>2.758391</td>\n",
       "      <td>-0.161269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>”</th>\n",
       "      <td>0.580307</td>\n",
       "      <td>0.234340</td>\n",
       "      <td>-0.306442</td>\n",
       "      <td>-0.312421</td>\n",
       "      <td>1.066886</td>\n",
       "      <td>0.769846</td>\n",
       "      <td>0.548291</td>\n",
       "      <td>1.264565</td>\n",
       "      <td>0.537979</td>\n",
       "      <td>-0.150232</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115832</td>\n",
       "      <td>-0.126024</td>\n",
       "      <td>-0.116259</td>\n",
       "      <td>-0.112412</td>\n",
       "      <td>0.546634</td>\n",
       "      <td>-0.159672</td>\n",
       "      <td>1.848233</td>\n",
       "      <td>2.758391</td>\n",
       "      <td>1.955250</td>\n",
       "      <td>-0.117112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>❝real</th>\n",
       "      <td>0.299704</td>\n",
       "      <td>-1.250236</td>\n",
       "      <td>-0.181580</td>\n",
       "      <td>-0.187558</td>\n",
       "      <td>-1.005477</td>\n",
       "      <td>-0.203904</td>\n",
       "      <td>-0.019994</td>\n",
       "      <td>-1.249630</td>\n",
       "      <td>-0.030306</td>\n",
       "      <td>-0.025370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009030</td>\n",
       "      <td>-0.001161</td>\n",
       "      <td>0.008603</td>\n",
       "      <td>0.012450</td>\n",
       "      <td>-0.021651</td>\n",
       "      <td>-0.034809</td>\n",
       "      <td>0.101293</td>\n",
       "      <td>-0.161269</td>\n",
       "      <td>-0.117112</td>\n",
       "      <td>0.007750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2325 rows × 2325 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              !         #         (         )         ,         -        --  \\\n",
       "!      4.033677  1.782558 -0.582773  0.104395  0.991225  0.781197 -0.421188   \n",
       "#      1.782558  3.970288  0.863019  0.857040  2.472735  1.533842  0.108314   \n",
       "(     -0.582773  0.863019  0.727702  3.119619  1.444250  0.299913 -0.209324   \n",
       ")      0.104395  0.857040  3.119619  0.715745  1.438272  0.293935 -0.215303   \n",
       ",      0.991225  2.472735  1.444250  1.438272  2.915770  1.347818  0.576217   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "‘     -0.436003  0.316642 -0.224140 -0.230118  0.338258 -0.246463 -0.062554   \n",
       "’      2.408150  2.309043  0.828254  0.822275  2.223560  1.142402 -0.619599   \n",
       "“      1.634762  0.372504  0.342548  0.336569  1.598092  1.013371  0.504133   \n",
       "”      0.580307  0.234340 -0.306442 -0.312421  1.066886  0.769846  0.548291   \n",
       "❝real  0.299704 -1.250236 -0.181580 -0.187558 -1.005477 -0.203904 -0.019994   \n",
       "\n",
       "              .       ...         1  ...    zombie      zone    zoomer  \\\n",
       "!      1.986763  1.647942  0.959731  ... -0.392164 -0.402355 -0.392590   \n",
       "#      2.867662 -0.595145 -0.590209  ... -1.248956 -0.566000 -0.556236   \n",
       "(      1.451412  0.473511 -0.214700  ... -0.180300 -0.190491 -0.180727   \n",
       ")      1.599584  0.467533 -0.220678  ... -0.186279 -0.196470 -0.186706   \n",
       ",      2.799738  0.342761  0.570841  ...  0.382097 -0.321241 -1.004624   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "‘      0.317248 -0.072865 -0.067929  ... -0.033530 -0.043721 -0.033956   \n",
       "’      2.616674  1.161849 -0.624974  ... -0.590575 -0.600766 -0.591001   \n",
       "“      1.471722  0.493822  0.498758  ... -0.159990 -0.170181 -0.160416   \n",
       "”      1.264565  0.537979 -0.150232  ... -0.115832 -0.126024 -0.116259   \n",
       "❝real -1.249630 -0.030306 -0.025370  ...  0.009030 -0.001161  0.008603   \n",
       "\n",
       "       zuckerberg         —         ‘         ’         “         ”     ❝real  \n",
       "!       -0.388743  0.270302 -0.436003  2.408150  1.634762  0.580307  0.299704  \n",
       "#       -1.245536 -0.181025  0.316642  2.309043  0.372504  0.234340 -1.250236  \n",
       "(       -0.176880 -0.210981 -0.224140  0.828254  0.342548 -0.306442 -0.181580  \n",
       ")       -0.182859 -0.216960 -0.230118  0.822275  0.336569 -0.312421 -0.187558  \n",
       ",       -1.000777  0.063734  0.338258  2.223560  1.598092  1.066886 -1.005477  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "‘       -0.030109 -0.064211 -0.077369  1.668171 -0.203829 -0.159672 -0.034809  \n",
       "’       -0.587154 -0.621256  1.668171  2.919415  1.878184  1.848233  0.101293  \n",
       "“       -0.156569  0.502476 -0.203829  1.878184  1.279149  2.758391 -0.161269  \n",
       "”       -0.112412  0.546634 -0.159672  1.848233  2.758391  1.955250 -0.117112  \n",
       "❝real    0.012450 -0.021651 -0.034809  0.101293 -0.161269 -0.117112  0.007750  \n",
       "\n",
       "[2325 rows x 2325 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(word_context_matrix, index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2325, 2325)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_context_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = FastICA(n_components = 2)\n",
    "std_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.85193848e-02,  1.28617503e-01],\n",
       "       [ 9.23593576e-01,  7.74579396e-02],\n",
       "       [-1.53941163e-02,  6.89422797e-02],\n",
       "       ...,\n",
       "       [-3.05020704e-02,  6.61515057e-02],\n",
       "       [-2.19582559e-02,  4.78802194e-02],\n",
       "       [ 1.94461205e-04, -4.28168824e-03]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std = std_scaler.fit_transform(word_context_matrix)\n",
    "\n",
    "matrix = ica.fit_transform(X_std)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comp 1</th>\n",
       "      <th>Comp 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>0.028519</td>\n",
       "      <td>0.128618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>0.923594</td>\n",
       "      <td>0.077458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>-0.015394</td>\n",
       "      <td>0.068942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>-0.016923</td>\n",
       "      <td>0.071512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>-0.145321</td>\n",
       "      <td>0.356900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>-0.004236</td>\n",
       "      <td>0.012734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>-0.004035</td>\n",
       "      <td>0.195237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“</th>\n",
       "      <td>-0.030502</td>\n",
       "      <td>0.066152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>”</th>\n",
       "      <td>-0.021958</td>\n",
       "      <td>0.047880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>❝real</th>\n",
       "      <td>0.000194</td>\n",
       "      <td>-0.004282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2325 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Comp 1    Comp 2\n",
       "!      0.028519  0.128618\n",
       "#      0.923594  0.077458\n",
       "(     -0.015394  0.068942\n",
       ")     -0.016923  0.071512\n",
       ",     -0.145321  0.356900\n",
       "...         ...       ...\n",
       "‘     -0.004236  0.012734\n",
       "’     -0.004035  0.195237\n",
       "“     -0.030502  0.066152\n",
       "”     -0.021958  0.047880\n",
       "❝real  0.000194 -0.004282\n",
       "\n",
       "[2325 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(matrix,\n",
    "                  index = cm.vocabulary,\n",
    "                  columns = ['Comp {}'.format(i+1) for i in range(2)])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 62222 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 62222 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = [key for key in cm.vocabulary.keys()]\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    \n",
    "    #if re.match('^co[rv]', word):\n",
    "    \n",
    "        x = df['Comp 1'][i]\n",
    "        y = df['Comp 2'][i]\n",
    "\n",
    "        plt.scatter(x, y)\n",
    "        plt.text(x, y, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set word embeddings for text classification\n",
    "ica = FastICA(n_components = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00424978,  0.0011985 ,  0.00114197, ..., -0.00307293,\n",
       "         0.00190511,  0.00239288],\n",
       "       [ 0.00429427, -0.00362679, -0.00123628, ..., -0.00208088,\n",
       "        -0.00184989,  0.00180387],\n",
       "       [ 0.00066321, -0.0021798 , -0.00302004, ...,  0.0009759 ,\n",
       "        -0.0092731 ,  0.0003531 ],\n",
       "       ...,\n",
       "       [ 0.01083269,  0.00145179, -0.0047613 , ...,  0.00376973,\n",
       "        -0.00278825, -0.01029548],\n",
       "       [-0.00495798, -0.00162349, -0.00528714, ..., -0.00860926,\n",
       "        -0.00086067,  0.00587347],\n",
       "       [ 0.00285894,  0.00052109,  0.00096583, ...,  0.00419195,\n",
       "        -0.00351418,  0.00922326]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = ica.fit_transform(X_std)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out target\n",
    "y = tweets['Is_Unreliable']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derive text vectors from word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_vectors(word_embeddings,\n",
    "                     word_index_dict,\n",
    "                     text_list,\n",
    "                     remove_stopwords = True,\n",
    "                     lowercase = True,\n",
    "                     lemmatize = True,\n",
    "                     add_start_end_tokens = True):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    for k in range(len(text_list)):\n",
    "        text = text_list[k]\n",
    "        text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "        text_vec = np.zeros(word_embeddings.shape[1])\n",
    "        words = word_tokenize(text)\n",
    "        tracker = 0 # to track whether we've encountered a word for which we have an embedding (in each tweet)\n",
    "        \n",
    "        if remove_stopwords:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                if word.lower() not in set(stopwords.words('english')):\n",
    "                    clean_words.append(word)\n",
    "            words = clean_words\n",
    "\n",
    "        if lowercase:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                clean_words.append(word.lower())\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if lemmatize:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                PoS_tag = pos_tag([word])[0][1]\n",
    "\n",
    "                # to change contractions to full word form\n",
    "                if word in contractions:\n",
    "                    word = contractions[word]\n",
    "\n",
    "                if PoS_tag[0].upper() in 'JNVR':\n",
    "                    word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                else:\n",
    "                    word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                clean_words.append(word)\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if add_start_end_tokens:\n",
    "            words = ['<START>'] + words + ['<END>']\n",
    "        \n",
    "        for i in range(len(words)):\n",
    "            word = words[i]\n",
    "            if word in word_index_dict:\n",
    "                word_embed_vec = word_embeddings[word_index_dict[word],:]\n",
    "                if tracker == 0:\n",
    "                    text_matrix = word_embed_vec\n",
    "                else:\n",
    "                    text_matrix = np.vstack((text_matrix, word_embed_vec))\n",
    "                    \n",
    "                # only increment if we have come across a word in the embeddings dictionary\n",
    "                tracker += 1\n",
    "                    \n",
    "        for j in range(len(text_vec)):\n",
    "            text_vec[j] = text_matrix[:,j].mean()\n",
    "            \n",
    "        if k == 0:\n",
    "            full_matrix = text_vec\n",
    "        else:\n",
    "            full_matrix = np.vstack((full_matrix, text_vec))\n",
    "            \n",
    "    return full_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_text_vectors(embeddings, cm.vocabulary, tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 250)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00020552, -0.00203316,  0.00065841, ..., -0.00060031,\n",
       "        -0.00249546,  0.00612142],\n",
       "       [-0.00072499, -0.00067602, -0.00032185, ..., -0.00017674,\n",
       "        -0.00245525,  0.00367647],\n",
       "       [-0.00508143, -0.00989502, -0.00360545, ...,  0.00160898,\n",
       "        -0.00029901,  0.00052407],\n",
       "       ...,\n",
       "       [ 0.02237961, -0.00173389, -0.00486746, ..., -0.00053517,\n",
       "        -0.00274448, -0.00737599],\n",
       "       [-0.00342082, -0.001821  , -0.00408193, ..., -0.00141228,\n",
       "        -0.00746923, -0.00443483],\n",
       "       [-0.00242631, -0.00174541,  0.06924709, ..., -0.00129166,\n",
       "        -0.00457395, -0.00423027]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, KFold, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipe = Pipeline([\n",
    "    ('classify', SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC hyperparams to optimize\n",
    "kernel = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "C = [0.001, 0.01, 0.1, 1, 10]\n",
    "# set up parameter grid\n",
    "params = {\n",
    "    'classify__kernel': kernel,\n",
    "    'classify__C': C\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CV scheme for inner and outer loops\n",
    "inner_cv = KFold(n_splits = 3, shuffle = True, random_state = 1)\n",
    "outer_cv = KFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "\n",
    "# Set up GridSearch for inner loop\n",
    "grid_SVC = GridSearchCV(pipe, params, cv = inner_cv)\n",
    "#grid_SVC.fit(X, y)\n",
    "\n",
    "# Nested CV scores\n",
    "scores = cross_validate(grid_SVC,\n",
    "                        X = X,\n",
    "                        y = y,\n",
    "                        cv = outer_cv,\n",
    "                        scoring = ['roc_auc', 'accuracy', 'f1', 'precision', 'recall'],\n",
    "                        return_estimator = True)\n",
    "auc = scores['test_roc_auc']\n",
    "accuracy = scores['test_accuracy']\n",
    "f1 = scores['test_f1']\n",
    "precision = scores['test_precision']\n",
    "recall = scores['test_recall']\n",
    "estimators = scores['estimator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.921175049468"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8607142857142855"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666969694348001"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.829839707707395"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9091408606261415"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classify__C': 10, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 10, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in estimators:\n",
    "    print(i.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
