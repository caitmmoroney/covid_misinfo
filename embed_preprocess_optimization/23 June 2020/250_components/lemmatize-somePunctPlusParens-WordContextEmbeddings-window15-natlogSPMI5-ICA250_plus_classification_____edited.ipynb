{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Word Context Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.decomposition import FastICA, TruncatedSVD, PCA, NMF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert contractions picked up by word_tokenize() into full words\n",
    "contractions = {\n",
    "    \"n't\": 'not',\n",
    "    \"'ve\": 'have',\n",
    "    \"'s\": 'is', # note that this will include possessive nouns\n",
    "    'gonna': 'going to',\n",
    "    'gotta': 'got to',\n",
    "    \"'d\": 'would',\n",
    "    \"'ll\": 'will',\n",
    "    \"'re\": 'are',\n",
    "    \"'m\": 'am',\n",
    "    'wanna': 'want to'\n",
    "}\n",
    "\n",
    "# to convert nltk_pos tags to wordnet-compatible PoS tags\n",
    "def convert_pos_wordnet(tag):\n",
    "    tag_abbr = tag[0].upper()\n",
    "    tag_dict = {\n",
    "        'J': wordnet.ADJ,\n",
    "        'N': wordnet.NOUN,\n",
    "        'V': wordnet.VERB,\n",
    "        'R': wordnet.ADV\n",
    "    }\n",
    "                \n",
    "    if tag_abbr in tag_dict:\n",
    "        return tag_dict[tag_abbr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextMatrix(TransformerMixin):\n",
    "    \n",
    "    # initialize class & private variables\n",
    "    def __init__(self,\n",
    "                 window_size = 4,\n",
    "                 remove_stopwords = True,\n",
    "                 add_start_end_tokens = True,\n",
    "                 lowercase = False,\n",
    "                 lemmatize = False,\n",
    "                 pmi = False,\n",
    "                 spmi_k = 1,\n",
    "                 laplace_smoothing = 0,\n",
    "                 pmi_positive = False,\n",
    "                 sppmi_k = 1):\n",
    "        \n",
    "        \"\"\" Params:\n",
    "                window_size: size of +/- context window (default = 4)\n",
    "                remove_stopwords: boolean, whether or not to remove NLTK English stopwords\n",
    "                add_start_end_tokens: boolean, whether or not to append <START> and <END> to the\n",
    "                beginning/end of each document in the corpus (default = True)\n",
    "                lowercase: boolean, whether or not to convert words to all lowercase\n",
    "                lemmatize: boolean, whether or not to lemmatize input text\n",
    "                pmi: boolean, whether or not to compute pointwise mutual information\n",
    "                pmi_positive: boolean, whether or not to compute positive PMI\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.add_start_end_tokens = add_start_end_tokens\n",
    "        self.lowercase = lowercase\n",
    "        self.lemmatize = lemmatize\n",
    "        self.pmi = pmi\n",
    "        self.spmi_k = spmi_k\n",
    "        self.laplace_smoothing = laplace_smoothing\n",
    "        self.pmi_positive = pmi_positive\n",
    "        self.sppmi_k = sppmi_k\n",
    "        self.corpus = None\n",
    "        self.clean_corpus = None\n",
    "        self.vocabulary = None\n",
    "        self.X = None\n",
    "        self.doc_terms_lists = None\n",
    "    \n",
    "    def fit(self, corpus, y = None):\n",
    "        \n",
    "        \"\"\" Learn the dictionary of all unique tokens for given corpus.\n",
    "        \n",
    "            Params:\n",
    "                corpus: list of strings\n",
    "            \n",
    "            Returns: self\n",
    "        \"\"\"\n",
    "        self.corpus = corpus\n",
    "        \n",
    "        term_dict = dict()\n",
    "        k = 0\n",
    "        corpus_words = []\n",
    "        clean_corpus = []\n",
    "        doc_terms_lists = []\n",
    "        detokenizer = TreebankWordDetokenizer()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        for text in corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "            \n",
    "            # detokenize trick taken from this StackOverflow post:\n",
    "            # https://stackoverflow.com/questions/21948019/python-untokenize-a-sentence\n",
    "            # and NLTK treebank documentation:\n",
    "            # https://www.nltk.org/_modules/nltk/tokenize/treebank.html\n",
    "            text = detokenizer.detokenize(words)\n",
    "            clean_corpus.append(text)\n",
    "            \n",
    "            [corpus_words.append(word) for word in words]\n",
    "            \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            doc_terms_lists.append(words)\n",
    "            \n",
    "        self.clean_corpus = clean_corpus\n",
    "        \n",
    "        self.doc_terms_lists = doc_terms_lists\n",
    "        \n",
    "        corpus_words = list(set(corpus_words))\n",
    "        \n",
    "        if self.add_start_end_tokens:\n",
    "            corpus_words = ['<START>'] + corpus_words + ['<END>']\n",
    "        \n",
    "        corpus_words = sorted(corpus_words)\n",
    "        \n",
    "        for el in corpus_words:\n",
    "            term_dict[el] = k\n",
    "            k += 1\n",
    "            \n",
    "        self.vocabulary = term_dict\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def transform(self, new_corpus = None, y = None):\n",
    "        \n",
    "        \"\"\" Compute the co-occurrence matrix for given corpus and window_size, using term dictionary\n",
    "            obtained with fit method.\n",
    "        \n",
    "            Returns: term-context co-occurrence matrix (shape: target terms by context terms) with\n",
    "            raw counts\n",
    "        \"\"\"\n",
    "        num_terms = len(self.vocabulary)\n",
    "        window = self.window_size\n",
    "        X = np.full((num_terms, num_terms), self.laplace_smoothing)\n",
    "        \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        if type(new_corpus) != list:\n",
    "            new_corpus = self.corpus\n",
    "        \n",
    "        for text in new_corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            for i in range(len(words)):\n",
    "                target = words[i]\n",
    "                \n",
    "                # check to see if target word is in the dictionary; if not, skip\n",
    "                if target in self.vocabulary:\n",
    "                    \n",
    "                    # grab index from dictionary\n",
    "                    target_dict_index = self.vocabulary[target]\n",
    "                    \n",
    "                    # find left-most and right-most window indices for each target word\n",
    "                    left_end_index = max(i - window, 0)\n",
    "                    right_end_index = min(i + window, len(words) - 1)\n",
    "                    \n",
    "                    # loop over all words within window\n",
    "                    # NOTE: this will include the target word; make sure to skip over it\n",
    "                    for j in range(left_end_index, right_end_index + 1):\n",
    "                        \n",
    "                        # skip \"context word\" where the \"context word\" index is equal to the\n",
    "                        # target word index\n",
    "                        if j != i:\n",
    "                            context_word = words[j]\n",
    "                            \n",
    "                            # check to see if context word is in the fitted dictionary; if\n",
    "                            # not, skip\n",
    "                            if context_word in self.vocabulary:\n",
    "                                X[target_dict_index, self.vocabulary[context_word]] += 1\n",
    "        \n",
    "        # if pmi = True, compute pmi matrix from word-context raw frequencies\n",
    "        # more concise code taken from this StackOverflow post:\n",
    "        # https://stackoverflow.com/questions/58701337/how-to-construct-ppmi-matrix-from-a-text-corpus\n",
    "        if self.pmi:\n",
    "            denom = X.sum()\n",
    "            col_sums = X.sum(axis = 0)\n",
    "            row_sums = X.sum(axis = 1)\n",
    "            \n",
    "            expected = np.outer(row_sums, col_sums)/denom\n",
    "            \n",
    "            X = X/expected\n",
    "            \n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(X.shape[1]):\n",
    "                \n",
    "                    if X[i,j] > 0:\n",
    "                        X[i,j] = np.log(X[i,j]) - np.log(self.spmi_k)\n",
    "                        \n",
    "                        if self.pmi_positive:\n",
    "                            X[i,j] = max(X[i,j] - np.log(self.sppmi_k), 0)\n",
    "        \n",
    "        # note that X is a dense matrix\n",
    "        self.X = X\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(lowercase = True, lemmatize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [\n",
    "    \"Coronavirus is a fake liberal hoax.\",\n",
    "    \"Trump won't do anything about coronavirus.\",\n",
    "    \"The liberal fake news media always blame Pres Trump.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ContextMatrix at 0x1a2629ecd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.fit(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <th>always</th>\n",
       "      <th>anything</th>\n",
       "      <th>blame</th>\n",
       "      <th>coronavirus</th>\n",
       "      <th>fake</th>\n",
       "      <th>hoax</th>\n",
       "      <th>liberal</th>\n",
       "      <th>medium</th>\n",
       "      <th>news</th>\n",
       "      <th>pres</th>\n",
       "      <th>trump</th>\n",
       "      <th>wont</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>always</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anything</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blame</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronavirus</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fake</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoax</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pres</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wont</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             .  <END>  <START>  always  anything  blame  coronavirus  fake  \\\n",
       ".            0      3        0       1         1      1            2     1   \n",
       "<END>        3      0        0       0         1      1            1     1   \n",
       "<START>      0      0        0       0         1      0            2     2   \n",
       "always       1      0        0       0         0      1            0     1   \n",
       "anything     1      1        1       0         0      0            1     0   \n",
       "blame        1      1        0       1         0      0            0     1   \n",
       "coronavirus  2      1        2       0         1      0            0     1   \n",
       "fake         1      1        2       1         0      1            1     0   \n",
       "hoax         1      1        1       0         0      0            1     1   \n",
       "liberal      1      1        2       1         0      0            1     2   \n",
       "medium       0      0        1       1         0      1            0     1   \n",
       "news         0      0        1       1         0      1            0     1   \n",
       "pres         1      1        0       1         0      1            0     0   \n",
       "trump        2      1        1       1         1      1            1     0   \n",
       "wont         1      1        1       0         1      0            1     0   \n",
       "\n",
       "             hoax  liberal  medium  news  pres  trump  wont  \n",
       ".               1        1       0     0     1      2     1  \n",
       "<END>           1        1       0     0     1      1     1  \n",
       "<START>         1        2       1     1     0      1     1  \n",
       "always          0        1       1     1     1      1     0  \n",
       "anything        0        0       0     0     0      1     1  \n",
       "blame           0        0       1     1     1      1     0  \n",
       "coronavirus     1        1       0     0     0      1     1  \n",
       "fake            1        2       1     1     0      0     0  \n",
       "hoax            0        1       0     0     0      0     0  \n",
       "liberal         1        0       1     1     0      0     0  \n",
       "medium          0        1       0     1     1      1     0  \n",
       "news            0        1       1     0     1      0     0  \n",
       "pres            0        0       1     1     0      1     0  \n",
       "trump           0        0       1     0     1      0     1  \n",
       "wont            0        0       0     0     0      1     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cm.transform(tweets), index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coronavirus fake liberal hoax.',\n",
       " 'trump wont anything coronavirus.',\n",
       " 'liberal fake news medium always blame pres trump.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.clean_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coronavirus is a fake liberal hoax.',\n",
       " \"Trump won't do anything about coronavirus.\",\n",
       " 'The liberal fake news media always blame Pres Trump.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train embeddings using tweets as corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('COVID19_Dataset-text_labels_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Unreliable</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 3, 6, 9</td>\n",
       "      <td>We are living in scary times in Canada. Gov’t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 6, 8, 9</td>\n",
       "      <td>Just as bad in Canada. In fact, our government...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 4, 9</td>\n",
       "      <td>It was only a matter of time before the mainst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8</td>\n",
       "      <td>Russia's taking no chances: Foreigners infecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8, 9</td>\n",
       "      <td>Although there is now a presumptive confirmed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BREAKING: Harvard classes will move online sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singularity University is hosting a FREE Virtu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus: how does it spread and what are t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stanford just cancelled classes for the rest o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tech conferences were cancelled in #Waterloo R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Is_Unreliable    Category  \\\n",
       "0                1  1, 3, 6, 9   \n",
       "1                1  1, 6, 8, 9   \n",
       "2                1     1, 4, 9   \n",
       "3                1        6, 8   \n",
       "4                1     6, 8, 9   \n",
       "..             ...         ...   \n",
       "555              0         NaN   \n",
       "556              0         NaN   \n",
       "557              0         NaN   \n",
       "558              0         NaN   \n",
       "559              0         NaN   \n",
       "\n",
       "                                                 Tweet  \n",
       "0    We are living in scary times in Canada. Gov’t ...  \n",
       "1    Just as bad in Canada. In fact, our government...  \n",
       "2    It was only a matter of time before the mainst...  \n",
       "3    Russia's taking no chances: Foreigners infecte...  \n",
       "4    Although there is now a presumptive confirmed ...  \n",
       "..                                                 ...  \n",
       "555  BREAKING: Harvard classes will move online sta...  \n",
       "556  Singularity University is hosting a FREE Virtu...  \n",
       "557  Coronavirus: how does it spread and what are t...  \n",
       "558  Stanford just cancelled classes for the rest o...  \n",
       "559  Tech conferences were cancelled in #Waterloo R...  \n",
       "\n",
       "[560 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(window_size = 15, lowercase = True, lemmatize = True, pmi = True, spmi_k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ContextMatrix at 0x1a2de19a50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.fit(tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_context_matrix = cm.transform(tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>#</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>,</th>\n",
       "      <th>-</th>\n",
       "      <th>--</th>\n",
       "      <th>.</th>\n",
       "      <th>...</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoomer</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>—</th>\n",
       "      <th>‘</th>\n",
       "      <th>’</th>\n",
       "      <th>“</th>\n",
       "      <th>”</th>\n",
       "      <th>❝real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>0.921891</td>\n",
       "      <td>-2.112382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.093170</td>\n",
       "      <td>-2.851110</td>\n",
       "      <td>-2.079986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.901818</td>\n",
       "      <td>0.401442</td>\n",
       "      <td>-0.332527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.336828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.033232</td>\n",
       "      <td>-0.862420</td>\n",
       "      <td>-1.940964</td>\n",
       "      <td>0.129509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>-2.112382</td>\n",
       "      <td>-0.651796</td>\n",
       "      <td>-2.478344</td>\n",
       "      <td>-2.511134</td>\n",
       "      <td>-2.041496</td>\n",
       "      <td>-1.849348</td>\n",
       "      <td>-1.808454</td>\n",
       "      <td>-1.757287</td>\n",
       "      <td>-3.159657</td>\n",
       "      <td>-3.046328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.178828</td>\n",
       "      <td>-1.385597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.258870</td>\n",
       "      <td>-1.867048</td>\n",
       "      <td>-1.872582</td>\n",
       "      <td>-2.947612</td>\n",
       "      <td>-2.863006</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.478344</td>\n",
       "      <td>-1.529221</td>\n",
       "      <td>1.210578</td>\n",
       "      <td>-1.750735</td>\n",
       "      <td>-2.340587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.841512</td>\n",
       "      <td>-0.706457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.176222</td>\n",
       "      <td>-2.103850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>-3.093170</td>\n",
       "      <td>-2.511134</td>\n",
       "      <td>1.210578</td>\n",
       "      <td>-1.594801</td>\n",
       "      <td>-1.783524</td>\n",
       "      <td>-2.373377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.711783</td>\n",
       "      <td>-0.739246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.209012</td>\n",
       "      <td>-2.136640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>-2.851110</td>\n",
       "      <td>-2.041496</td>\n",
       "      <td>-1.750735</td>\n",
       "      <td>-1.783524</td>\n",
       "      <td>-1.481746</td>\n",
       "      <td>-1.948996</td>\n",
       "      <td>-1.160887</td>\n",
       "      <td>-1.711795</td>\n",
       "      <td>-1.701160</td>\n",
       "      <td>-1.300149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126967</td>\n",
       "      <td>-1.818943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.898986</td>\n",
       "      <td>-1.794845</td>\n",
       "      <td>-1.849169</td>\n",
       "      <td>-1.489115</td>\n",
       "      <td>-1.809974</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.867048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.794845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.866204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>-1.033232</td>\n",
       "      <td>-1.872582</td>\n",
       "      <td>-2.176222</td>\n",
       "      <td>-2.209012</td>\n",
       "      <td>-1.849169</td>\n",
       "      <td>-1.888975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.560525</td>\n",
       "      <td>-0.437166</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056935</td>\n",
       "      <td>-0.808319</td>\n",
       "      <td>-0.879048</td>\n",
       "      <td>-0.651341</td>\n",
       "      <td>-0.372628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“</th>\n",
       "      <td>-0.862420</td>\n",
       "      <td>-2.947612</td>\n",
       "      <td>-2.103850</td>\n",
       "      <td>-2.136640</td>\n",
       "      <td>-1.489115</td>\n",
       "      <td>-1.123456</td>\n",
       "      <td>-0.335347</td>\n",
       "      <td>-1.722993</td>\n",
       "      <td>-0.587938</td>\n",
       "      <td>-0.474609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.380299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.879048</td>\n",
       "      <td>-0.599037</td>\n",
       "      <td>1.318151</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>”</th>\n",
       "      <td>-1.940964</td>\n",
       "      <td>-2.863006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.809974</td>\n",
       "      <td>-1.221172</td>\n",
       "      <td>-0.027598</td>\n",
       "      <td>-1.683507</td>\n",
       "      <td>-0.280188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.072549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.651341</td>\n",
       "      <td>1.318151</td>\n",
       "      <td>0.709610</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>❝real</th>\n",
       "      <td>0.129509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.372628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2325 rows × 2325 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              !         #         (         )         ,         -        --  \\\n",
       "!      0.921891 -2.112382  0.000000 -3.093170 -2.851110 -2.079986  0.000000   \n",
       "#     -2.112382 -0.651796 -2.478344 -2.511134 -2.041496 -1.849348 -1.808454   \n",
       "(      0.000000 -2.478344 -1.529221  1.210578 -1.750735 -2.340587  0.000000   \n",
       ")     -3.093170 -2.511134  1.210578 -1.594801 -1.783524 -2.373377  0.000000   \n",
       ",     -2.851110 -2.041496 -1.750735 -1.783524 -1.481746 -1.948996 -1.160887   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "‘      0.000000 -1.867048  0.000000  0.000000 -1.794845  0.000000  0.000000   \n",
       "’     -1.033232 -1.872582 -2.176222 -2.209012 -1.849169 -1.888975  0.000000   \n",
       "“     -0.862420 -2.947612 -2.103850 -2.136640 -1.489115 -1.123456 -0.335347   \n",
       "”     -1.940964 -2.863006  0.000000  0.000000 -1.809974 -1.221172 -0.027598   \n",
       "❝real  0.129509  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "              .       ...         1  ...    zombie      zone    zoomer  \\\n",
       "!     -1.901818  0.401442 -0.332527  ...  0.000000  0.000000  0.000000   \n",
       "#     -1.757287 -3.159657 -3.046328  ...  0.000000 -2.178828 -1.385597   \n",
       "(     -1.841512 -0.706457  0.000000  ...  0.000000  0.000000  0.000000   \n",
       ")     -1.711783 -0.739246  0.000000  ...  0.000000  0.000000  0.000000   \n",
       ",     -1.711795 -1.701160 -1.300149  ...  0.126967 -1.818943  0.000000   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "‘     -1.866204  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "’     -1.560525 -0.437166  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "“     -1.722993 -0.587938 -0.474609  ...  0.000000  0.000000  0.000000   \n",
       "”     -1.683507 -0.280188  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "❝real  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "\n",
       "       zuckerberg         —         ‘         ’         “         ”     ❝real  \n",
       "!             0.0 -1.336828  0.000000 -1.033232 -0.862420 -1.940964  0.129509  \n",
       "#             0.0 -2.258870 -1.867048 -1.872582 -2.947612 -2.863006  0.000000  \n",
       "(             0.0  0.000000  0.000000 -2.176222 -2.103850  0.000000  0.000000  \n",
       ")             0.0  0.000000  0.000000 -2.209012 -2.136640  0.000000  0.000000  \n",
       ",             0.0 -1.898986 -1.794845 -1.849169 -1.489115 -1.809974  0.000000  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "‘             0.0  0.000000  0.000000  0.056935  0.000000  0.000000  0.000000  \n",
       "’             0.0  0.000000  0.056935 -0.808319 -0.879048 -0.651341 -0.372628  \n",
       "“             0.0 -0.380299  0.000000 -0.879048 -0.599037  1.318151  0.000000  \n",
       "”             0.0 -0.072549  0.000000 -0.651341  1.318151  0.709610  0.000000  \n",
       "❝real         0.0  0.000000  0.000000 -0.372628  0.000000  0.000000  0.000000  \n",
       "\n",
       "[2325 rows x 2325 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(word_context_matrix, index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2325, 2325)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_context_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = FastICA(n_components = 2)\n",
    "std_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.12803289e-03, -1.55721006e-01],\n",
       "       [ 2.13618864e-01, -3.00140081e-01],\n",
       "       [-1.02953684e-02, -1.05313058e-01],\n",
       "       ...,\n",
       "       [-1.41612073e-02, -9.08840232e-02],\n",
       "       [-1.53887982e-02, -5.38277271e-02],\n",
       "       [ 1.94863585e-05,  6.27619433e-03]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std = std_scaler.fit_transform(word_context_matrix)\n",
    "\n",
    "matrix = ica.fit_transform(X_std)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comp 1</th>\n",
       "      <th>Comp 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>0.005128</td>\n",
       "      <td>-0.155721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>0.213619</td>\n",
       "      <td>-0.300140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>-0.010295</td>\n",
       "      <td>-0.105313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>-0.009623</td>\n",
       "      <td>-0.110693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.205428</td>\n",
       "      <td>-0.253387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>-0.010305</td>\n",
       "      <td>-0.012450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>0.059803</td>\n",
       "      <td>-0.229134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“</th>\n",
       "      <td>-0.014161</td>\n",
       "      <td>-0.090884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>”</th>\n",
       "      <td>-0.015389</td>\n",
       "      <td>-0.053828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>❝real</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.006276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2325 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Comp 1    Comp 2\n",
       "!      0.005128 -0.155721\n",
       "#      0.213619 -0.300140\n",
       "(     -0.010295 -0.105313\n",
       ")     -0.009623 -0.110693\n",
       ",      0.205428 -0.253387\n",
       "...         ...       ...\n",
       "‘     -0.010305 -0.012450\n",
       "’      0.059803 -0.229134\n",
       "“     -0.014161 -0.090884\n",
       "”     -0.015389 -0.053828\n",
       "❝real  0.000019  0.006276\n",
       "\n",
       "[2325 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(matrix,\n",
    "                  index = cm.vocabulary,\n",
    "                  columns = ['Comp {}'.format(i+1) for i in range(2)])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 62222 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 62222 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = [key for key in cm.vocabulary.keys()]\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    \n",
    "    #if re.match('^co[rv]', word):\n",
    "    \n",
    "        x = df['Comp 1'][i]\n",
    "        y = df['Comp 2'][i]\n",
    "\n",
    "        plt.scatter(x, y)\n",
    "        plt.text(x, y, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set word embeddings for text classification\n",
    "ica = FastICA(n_components = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00138258, -0.00593232,  0.00448819, ..., -0.00287388,\n",
       "        -0.00942495,  0.00512568],\n",
       "       [ 0.00447117,  0.01771247, -0.01126077, ..., -0.00814784,\n",
       "         0.07552113, -0.00364746],\n",
       "       [-0.01112154,  0.04248045, -0.00412459, ..., -0.02254523,\n",
       "        -0.00661443, -0.01093961],\n",
       "       ...,\n",
       "       [ 0.00072296, -0.00212229, -0.00467142, ...,  0.00177256,\n",
       "        -0.00125594,  0.00355617],\n",
       "       [-0.00016979, -0.00692544,  0.00386728, ...,  0.00021324,\n",
       "        -0.00637481, -0.00477102],\n",
       "       [ 0.00282799, -0.00044125,  0.0006292 , ...,  0.00070019,\n",
       "         0.00188922, -0.00167793]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = ica.fit_transform(X_std)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out target\n",
    "y = tweets['Is_Unreliable']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derive text vectors from word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_vectors(word_embeddings,\n",
    "                     word_index_dict,\n",
    "                     text_list,\n",
    "                     remove_stopwords = True,\n",
    "                     lowercase = True,\n",
    "                     lemmatize = True,\n",
    "                     add_start_end_tokens = True):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    for k in range(len(text_list)):\n",
    "        text = text_list[k]\n",
    "        text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "        text_vec = np.zeros(word_embeddings.shape[1])\n",
    "        words = word_tokenize(text)\n",
    "        tracker = 0 # to track whether we've encountered a word for which we have an embedding (in each tweet)\n",
    "        \n",
    "        if remove_stopwords:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                if word.lower() not in set(stopwords.words('english')):\n",
    "                    clean_words.append(word)\n",
    "            words = clean_words\n",
    "\n",
    "        if lowercase:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                clean_words.append(word.lower())\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if lemmatize:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                PoS_tag = pos_tag([word])[0][1]\n",
    "\n",
    "                # to change contractions to full word form\n",
    "                if word in contractions:\n",
    "                    word = contractions[word]\n",
    "\n",
    "                if PoS_tag[0].upper() in 'JNVR':\n",
    "                    word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                else:\n",
    "                    word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                clean_words.append(word)\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if add_start_end_tokens:\n",
    "            words = ['<START>'] + words + ['<END>']\n",
    "        \n",
    "        for i in range(len(words)):\n",
    "            word = words[i]\n",
    "            if word in word_index_dict:\n",
    "                word_embed_vec = word_embeddings[word_index_dict[word],:]\n",
    "                if tracker == 0:\n",
    "                    text_matrix = word_embed_vec\n",
    "                else:\n",
    "                    text_matrix = np.vstack((text_matrix, word_embed_vec))\n",
    "                    \n",
    "                # only increment if we have come across a word in the embeddings dictionary\n",
    "                tracker += 1\n",
    "                    \n",
    "        for j in range(len(text_vec)):\n",
    "            text_vec[j] = text_matrix[:,j].mean()\n",
    "            \n",
    "        if k == 0:\n",
    "            full_matrix = text_vec\n",
    "        else:\n",
    "            full_matrix = np.vstack((full_matrix, text_vec))\n",
    "            \n",
    "    return full_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_text_vectors(embeddings, cm.vocabulary, tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 250)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00373922, -0.00184515,  0.01354492, ..., -0.0043836 ,\n",
       "        -0.00760998, -0.00164242],\n",
       "       [ 0.01501424,  0.0071234 ,  0.00061878, ..., -0.0087137 ,\n",
       "        -0.01754812, -0.00075705],\n",
       "       [-0.00061213, -0.00230069,  0.00355722, ...,  0.00449083,\n",
       "        -0.00399046,  0.00044685],\n",
       "       ...,\n",
       "       [ 0.00135668, -0.00677734,  0.00308439, ...,  0.00370106,\n",
       "         0.00470409, -0.002444  ],\n",
       "       [-0.00236124, -0.00149181,  0.00182924, ...,  0.17492132,\n",
       "         0.00220718, -0.00447817],\n",
       "       [-0.00070351, -0.00260353,  0.002351  , ..., -0.00071871,\n",
       "        -0.00195615, -0.00157719]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, KFold, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipe = Pipeline([\n",
    "    ('classify', SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC hyperparams to optimize\n",
    "kernel = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "C = [0.001, 0.01, 0.1, 1, 10]\n",
    "# set up parameter grid\n",
    "params = {\n",
    "    'classify__kernel': kernel,\n",
    "    'classify__C': C\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CV scheme for inner and outer loops\n",
    "inner_cv = KFold(n_splits = 3, shuffle = True, random_state = 1)\n",
    "outer_cv = KFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "\n",
    "# Set up GridSearch for inner loop\n",
    "grid_SVC = GridSearchCV(pipe, params, cv = inner_cv)\n",
    "#grid_SVC.fit(X, y)\n",
    "\n",
    "# Nested CV scores\n",
    "scores = cross_validate(grid_SVC,\n",
    "                        X = X,\n",
    "                        y = y,\n",
    "                        cv = outer_cv,\n",
    "                        scoring = ['roc_auc', 'accuracy', 'f1', 'precision', 'recall'],\n",
    "                        return_estimator = True)\n",
    "auc = scores['test_roc_auc']\n",
    "accuracy = scores['test_accuracy']\n",
    "f1 = scores['test_f1']\n",
    "precision = scores['test_precision']\n",
    "recall = scores['test_recall']\n",
    "estimators = scores['estimator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8909941156172865"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8017857142857142"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8155749653199823"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7625124995370542"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8813463744106027"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classify__C': 1, 'classify__kernel': 'sigmoid'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__C': 1, 'classify__kernel': 'rbf'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in estimators:\n",
    "    print(i.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
