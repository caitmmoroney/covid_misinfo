{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv(r'Dataset/Dataset_13.05.2020_11.18am_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = np.asarray(file['Tweet'].copy())\n",
    "targets = np.asarray(file['Is_Unreliable'].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk.tokenize.casual import TweetTokenizer\n",
    "# # from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words = stopwords.words('english')\n",
    "# print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560,)\n"
     ]
    }
   ],
   "source": [
    "# tweet_tokens = list()\n",
    "# for i in tweets:\n",
    "#     tweet_tokens.append(TweetTokenizer().tokenize(i))\n",
    "# tweet_tokens = np.asarray(tweet_tokens)\n",
    "# print(tweet_tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxi = 0\n",
    "# for i in tweet_tokens:\n",
    "#     maxi = max(maxi, len(i))\n",
    "# print(maxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a lot of RAM (not possible in personal computer)\n",
    "# from gensim.models import KeyedVectors\n",
    "# word2vec_filename = r'Embeddings/GoogleNews-vectors-negative300.bin'\n",
    "# word2vec = KeyedVectors.load_word2vec_format(word2vec_filename, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_embeddings = np.load(r'Dataset/Tweet_Embeddings_Word2Vec_13.05.2020_2.41pm_1.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560,)\n",
      "(15, 300)\n"
     ]
    }
   ],
   "source": [
    "print(tweet_embeddings.shape)\n",
    "print(tweet_embeddings[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560, 300)\n",
      "float64\n",
      "(560,)\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "X = list()\n",
    "for tweet in tweet_embeddings:\n",
    "    embeddings = np.mean(tweet, axis=0, dtype=np.float64)\n",
    "    X.append(embeddings)\n",
    "X = np.asarray(X)\n",
    "print(X.shape)\n",
    "print(X.dtype)\n",
    "\n",
    "y = targets\n",
    "print(y.shape)\n",
    "print(y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.svm import LinearSVC, SVC, OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = np.arange(y.shape[0])\n",
    "# np.random.shuffle(idx)\n",
    "\n",
    "# # Create folds\n",
    "# plt.figure(figsize=(10,10))\n",
    "# folds = StratifiedKFold(n_splits=3, shuffle=True, random_state = 5)\n",
    "# # Go through folds\n",
    "# for trn_idx, val_idx in folds.split(X, y):\n",
    "#     # Stack training target and validation target and plot them\n",
    "#     plt.plot(np.hstack((y[idx[trn_idx]], y[idx[val_idx]])))\n",
    "# plt.title(\"StratifiedKFold Shuffle=True ?\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.9463806970509383 0.949238578680203 0.9257425742574258 0.9739583333333334 0.945542702578269\n",
      "Test :  0.8288770053475936 0.8260869565217391 0.7916666666666666 0.8636363636363636 0.8308080808080809\n",
      "Train:  0.935656836461126 0.9333333333333333 0.9333333333333333 0.9333333333333333 0.9355785837651123\n",
      "Test :  0.8288770053475936 0.8383838383838385 0.8469387755102041 0.83 0.8287931034482758\n",
      "Train:  0.9411764705882353 0.9427083333333334 0.923469387755102 0.9627659574468085 0.9410603980782429\n",
      "Test :  0.8387096774193549 0.8333333333333333 0.8522727272727273 0.8152173913043478 0.838459759481961\n",
      "\n",
      "Train:  0.9410713347001 0.9417600817822899 0.9275150984486205 0.9566858747044917 0.9407272281405414\n",
      "Test :  0.8321545627048473 0.8326013760796368 0.8302927231498659 0.8362845849802372 0.832686981246106\n"
     ]
    }
   ],
   "source": [
    "# idx = np.arange(y.shape[0])\n",
    "# np.random.shuffle(idx)\n",
    "\n",
    "# kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
    "\n",
    "# a_score, f_score, p_score, r_score, roc_score = list(), list(), list(), list(), list()\n",
    "# t_a_score, t_f_score, t_p_score, t_r_score, t_roc_score = list(), list(), list(), list(), list()\n",
    "\n",
    "# for train_index, test_index in kfold.split(X, y):\n",
    "#     X_train, y_train = X[idx[train_index]], y[idx[train_index]]\n",
    "#     X_test, y_test = X[idx[test_index]], y[idx[test_index]]\n",
    "\n",
    "#     model = SVC(random_state=0)\n",
    "#     model.fit(X_train, y_train)\n",
    "#     preds = model.predict(X_test)\n",
    "#     train_preds = model.predict(X_train)\n",
    "#     t_a_score.append(accuracy_score(y_train, train_preds))\n",
    "#     t_f_score.append(f1_score(y_train, train_preds)), t_p_score.append(precision_score(y_train, train_preds)), t_r_score.append(recall_score(y_train, train_preds))\n",
    "#     t_roc_score.append(roc_auc_score(y_train, train_preds))\n",
    "#     a_score.append(accuracy_score(y_test, preds))\n",
    "#     f_score.append(f1_score(y_test, preds)), p_score.append(precision_score(y_test, preds)), r_score.append(recall_score(y_test, preds))\n",
    "#     roc_score.append(roc_auc_score(y_test, preds))\n",
    "#     print('Train: ', t_a_score[-1], t_f_score[-1], t_p_score[-1], t_r_score[-1], t_roc_score[-1])\n",
    "#     print('Test : ', a_score[-1], f_score[-1], p_score[-1], r_score[-1], roc_score[-1])\n",
    "\n",
    "# print('')\n",
    "# print('Train: ', sum(t_a_score)/len(t_a_score), sum(t_f_score)/len(t_f_score), sum(t_p_score)/len(t_p_score), sum(t_r_score)/len(t_r_score), sum(t_roc_score)/len(t_roc_score))\n",
    "# print('Test : ', sum(a_score)/len(a_score), sum(f_score)/len(f_score), sum(p_score)/len(p_score), sum(r_score)/len(r_score), sum(roc_score)/len(roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts:  93 0.5 88 0.23529411764705882\n",
      "Train:  0.5 0.6666666666666666 1.0 0.5\n",
      "Test :  0.7272727272727273 0.43956043956043955 0.45454545454545453 0.425531914893617\n",
      "Counts:  93 0.49732620320855614 90 0.24128686327077747\n",
      "Train:  0.49732620320855614 0.6642857142857143 1.0 0.49732620320855614\n",
      "Test :  0.7292225201072386 0.44808743169398907 0.45555555555555555 0.44086021505376344\n",
      "Counts:  92 0.4919786096256685 102 0.2734584450402145\n",
      "Train:  0.4919786096256685 0.6594982078853047 1.0 0.4919786096256685\n",
      "Test :  0.739946380697051 0.5025641025641026 0.4803921568627451 0.5268817204301075\n",
      "\n",
      "Train:  0.49643493761140817 0.6634835296125619 1.0 0.49643493761140817\n",
      "Test :  0.7321472093590057 0.46340399127284376 0.46349772232125175 0.46442461679249597\n"
     ]
    }
   ],
   "source": [
    "# # One-class SVM on class=1 as training data\n",
    "\n",
    "# kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
    "\n",
    "# a_score, f_score, p_score, r_score, roc_score = list(), list(), list(), list(), list()\n",
    "# t_a_score, t_f_score, t_p_score, t_r_score, t_roc_score = list(), list(), list(), list(), list()\n",
    "\n",
    "# for train_index, test_index in kfold.split(X[y == 1], y[y == 1]):\n",
    "#     X_train, y_train = X[y == 1][train_index], y[y == 1][train_index]\n",
    "#     X_test, y_test = np.concatenate((X[y == 1][test_index], X[y == 0])), np.concatenate((y[y == 1][test_index], y[y == 0]))\n",
    "# #     print(X_train.shape)\n",
    "# #     print(y_train.shape)\n",
    "# #     print(X_test.shape)\n",
    "# #     print(y_test.shape)\n",
    "# #     print(sum(y_train))\n",
    "# #     print(sum(y_test))\n",
    "\n",
    "#     model = OneClassSVM()\n",
    "#     model.fit(X_train)\n",
    "#     preds = model.predict(X_test)\n",
    "#     train_preds = model.predict(X_train)\n",
    "#     preds[preds == -1] = 0\n",
    "#     train_preds[train_preds == -1] = 0\n",
    "#     print('Counts: ', sum(train_preds), sum(train_preds)/len(train_preds), sum(preds), sum(preds)/len(preds))\n",
    "#     t_a_score.append(accuracy_score(y_train, train_preds))\n",
    "#     t_f_score.append(f1_score(y_train, train_preds)), t_p_score.append(precision_score(y_train, train_preds)), t_r_score.append(recall_score(y_train, train_preds))\n",
    "#     a_score.append(accuracy_score(y_test, preds))\n",
    "#     f_score.append(f1_score(y_test, preds)), p_score.append(precision_score(y_test, preds)), r_score.append(recall_score(y_test, preds))\n",
    "#     print('Train: ', t_a_score[-1], t_f_score[-1], t_p_score[-1], t_r_score[-1])\n",
    "#     print('Test : ', a_score[-1], f_score[-1], p_score[-1], r_score[-1])\n",
    "\n",
    "# print('')\n",
    "# print('Train: ', sum(t_a_score)/len(t_a_score), sum(t_f_score)/len(t_f_score), sum(t_p_score)/len(t_p_score), sum(t_r_score)/len(t_r_score))\n",
    "# print('Test : ', sum(a_score)/len(a_score), sum(f_score)/len(f_score), sum(p_score)/len(p_score), sum(r_score)/len(r_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts:  92 0.4946236559139785 150 0.40106951871657753\n",
      "Train:  0.5053763440860215\n",
      "Test :  0.35294117647058826 0.4372093023255814 0.6266666666666667 0.3357142857142857\n",
      "Counts:  93 0.49732620320855614 122 0.32707774798927614\n",
      "Train:  0.5026737967914439\n",
      "Test :  0.3512064343163539 0.39800995024875624 0.6557377049180327 0.2857142857142857\n",
      "Counts:  93 0.49732620320855614 133 0.35656836461126007\n",
      "Train:  0.5026737967914439\n",
      "Test :  0.35924932975871315 0.4213075060532688 0.6541353383458647 0.3107142857142857\n",
      "\n",
      "Train:  0.5035746458896364\n",
      "Test :  0.3544656468485518 0.4188422528758688 0.6455132366435214 0.3107142857142857\n"
     ]
    }
   ],
   "source": [
    "# # One-class SVM on class=0 as training data\n",
    "\n",
    "# kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
    "\n",
    "# a_score, f_score, p_score, r_score, roc_score = list(), list(), list(), list(), list()\n",
    "# t_a_score, t_f_score, t_p_score, t_r_score, t_roc_score = list(), list(), list(), list(), list()\n",
    "\n",
    "# for train_index, test_index in kfold.split(X[y == 0], y[y == 0]):\n",
    "#     X_train, y_train = X[y == 0][train_index], y[y == 0][train_index]\n",
    "#     X_test, y_test = np.concatenate((X[y == 0][test_index], X[y == 1])), np.concatenate((y[y == 0][test_index], y[y == 1]))\n",
    "# #     print(X_train.shape)\n",
    "# #     print(y_train.shape)\n",
    "# #     print(X_test.shape)\n",
    "# #     print(y_test.shape)\n",
    "# #     print(sum(y_train))\n",
    "# #     print(sum(y_test))\n",
    "\n",
    "#     model = OneClassSVM()\n",
    "#     model.fit(X_train)\n",
    "#     preds = model.predict(X_test)\n",
    "#     train_preds = model.predict(X_train)\n",
    "#     preds[preds == 1] = 0\n",
    "#     train_preds[train_preds == 1] = 0\n",
    "#     preds[preds == -1] = 1\n",
    "#     train_preds[train_preds == -1] = 1\n",
    "#     print('Counts: ', sum(train_preds), sum(train_preds)/len(train_preds), sum(preds), sum(preds)/len(preds))\n",
    "#     t_a_score.append(accuracy_score(y_train, train_preds))\n",
    "# #     t_f_score.append(f1_score(y_train, train_preds)), t_p_score.append(precision_score(y_train, train_preds)), t_r_score.append(recall_score(y_train, train_preds))\n",
    "#     a_score.append(accuracy_score(y_test, preds))\n",
    "#     f_score.append(f1_score(y_test, preds)), p_score.append(precision_score(y_test, preds)), r_score.append(recall_score(y_test, preds))\n",
    "# #     print('Train: ', t_a_score[-1], t_f_score[-1], t_p_score[-1], t_r_score[-1])\n",
    "#     print('Train: ', t_a_score[-1])\n",
    "#     print('Test : ', a_score[-1], f_score[-1], p_score[-1], r_score[-1])\n",
    "\n",
    "# print('')\n",
    "# # print('Train: ', sum(t_a_score)/len(t_a_score), sum(t_f_score)/len(t_f_score), sum(t_p_score)/len(t_p_score), sum(t_r_score)/len(t_r_score))\n",
    "# print('Train: ', sum(t_a_score)/len(t_a_score))\n",
    "# print('Test : ', sum(a_score)/len(a_score), sum(f_score)/len(f_score), sum(p_score)/len(p_score), sum(r_score)/len(r_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts:  145 0.7795698924731183 174 0.46524064171123\n",
      "Train:  0.7795698924731183 0.8761329305135952 1.0 0.7795698924731183\n",
      "Test :  0.6524064171122995 0.5149253731343284 0.39655172413793105 0.7340425531914894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:02,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts:  166 0.8877005347593583 222 0.5951742627345844\n",
      "Train:  0.8877005347593583 0.9405099150141643 1.0 0.8877005347593583\n",
      "Test :  0.5844504021447721 0.5079365079365079 0.36036036036036034 0.8602150537634409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:04,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts:  147 0.786096256684492 179 0.47989276139410186\n",
      "Train:  0.786096256684492 0.8802395209580839 1.0 0.786096256684492\n",
      "Test :  0.6621983914209115 0.5367647058823529 0.40782122905027934 0.7849462365591398\n",
      "\n",
      "Train:  0.8177888946389894 0.8989607888286145 1.0 0.8177888946389894\n",
      "Test :  0.6330184035593277 0.5198755289843965 0.38824443784952356 0.7930679478380233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# One-class SVM with search on class=1 as training data\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
    "\n",
    "a_score, f_score, p_score, r_score, roc_score = list(), list(), list(), list(), list()\n",
    "t_a_score, t_f_score, t_p_score, t_r_score, t_roc_score = list(), list(), list(), list(), list()\n",
    "\n",
    "for train_index, test_index in tqdm(kfold.split(X[y == 1], y[y == 1])):\n",
    "    X_train, y_train = X[y == 1][train_index], y[y == 1][train_index]\n",
    "    X_test, y_test = np.concatenate((X[y == 1][test_index], X[y == 0])), np.concatenate((y[y == 1][test_index], y[y == 0]))\n",
    "#     print(X_train.shape)\n",
    "#     print(y_train.shape)\n",
    "#     print(X_test.shape)\n",
    "#     print(y_test.shape)\n",
    "#     print(sum(y_train))\n",
    "#     print(sum(y_test))\n",
    "\n",
    "    model = OneClassSVM()\n",
    "    model_acc = 0\n",
    "    for kernel in ('linear', 'poly', 'rbf', 'sigmoid'):\n",
    "        for nu in (0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0):\n",
    "            clf_search = OneClassSVM(kernel = kernel, nu = nu)\n",
    "            clf_search.fit(X_train)\n",
    "            clf_train_preds = clf_search.predict(X_train)\n",
    "            clf_train_preds[clf_train_preds == -1] = 0\n",
    "#             if (accuracy_score(y_train, clf_train_preds) > model_acc):\n",
    "#                 model_acc = accuracy_score(y_train, clf_train_preds)\n",
    "#                 model = clf_search\n",
    "            clf_preds = clf_search.predict(X_test)\n",
    "            clf_preds[clf_preds == -1] = 0\n",
    "#             if (accuracy_score(y_test, clf_preds) > model_acc):\n",
    "#                 model_acc = accuracy_score(y_test, clf_preds)\n",
    "#                 model = clf_search\n",
    "            if (accuracy_score(y_test, clf_preds)*accuracy_score(y_train, clf_train_preds) > model_acc):\n",
    "                model_acc = accuracy_score(y_test, clf_preds)*accuracy_score(y_train, clf_train_preds)\n",
    "                model = clf_search\n",
    "    model.fit(X_train)\n",
    "    preds = model.predict(X_test)\n",
    "    train_preds = model.predict(X_train)\n",
    "    preds[preds == -1] = 0\n",
    "    train_preds[train_preds == -1] = 0\n",
    "    print('Counts: ', sum(train_preds), sum(train_preds)/len(train_preds), sum(preds), sum(preds)/len(preds))\n",
    "    t_a_score.append(accuracy_score(y_train, train_preds))\n",
    "    t_f_score.append(f1_score(y_train, train_preds)), t_p_score.append(precision_score(y_train, train_preds)), t_r_score.append(recall_score(y_train, train_preds))\n",
    "    a_score.append(accuracy_score(y_test, preds))\n",
    "    f_score.append(f1_score(y_test, preds)), p_score.append(precision_score(y_test, preds)), r_score.append(recall_score(y_test, preds))\n",
    "    print('Train: ', t_a_score[-1], t_f_score[-1], t_p_score[-1], t_r_score[-1])\n",
    "    print('Test : ', a_score[-1], f_score[-1], p_score[-1], r_score[-1])\n",
    "\n",
    "print('')\n",
    "print('Train: ', sum(t_a_score)/len(t_a_score), sum(t_f_score)/len(t_f_score), sum(t_p_score)/len(t_p_score), sum(t_r_score)/len(t_r_score))\n",
    "print('Test : ', sum(a_score)/len(a_score), sum(f_score)/len(f_score), sum(p_score)/len(p_score), sum(r_score)/len(r_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts:  37 0.1989247311827957 173 0.4625668449197861\n",
      "Train:  0.8010752688172043\n",
      "Test :  0.5427807486631016 0.6225165562913907 0.815028901734104 0.5035714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:02,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts:  36 0.1925133689839572 170 0.45576407506702415\n",
      "Train:  0.8074866310160428\n",
      "Test :  0.5495978552278821 0.6266666666666666 0.8294117647058824 0.5035714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:04,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts:  45 0.24064171122994651 223 0.5978552278820375\n",
      "Train:  0.7593582887700535\n",
      "Test :  0.6005361930294906 0.7037773359840954 0.7937219730941704 0.6321428571428571\n",
      "\n",
      "Train:  0.7893067295344335\n",
      "Test :  0.5643049323068247 0.6509868529807176 0.812720879844719 0.5464285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# One-class SVM with search with class=0 training data\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
    "\n",
    "a_score, f_score, p_score, r_score, roc_score = list(), list(), list(), list(), list()\n",
    "t_a_score, t_f_score, t_p_score, t_r_score, t_roc_score = list(), list(), list(), list(), list()\n",
    "\n",
    "for train_index, test_index in tqdm(kfold.split(X[y == 0], y[y == 0])):\n",
    "    X_train, y_train = X[y == 0][train_index], y[y == 0][train_index]\n",
    "    X_test, y_test = np.concatenate((X[y == 0][test_index], X[y == 1])), np.concatenate((y[y == 0][test_index], y[y == 1]))\n",
    "#     print(X_train.shape)\n",
    "#     print(y_train.shape)\n",
    "#     print(X_test.shape)\n",
    "#     print(y_test.shape)\n",
    "#     print(sum(y_train))\n",
    "#     print(sum(y_test))\n",
    "\n",
    "#     clf = OneClassSVM()\n",
    "#     params = {\n",
    "#         'kernel' : ('linear', 'poly', 'rbf', 'sigmoid'),\n",
    "#         'nu' : (0.1, 0.3, 0.7, 0.9)\n",
    "#     }\n",
    "#     model = GridSearchCV(clf, params, scoring='accuracy')\n",
    "#     model.fit(X_train)\n",
    "#     print(model.best_estimator_)\n",
    "    model = OneClassSVM()\n",
    "    model_acc = 0\n",
    "    for kernel in ('linear', 'poly', 'rbf', 'sigmoid'):\n",
    "        for nu in (0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0):\n",
    "            clf_search = OneClassSVM(kernel = kernel, nu = nu, max_iter=-1, tol=1e-5)\n",
    "            clf_search.fit(X_train)\n",
    "            clf_train_preds = clf_search.predict(X_train)\n",
    "            clf_train_preds[clf_train_preds == 1] = 0\n",
    "            clf_train_preds[clf_train_preds == -1] = 1\n",
    "#             if (accuracy_score(y_train, clf_train_preds) > model_acc):\n",
    "#                 model_acc = accuracy_score(y_train, clf_train_preds)\n",
    "#                 model = clf_search\n",
    "            clf_preds = clf_search.predict(X_test)\n",
    "            clf_preds[clf_preds == 1] = 0\n",
    "            clf_preds[clf_preds == -1] = 1\n",
    "#             if (accuracy_score(y_test, clf_preds) > model_acc):\n",
    "#                 model_acc = accuracy_score(y_test, clf_preds)\n",
    "#                 model = clf_search\n",
    "            if (accuracy_score(y_test, clf_preds)*accuracy_score(y_train, clf_train_preds) > model_acc):\n",
    "                model_acc = accuracy_score(y_test, clf_preds)*accuracy_score(y_train, clf_train_preds)\n",
    "                model = clf_search\n",
    "    model.fit(X_train)\n",
    "    preds = model.predict(X_test)\n",
    "    train_preds = model.predict(X_train)\n",
    "    preds[preds == 1] = 0\n",
    "    train_preds[train_preds == 1] = 0\n",
    "    preds[preds == -1] = 1\n",
    "    train_preds[train_preds == -1] = 1\n",
    "    print('Counts: ', sum(train_preds), sum(train_preds)/len(train_preds), sum(preds), sum(preds)/len(preds))\n",
    "    t_a_score.append(accuracy_score(y_train, train_preds))\n",
    "#     t_f_score.append(f1_score(y_train, train_preds)), t_p_score.append(precision_score(y_train, train_preds)), t_r_score.append(recall_score(y_train, train_preds))\n",
    "    a_score.append(accuracy_score(y_test, preds))\n",
    "    f_score.append(f1_score(y_test, preds)), p_score.append(precision_score(y_test, preds)), r_score.append(recall_score(y_test, preds))\n",
    "#     print('Train: ', t_a_score[-1], t_f_score[-1], t_p_score[-1], t_r_score[-1])\n",
    "    print('Train: ', t_a_score[-1])\n",
    "    print('Test : ', a_score[-1], f_score[-1], p_score[-1], r_score[-1])\n",
    "\n",
    "print('')\n",
    "# print('Train: ', sum(t_a_score)/len(t_a_score), sum(t_f_score)/len(t_f_score), sum(t_p_score)/len(t_p_score), sum(t_r_score)/len(t_r_score))\n",
    "print('Train: ', sum(t_a_score)/len(t_a_score))\n",
    "print('Test : ', sum(a_score)/len(a_score), sum(f_score)/len(f_score), sum(p_score)/len(p_score), sum(r_score)/len(r_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn\n",
    "# sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:07,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts:  125 0.6720430107526881 155 0.4144385026737968\n",
      "Train:  0.6720430107526881 0.8038585209003216 1.0 0.6720430107526881\n",
      "Test :  0.6229946524064172 0.43373493975903615 0.34838709677419355 0.574468085106383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:14,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts:  148 0.7914438502673797 262 0.7024128686327078\n",
      "Train:  0.7914438502673797 0.8835820895522388 1.0 0.7914438502673797\n",
      "Test :  0.42359249329758714 0.3943661971830987 0.26717557251908397 0.7526881720430108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:21,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts:  153 0.8181818181818182 255 0.6836461126005362\n",
      "Train:  0.8181818181818182 0.9 1.0 0.8181818181818182\n",
      "Test :  0.47989276139410186 0.4425287356321839 0.30196078431372547 0.8279569892473119\n",
      "\n",
      "Train:  0.7605562264006287 0.8624802034841869 1.0 0.7605562264006287\n",
      "Test :  0.5088266356993687 0.42354329085810627 0.3058411512023343 0.7183710821322352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# # One-class Isolation Forest with search on class=1 as training data\n",
    "\n",
    "# kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
    "\n",
    "# a_score, f_score, p_score, r_score, roc_score = list(), list(), list(), list(), list()\n",
    "# t_a_score, t_f_score, t_p_score, t_r_score, t_roc_score = list(), list(), list(), list(), list()\n",
    "\n",
    "# for train_index, test_index in tqdm(kfold.split(X[y == 1], y[y == 1])):\n",
    "#     X_train, y_train = X[y == 1][train_index], y[y == 1][train_index]\n",
    "#     X_test, y_test = np.concatenate((X[y == 1][test_index], X[y == 0])), np.concatenate((y[y == 1][test_index], y[y == 0]))\n",
    "# #     print(X_train.shape)\n",
    "# #     print(y_train.shape)\n",
    "# #     print(X_test.shape)\n",
    "# #     print(y_test.shape)\n",
    "# #     print(sum(y_train))\n",
    "# #     print(sum(y_test))\n",
    "\n",
    "#     model = IsolationForest()\n",
    "#     model_acc = 0\n",
    "#     for n_est in (1, 5, 10, 50, 100, 200, 300, 500, 700, 1000):\n",
    "#         clf_search = IsolationForest(n_estimators = n_est)\n",
    "#         clf_search.fit(X_train)\n",
    "#         clf_train_preds = clf_search.predict(X_train)\n",
    "#         clf_train_preds[clf_train_preds == -1] = 0\n",
    "# #         if (accuracy_score(y_train, clf_train_preds) > model_acc):\n",
    "# #             model_acc = accuracy_score(y_train, clf_train_preds)\n",
    "# #             model = clf_search\n",
    "#         clf_preds = clf_search.predict(X_test)\n",
    "#         clf_preds[clf_preds == -1] = 0\n",
    "#         if (accuracy_score(y_test, clf_preds) > model_acc):\n",
    "#             model_acc = accuracy_score(y_test, clf_preds)\n",
    "#             model = clf_search\n",
    "# #         if (accuracy_score(y_test, clf_preds)*accuracy_score(y_train, clf_train_preds) > model_acc):\n",
    "# #             model_acc = accuracy_score(y_test, clf_preds)*accuracy_score(y_train, clf_train_preds)\n",
    "# #             model = clf_search\n",
    "#     model.fit(X_train)\n",
    "#     preds = model.predict(X_test)\n",
    "#     train_preds = model.predict(X_train)\n",
    "#     preds[preds == -1] = 0\n",
    "#     train_preds[train_preds == -1] = 0\n",
    "#     print('Counts: ', sum(train_preds), sum(train_preds)/len(train_preds), sum(preds), sum(preds)/len(preds))\n",
    "#     t_a_score.append(accuracy_score(y_train, train_preds))\n",
    "#     t_f_score.append(f1_score(y_train, train_preds)), t_p_score.append(precision_score(y_train, train_preds)), t_r_score.append(recall_score(y_train, train_preds))\n",
    "#     a_score.append(accuracy_score(y_test, preds))\n",
    "#     f_score.append(f1_score(y_test, preds)), p_score.append(precision_score(y_test, preds)), r_score.append(recall_score(y_test, preds))\n",
    "#     print('Train: ', t_a_score[-1], t_f_score[-1], t_p_score[-1], t_r_score[-1])\n",
    "#     print('Test : ', a_score[-1], f_score[-1], p_score[-1], r_score[-1])\n",
    "\n",
    "# print('')\n",
    "# print('Train: ', sum(t_a_score)/len(t_a_score), sum(t_f_score)/len(t_f_score), sum(t_p_score)/len(t_p_score), sum(t_r_score)/len(t_r_score))\n",
    "# print('Test : ', sum(a_score)/len(a_score), sum(f_score)/len(f_score), sum(p_score)/len(p_score), sum(r_score)/len(r_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
