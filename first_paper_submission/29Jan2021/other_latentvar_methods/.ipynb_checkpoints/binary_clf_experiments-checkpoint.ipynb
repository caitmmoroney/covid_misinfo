{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification with Tweet Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Unreliable</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 3, 6, 9</td>\n",
       "      <td>We are living in scary times in Canada. Gov’t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 6, 8, 9</td>\n",
       "      <td>Just as bad in Canada. In fact, our government...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 4, 9</td>\n",
       "      <td>It was only a matter of time before the mainst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8</td>\n",
       "      <td>Russia's taking no chances: Foreigners infecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8, 9</td>\n",
       "      <td>Although there is now a presumptive confirmed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BREAKING: Harvard classes will move online sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singularity University is hosting a FREE Virtu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus: how does it spread and what are t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stanford just cancelled classes for the rest o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tech conferences were cancelled in #Waterloo R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Is_Unreliable    Category  \\\n",
       "0                1  1, 3, 6, 9   \n",
       "1                1  1, 6, 8, 9   \n",
       "2                1     1, 4, 9   \n",
       "3                1        6, 8   \n",
       "4                1     6, 8, 9   \n",
       "..             ...         ...   \n",
       "555              0         NaN   \n",
       "556              0         NaN   \n",
       "557              0         NaN   \n",
       "558              0         NaN   \n",
       "559              0         NaN   \n",
       "\n",
       "                                                 Tweet  \n",
       "0    We are living in scary times in Canada. Gov’t ...  \n",
       "1    Just as bad in Canada. In fact, our government...  \n",
       "2    It was only a matter of time before the mainst...  \n",
       "3    Russia's taking no chances: Foreigners infecte...  \n",
       "4    Although there is now a presumptive confirmed ...  \n",
       "..                                                 ...  \n",
       "555  BREAKING: Harvard classes will move online sta...  \n",
       "556  Singularity University is hosting a FREE Virtu...  \n",
       "557  Coronavirus: how does it spread and what are t...  \n",
       "558  Stanford just cancelled classes for the rest o...  \n",
       "559  Tech conferences were cancelled in #Waterloo R...  \n",
       "\n",
       "[560 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load tweets\n",
    "tweets = pd.read_excel('COVID19_Dataset-CM-ZB-complete with sources.xlsx')\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tweet embeddings\n",
    "fname = 'tweet_embed_{}.npy'\n",
    "fname_NMF = fname.format('NMF')\n",
    "fname_LDA = fname.format('LDA')\n",
    "fname_DL = fname.format('DL')\n",
    "tweet_embeddings_NMF = np.load(fname_NMF)\n",
    "tweet_embeddings_LDA = np.load(fname_LDA)\n",
    "tweet_embeddings_DL = np.load(fname_DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of embeddings to iterate over\n",
    "embeddings = [tweet_embeddings_NMF, tweet_embeddings_LDA, tweet_embeddings_DL]\n",
    "\n",
    "# target y\n",
    "target = np.array(tweets['Is_Unreliable'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification: five-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC hyperparams to optimize\n",
    "kernel = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "C = [0.001, 0.01, 0.1, 1, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_num = int(tweets.shape[0]/5)\n",
    "tune_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the folds\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits = num_folds, shuffle = True, random_state = 1)\n",
    "splits = kf.split(tweet_embeddings_NMF) # use any set of embeddings to get train/test indices splits\n",
    "\n",
    "training_sets = []\n",
    "testing_sets = []\n",
    "for train_idx, test_idx in splits:\n",
    "    training_sets.append(train_idx)\n",
    "    testing_sets.append(test_idx)\n",
    "\n",
    "# Construct tuning sets from training sets (20% of data ~ 1 fold) &\n",
    "# write over training sets (60% of data ~ 3 folds)\n",
    "tuning_sets = []\n",
    "for i in range(len(training_sets)):\n",
    "    train_set = training_sets[i]\n",
    "    np.random.seed(i)\n",
    "    tune_idx = np.random.choice(train_set,\n",
    "                                size = tune_num,\n",
    "                                replace = False)\n",
    "    tuning_sets.append(tune_idx)\n",
    "    new_train_set = train_set[~np.in1d(train_set, tune_idx)]\n",
    "    training_sets[i] = new_train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to create results dictionary & save models in opt_models dictionary\n",
    "#\n",
    "# Inputs: numpy array\n",
    "# Outputs: dictionary containing model performance stats\n",
    "\n",
    "def get_results(np_array):\n",
    "    # Initialize dict to store all model stats\n",
    "    performance = dict()\n",
    "    \n",
    "    # Initialize dict to store optimal models from each fold\n",
    "    opt_models = dict()\n",
    "\n",
    "    # Loop over folds\n",
    "    for i in range(num_folds):\n",
    "        key1 = 'Fold {}'.format(i+1) # key for the performance dict\n",
    "\n",
    "        train_idx = training_sets[i]\n",
    "        test_idx = testing_sets[i]\n",
    "        tune_idx = tuning_sets[i]\n",
    "\n",
    "        y_train = target[train_idx]\n",
    "        y_test = target[test_idx]\n",
    "        y_tune = target[tune_idx]\n",
    "\n",
    "        X_train = np_array[train_idx]\n",
    "        X_test = np_array[test_idx]\n",
    "        X_tune = np_array[tune_idx]\n",
    "\n",
    "        # Training & tuning\n",
    "        models = [] # store list of models in order to retrieve optimal model\n",
    "        tune_auc = [] # tune based on AUC\n",
    "        model_dict = dict() # to store model params & performance metric values\n",
    "\n",
    "        for ker in kernel:\n",
    "            for el in C:\n",
    "                # Training\n",
    "                svc = SVC(C = el, kernel = ker, probability = True)\n",
    "                svc.fit(X_train, y_train)\n",
    "                models.append(svc)\n",
    "\n",
    "                # Tuning\n",
    "                tune_predict_proba = svc.predict_proba(X_tune)[:,1] # check on this subscripting\n",
    "                auc = roc_auc_score(y_tune, tune_predict_proba)\n",
    "                tune_auc.append(auc)\n",
    "\n",
    "        # Get optimal model based on hyperparameter tuning\n",
    "        opt_model = models[tune_auc.index(max(tune_auc))] # tune based on AUC\n",
    "        opt_model_params = opt_model.get_params()\n",
    "        model_dict['params'] = opt_model_params # store optimal values for model hyperparameters\n",
    "        opt_models[key1] = opt_model\n",
    "\n",
    "        # Save training scores\n",
    "        train_scores = dict() # to store all training scores\n",
    "        train_predict = opt_model.predict(X_train)\n",
    "        train_predict_proba = opt_model.predict_proba(X_train)[:,1] # check on this subscripting\n",
    "        train_scores['auc'] = roc_auc_score(y_train, train_predict_proba)\n",
    "        train_scores['accuracy'] = accuracy_score(y_train, train_predict)\n",
    "        train_scores['recall_macro'] = recall_score(y_train, train_predict, average = 'macro')\n",
    "        train_scores['precision_macro'] = precision_score(y_train, train_predict, average = 'macro')\n",
    "        train_scores['f1_macro'] = f1_score(y_train, train_predict, average = 'macro')\n",
    "\n",
    "        # Save training scores dictionary to model dictionary\n",
    "        model_dict['training'] = train_scores\n",
    "\n",
    "        # Save tuning scores\n",
    "        tune_scores = dict() # to store all tuning scores\n",
    "        tune_predict = opt_model.predict(X_tune)\n",
    "        tune_predict_proba = opt_model.predict_proba(X_tune)[:,1] # check on this subscripting\n",
    "        tune_scores['auc'] = roc_auc_score(y_tune, tune_predict_proba)\n",
    "        tune_scores['accuracy'] = accuracy_score(y_tune, tune_predict)\n",
    "        tune_scores['recall_macro'] = recall_score(y_tune, tune_predict, average = 'macro')\n",
    "        tune_scores['precision_macro'] = precision_score(y_tune, tune_predict, average = 'macro')\n",
    "        tune_scores['f1_macro'] = f1_score(y_tune, tune_predict, average = 'macro')\n",
    "\n",
    "        # Save tuning scores dictionary to model dictionary\n",
    "        model_dict['tuning'] = tune_scores\n",
    "\n",
    "        # Testing\n",
    "        test_scores = dict() # to store all testing scores\n",
    "        test_predict = opt_model.predict(X_test)\n",
    "        test_predict_proba = opt_model.predict_proba(X_test)[:,1]\n",
    "        test_scores['auc'] = roc_auc_score(y_test, test_predict_proba)\n",
    "        test_scores['accuracy'] = accuracy_score(y_test, test_predict)\n",
    "        test_scores['recall_macro'] = recall_score(y_test, test_predict, average = 'macro')\n",
    "        test_scores['precision_macro'] = precision_score(y_test, test_predict, average = 'macro')\n",
    "        test_scores['f1_macro'] = f1_score(y_test, test_predict, average = 'macro')\n",
    "\n",
    "        # Save test scores dictionary to model dictionary\n",
    "        model_dict['testing'] = test_scores\n",
    "\n",
    "        # Save model dictionary to overall dictionary\n",
    "        performance[key1] = model_dict\n",
    "    \n",
    "    return performance, opt_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# get results for NMF embeddings\n",
    "NMF_results, NMF_models = get_results(tweet_embeddings_NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get results for LDA embeddings\n",
    "LDA_results, LDA_models = get_results(tweet_embeddings_LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# get results for BERT embeddings\n",
    "DL_results, DL_models = get_results(tweet_embeddings_DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fold 1': {'params': {'C': 1,\n",
       "   'break_ties': False,\n",
       "   'cache_size': 200,\n",
       "   'class_weight': None,\n",
       "   'coef0': 0.0,\n",
       "   'decision_function_shape': 'ovr',\n",
       "   'degree': 3,\n",
       "   'gamma': 'scale',\n",
       "   'kernel': 'rbf',\n",
       "   'max_iter': -1,\n",
       "   'probability': True,\n",
       "   'random_state': None,\n",
       "   'shrinking': True,\n",
       "   'tol': 0.001,\n",
       "   'verbose': False},\n",
       "  'training': {'auc': 0.9979792966534317,\n",
       "   'accuracy': 0.9761904761904762,\n",
       "   'recall_macro': 0.9764605785592739,\n",
       "   'precision_macro': 0.9761904761904763,\n",
       "   'f1_macro': 0.9761871013465627},\n",
       "  'tuning': {'auc': 0.9057692307692307,\n",
       "   'accuracy': 0.8214285714285714,\n",
       "   'recall_macro': 0.8128205128205128,\n",
       "   'precision_macro': 0.8388888888888889,\n",
       "   'f1_macro': 0.8155467720685112},\n",
       "  'testing': {'auc': 0.9123086734693877,\n",
       "   'accuracy': 0.8571428571428571,\n",
       "   'recall_macro': 0.8571428571428572,\n",
       "   'precision_macro': 0.858974358974359,\n",
       "   'f1_macro': 0.8569604086845466}},\n",
       " 'Fold 2': {'params': {'C': 0.001,\n",
       "   'break_ties': False,\n",
       "   'cache_size': 200,\n",
       "   'class_weight': None,\n",
       "   'coef0': 0.0,\n",
       "   'decision_function_shape': 'ovr',\n",
       "   'degree': 3,\n",
       "   'gamma': 'scale',\n",
       "   'kernel': 'linear',\n",
       "   'max_iter': -1,\n",
       "   'probability': True,\n",
       "   'random_state': None,\n",
       "   'shrinking': True,\n",
       "   'tol': 0.001,\n",
       "   'verbose': False},\n",
       "  'training': {'auc': 0.9784708608091248,\n",
       "   'accuracy': 0.9166666666666666,\n",
       "   'recall_macro': 0.9119942969167706,\n",
       "   'precision_macro': 0.9239628800939002,\n",
       "   'f1_macro': 0.91521268925739},\n",
       "  'tuning': {'auc': 0.9432658309225329,\n",
       "   'accuracy': 0.8392857142857143,\n",
       "   'recall_macro': 0.8476374156219865,\n",
       "   'precision_macro': 0.8503401360544218,\n",
       "   'f1_macro': 0.8392344497607656},\n",
       "  'testing': {'auc': 0.9404296875,\n",
       "   'accuracy': 0.8125,\n",
       "   'recall_macro': 0.8333333333333333,\n",
       "   'precision_macro': 0.8396351575456054,\n",
       "   'f1_macro': 0.8123653769445552}},\n",
       " 'Fold 3': {'params': {'C': 1,\n",
       "   'break_ties': False,\n",
       "   'cache_size': 200,\n",
       "   'class_weight': None,\n",
       "   'coef0': 0.0,\n",
       "   'decision_function_shape': 'ovr',\n",
       "   'degree': 3,\n",
       "   'gamma': 'scale',\n",
       "   'kernel': 'rbf',\n",
       "   'max_iter': -1,\n",
       "   'probability': True,\n",
       "   'random_state': None,\n",
       "   'shrinking': True,\n",
       "   'tol': 0.001,\n",
       "   'verbose': False},\n",
       "  'training': {'auc': 0.994330262225372,\n",
       "   'accuracy': 0.9642857142857143,\n",
       "   'recall_macro': 0.9642097802976612,\n",
       "   'precision_macro': 0.9644072603516733,\n",
       "   'f1_macro': 0.9642743221690591},\n",
       "  'tuning': {'auc': 0.9736168851934761,\n",
       "   'accuracy': 0.9107142857142857,\n",
       "   'recall_macro': 0.9133354653022066,\n",
       "   'precision_macro': 0.9133354653022066,\n",
       "   'f1_macro': 0.9107142857142857},\n",
       "  'testing': {'auc': 0.9336523125996811,\n",
       "   'accuracy': 0.8928571428571429,\n",
       "   'recall_macro': 0.8918660287081339,\n",
       "   'precision_macro': 0.8979591836734694,\n",
       "   'f1_macro': 0.8923076923076922}},\n",
       " 'Fold 4': {'params': {'C': 0.1,\n",
       "   'break_ties': False,\n",
       "   'cache_size': 200,\n",
       "   'class_weight': None,\n",
       "   'coef0': 0.0,\n",
       "   'decision_function_shape': 'ovr',\n",
       "   'degree': 3,\n",
       "   'gamma': 'scale',\n",
       "   'kernel': 'rbf',\n",
       "   'max_iter': -1,\n",
       "   'probability': True,\n",
       "   'random_state': None,\n",
       "   'shrinking': True,\n",
       "   'tol': 0.001,\n",
       "   'verbose': False},\n",
       "  'training': {'auc': 0.9610827302398184,\n",
       "   'accuracy': 0.8273809523809523,\n",
       "   'recall_macro': 0.8220519369944657,\n",
       "   'precision_macro': 0.8587008060692272,\n",
       "   'f1_macro': 0.8216952129995608},\n",
       "  'tuning': {'auc': 0.962962962962963,\n",
       "   'accuracy': 0.7767857142857143,\n",
       "   'recall_macro': 0.7844827586206897,\n",
       "   'precision_macro': 0.8417721518987342,\n",
       "   'f1_macro': 0.7686524002313475},\n",
       "  'testing': {'auc': 0.9243589743589744,\n",
       "   'accuracy': 0.7232142857142857,\n",
       "   'recall_macro': 0.7378205128205129,\n",
       "   'precision_macro': 0.7753246753246753,\n",
       "   'f1_macro': 0.7166870665034679}},\n",
       " 'Fold 5': {'params': {'C': 0.001,\n",
       "   'break_ties': False,\n",
       "   'cache_size': 200,\n",
       "   'class_weight': None,\n",
       "   'coef0': 0.0,\n",
       "   'decision_function_shape': 'ovr',\n",
       "   'degree': 3,\n",
       "   'gamma': 'scale',\n",
       "   'kernel': 'rbf',\n",
       "   'max_iter': -1,\n",
       "   'probability': True,\n",
       "   'random_state': None,\n",
       "   'shrinking': True,\n",
       "   'tol': 0.001,\n",
       "   'verbose': False},\n",
       "  'training': {'auc': 0.9715332882610398,\n",
       "   'accuracy': 0.5327380952380952,\n",
       "   'recall_macro': 0.5,\n",
       "   'precision_macro': 0.2663690476190476,\n",
       "   'f1_macro': 0.34757281553398056},\n",
       "  'tuning': {'auc': 0.91015625,\n",
       "   'accuracy': 0.42857142857142855,\n",
       "   'recall_macro': 0.5,\n",
       "   'precision_macro': 0.21428571428571427,\n",
       "   'f1_macro': 0.3},\n",
       "  'testing': {'auc': 0.9491525423728815,\n",
       "   'accuracy': 0.4732142857142857,\n",
       "   'recall_macro': 0.5,\n",
       "   'precision_macro': 0.23660714285714285,\n",
       "   'f1_macro': 0.3212121212121212}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DL_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to create results df from nested dictionary\n",
    "def create_df(input_dict):\n",
    "    df = pd.DataFrame(input_dict)\n",
    "    df = df.transpose()\n",
    "    \n",
    "    df_params = df['params'].apply(pd.Series)\n",
    "    \n",
    "    df_training = df['training'].apply(pd.Series)\n",
    "    df_training.columns = ['train_' + str(col) for col in df_training.columns]\n",
    "    \n",
    "    df_tuning = df['tuning'].apply(pd.Series)\n",
    "    df_tuning.columns = ['tune_' + str(col) for col in df_tuning.columns]\n",
    "    \n",
    "    df_testing = df['testing'].apply(pd.Series)\n",
    "    df_testing.columns = ['test_' + str(col) for col in df_testing.columns]\n",
    "    \n",
    "    final_df = pd.concat([df_training, df_tuning, df_testing, df_params], axis = 1).reset_index()\n",
    "    final_df = final_df.rename({'index': 'fold_num'}, axis = 1)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get means for test results from dataframe of full results\n",
    "def get_test_means(df):\n",
    "    filter_cols = [col for col in df if col.startswith('test_')]\n",
    "    df_test = df[filter_cols]\n",
    "    df_test_mean = pd.DataFrame(df_test.mean(axis = 0)).transpose()\n",
    "    \n",
    "    return df_test_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_prefix = './clf_results/'\n",
    "\n",
    "# Save NMF embedding results\n",
    "NMF_full = create_df(NMF_results)\n",
    "fname = dir_prefix + 'NMF_svm_full_results.csv'\n",
    "NMF_full.to_csv(fname)\n",
    "\n",
    "NMF_test_mean = get_test_means(NMF_full)\n",
    "fname = dir_prefix + 'NMF_svm_testmean_results.csv'\n",
    "NMF_test_mean.to_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save LDA embedding results\n",
    "LDA_full = create_df(LDA_results)\n",
    "fname = dir_prefix + 'LDA_svm_full_results.csv'\n",
    "LDA_full.to_csv(fname)\n",
    "\n",
    "LDA_test_mean = get_test_means(LDA_full)\n",
    "fname = dir_prefix + 'LDA_svm_testmean_results.csv'\n",
    "LDA_test_mean.to_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DL embedding results\n",
    "DL_full = create_df(DL_results)\n",
    "fname = dir_prefix + 'DL_svm_full_results.csv'\n",
    "DL_full.to_csv(fname)\n",
    "\n",
    "DL_test_mean = get_test_means(DL_full)\n",
    "fname = dir_prefix + 'DL_svm_testmean_results.csv'\n",
    "DL_test_mean.to_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best folds & test accuracy for NMF, LDA, and DL\n",
    "emb_names = ['NMF', 'LDA', 'DL']\n",
    "best_folds = [NMF_full.iloc[NMF_full['test_accuracy'].idxmax()]['fold_num'],\n",
    "              LDA_full.iloc[LDA_full['test_accuracy'].idxmax()]['fold_num'],\n",
    "              DL_full.iloc[DL_full['test_accuracy'].idxmax()]['fold_num']]\n",
    "best_accuracy = [NMF_full.iloc[NMF_full['test_accuracy'].idxmax()]['test_accuracy'],\n",
    "                 LDA_full.iloc[LDA_full['test_accuracy'].idxmax()]['test_accuracy'],\n",
    "                 DL_full.iloc[DL_full['test_accuracy'].idxmax()]['test_accuracy']]\n",
    "\n",
    "best_fold_stats = pd.DataFrame({'embeddings': emb_names,\n",
    "                                'best_fold_num': best_folds,\n",
    "                                'test_acc': best_accuracy})\n",
    "fname = dir_prefix + 'best_folds.csv'\n",
    "best_fold_stats.to_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_DL_Fold 3.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best fold models for NMF, LDA, and DL\n",
    "\n",
    "# NMF embeddings\n",
    "fname = dir_prefix + 'svm_NMF_{}.pkl'.format(NMF_full.iloc[NMF_full['test_accuracy'].idxmax()]['fold_num'])\n",
    "joblib.dump(NMF_models[NMF_full.iloc[NMF_full['test_accuracy'].idxmax()]['fold_num']],\n",
    "            fname)\n",
    "\n",
    "# LDA embeddings\n",
    "fname = dir_prefix + 'svm_LDA_{}.pkl'.format(LDA_full.iloc[LDA_full['test_accuracy'].idxmax()]['fold_num'])\n",
    "joblib.dump(LDA_models[LDA_full.iloc[LDA_full['test_accuracy'].idxmax()]['fold_num']],\n",
    "            fname)\n",
    "\n",
    "# DL embeddings\n",
    "fname = dir_prefix + 'svm_DL_{}.pkl'.format(DL_full.iloc[DL_full['test_accuracy'].idxmax()]['fold_num'])\n",
    "joblib.dump(DL_models[DL_full.iloc[DL_full['test_accuracy'].idxmax()]['fold_num']],\n",
    "            fname)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
